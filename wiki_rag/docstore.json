{"docstore/metadata": {"1164": {"doc_hash": "f7d89d37b65b972cacfc270c355208a838fdb4a4e05772c89023bfcd0917947d"}, "2894560": {"doc_hash": "3f693a0322bab49ee1a9c95b0fad8b26f3b517c00c36665addff054ec94514ce"}, "32472154": {"doc_hash": "2c6d7e6f84c4a9e5e945746e1ba39555343099af69cd64331fed1375c56fdd56"}, "40409788": {"doc_hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388"}, "61603971": {"doc_hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655"}, "73248112": {"doc_hash": "e3ba2797cf6c96a6f37e9f6a3de5ff204e6856b2ddd874f988c790a6a61f66dc"}, "586357": {"doc_hash": "c1cb6325bbd1cbea4a0de6e688f417ec4ca9301c5924b53445ada99952b4f0c7"}, "726659": {"doc_hash": "341f2972b85a37a52d0b7b36a021cb08664fdf14343b0cf97eb85cfc57b934f0"}, "c03f7ad5-ff51-4896-9a8c-95683963c654": {"doc_hash": "b6e429dd2057f2880a69a43bce5f6c1e40f9aa784c054e4980402537f27b68f6", "ref_doc_id": "1164"}, "6da4fb61-9581-45e5-af32-bffd363db8cd": {"doc_hash": "2d8ba8a05a669f3b5aee510c60a31f0e89dd099e2f0fdd3c307da7c5f1939b70", "ref_doc_id": "1164"}, "f8255131-fd09-4fee-98d5-f3c677856163": {"doc_hash": "809179e80ff050502d1cc8051f08f0ab2708e1f50dc30d37842e511f047f17b7", "ref_doc_id": "1164"}, "bab36993-1f2c-467b-a48f-2d76d349e462": {"doc_hash": "d25119c20c44c8c3dd6cd5488af1f1aa23f7c1a7ad49ee6aade2878fbcff4c9f", "ref_doc_id": "1164"}, "dac361c8-9f61-4ba4-b075-f5d4389295ca": {"doc_hash": "a5f995670d84d48c5c4e3d4fa68f85e00bb7b405ea5af4ba524969eaaa7d1c79", "ref_doc_id": "1164"}, "9ebeca90-ffa5-45db-ba03-e39ed2751154": {"doc_hash": "281e36f21da11259ff60e1443782179572613d9bcdf293d9c09124f391de14ff", "ref_doc_id": "1164"}, "f6930d55-ee66-424b-82a6-941c359daf14": {"doc_hash": "4c2937c60468eadf27fc3cd2e91056881a10985c354ae19039f62dfdcdc77098", "ref_doc_id": "1164"}, "63a9bdd0-7722-40df-ae9e-df7011ac1d4f": {"doc_hash": "572bebce70a54a709deba05a60b7be6bded186199501335075633dd269e281f2", "ref_doc_id": "1164"}, "ce96c984-6bb1-4d3f-ada1-2aa6035ebf59": {"doc_hash": "3a4d82c02400a437d3713186697c03c3eaba2693b712a12824e55172fde11532", "ref_doc_id": "1164"}, "1014d9dc-9ae9-4dd1-ac14-0ada66e4a9ae": {"doc_hash": "b5dbd1384a94b93bd48bee9750710e49b012773ab43262065e76924e530dccee", "ref_doc_id": "1164"}, "f1900eb9-9794-4c79-9358-48a3619b395a": {"doc_hash": "e7d98fc8e12c14336af790dd1a5e31113a0e44f5f2851b02269ae983697ae8a7", "ref_doc_id": "1164"}, "a770c7d6-5fd8-43ca-930e-241f530884a9": {"doc_hash": "8acb1a98d9ddc1a43e5703ee9840a69e641d631ee44e2b5af62748a60c4f8794", "ref_doc_id": "1164"}, "748bfbfe-c62e-4446-af81-ff84db352218": {"doc_hash": "256371a07578bc23e597d7f516f3e7f0272fbc7023f171740ce5e4684c32a177", "ref_doc_id": "1164"}, "d6ec0057-9df7-44c8-a9ac-fadef7b4c449": {"doc_hash": "cbe88d40bc8ba70e49b83621505af8b9841e4e188b141b4ce8b26df6acf43d9f", "ref_doc_id": "1164"}, "582c2c70-e701-470b-85d3-692e9bf1d4dc": {"doc_hash": "2822f2aa1a88985766ac61b72ff1e33699980458f8204ff3e7188ed0fbbd0484", "ref_doc_id": "1164"}, "b305739e-f2bd-401f-aecc-710ed8a1673d": {"doc_hash": "0725c3115d23449ccf06dc3cc3d15c5b2c462d61c485842dc5e88972ec6014f7", "ref_doc_id": "1164"}, "940a7ba9-7764-41b2-92a6-fcfac7e6e3a0": {"doc_hash": "7f6e2dc6185f57eaa9260760cddc93f36cfdcc19fde5e460f03d8f8090bc7c02", "ref_doc_id": "1164"}, "d4f67fb4-9378-4832-bd9b-85d367e9cd28": {"doc_hash": "a6d4ffb897ee2a5cf294610ba9675ead2664454bb56c3b8a9fd35370e1f94181", "ref_doc_id": "1164"}, "1eb737bb-e068-4b59-a724-cd3acea8f8bb": {"doc_hash": "24b2e3abf0b9f077b347a32bde891c5c3fd45f63b5cdbaa1b82e43f595c025c0", "ref_doc_id": "1164"}, "e791a355-3211-4038-90d1-367802583262": {"doc_hash": "480c29dd28ef61d17e581baf61abac6e26c3fde5ba4a50b019889e6a6efd2ec6", "ref_doc_id": "1164"}, "9ed57cc2-be4a-4bbb-83e4-c0584faf7c66": {"doc_hash": "367f416124e2f2bf1579e43f9050100aacc13ac856e5d53f6e52d79ff139c2bc", "ref_doc_id": "1164"}, "d3ead8bc-b4a2-4d8b-abda-272b2327c406": {"doc_hash": "2a3c9ca8d179ab9c31627a6adc9606b6e502388da15cf0aecf448d41b37685d1", "ref_doc_id": "1164"}, "bf5a447d-15e9-4ad8-a417-680587a46b11": {"doc_hash": "476799b0174868703b9ec1d0e4139da796a296f71be7b5cad75d6593e2ffde4c", "ref_doc_id": "2894560"}, "337000d0-3fe4-4aae-a2ae-d2dd68a65cbd": {"doc_hash": "e39044c4a507606b3d5ed7f4af9627a71ea95b3cbebcd46fa99bebff785e2173", "ref_doc_id": "2894560"}, "06c55d0d-c5bc-4be0-b343-a1dadbe3c7f5": {"doc_hash": "485c11e87e5065fcc05dcf397709b88127901e06fa9823c9846aaa28d2b48e8c", "ref_doc_id": "2894560"}, "a9f41060-c6a3-42c7-ae1a-6777970c67c4": {"doc_hash": "ce1f3763195f91b70c078832846f0b2e5f04b1628d4659fa57b19dced55e43c6", "ref_doc_id": "2894560"}, "2ede79d6-a38d-4ad4-9072-14d7f6fa65bb": {"doc_hash": "0535960c4c99d21d0f6bf2fc14402c2c5be5cfb162e1e66fa5d8adfbcc1e756b", "ref_doc_id": "2894560"}, "e7cdee5d-f787-4990-b187-cef056780dbd": {"doc_hash": "776badf9e3d84ca9416fccb5776814d8950e7f7f7d33caf3d1dd42b1609ed3a9", "ref_doc_id": "2894560"}, "a05374f6-a217-493a-91c9-70fdc6dfe087": {"doc_hash": "80e94e2a7611a11aed8538cc5827e301dd1bb988beca6c6e0785d72661674dec", "ref_doc_id": "2894560"}, "e832520c-2c13-4055-9a3e-4df1f765c0e9": {"doc_hash": "6f82b960216dc86789c3dcbf6a609318bac9658491b858d8b45febfca62d4ef6", "ref_doc_id": "2894560"}, "feb0aa40-8067-4bb4-8062-cae21a5c75f5": {"doc_hash": "aa4e7d4e8393edf08ceef46d1d57f3674577f4b273d3357d29ff350e04eb9eac", "ref_doc_id": "2894560"}, "e001d43a-dfc3-457c-a172-4baaa93b33a8": {"doc_hash": "d30c1fa3821c9a0ee1c643959181c96abcb3ba8268abec8eaa7f1255a2ed074c", "ref_doc_id": "2894560"}, "16df7dc2-c5b0-4226-b2cb-ce8011e53851": {"doc_hash": "7af1ca56c758c7bb9a9e2f7cf794766c79860e2517674f3de76bd8f09b5370b4", "ref_doc_id": "2894560"}, "529e8857-e054-41cf-9d4b-b9b218b902a3": {"doc_hash": "73c2bef57416ebefc50ffe05a6a5e89896a098e827a2118617b736424d878ba2", "ref_doc_id": "2894560"}, "c1073fb2-a12d-4dc1-8d1e-fe0e81452a49": {"doc_hash": "d3ed24549a368d94de1a2a26b0b3a664e5ab3e748fc74eb67204e3ca67d13cdb", "ref_doc_id": "2894560"}, "c5bc599c-4fed-4424-a581-e4084dc88cc6": {"doc_hash": "b34c2b5fc3edcf58556548c92c909fa4a9e56a2fb2f4015a19b3e65b80ee4a04", "ref_doc_id": "2894560"}, "b5df004a-a492-45c4-944c-b32f65bf9718": {"doc_hash": "caa42b8d3fe4b4d02da56fc4cfc7c0c74f125b78ff2668bdc2c8069d7494ed42", "ref_doc_id": "2894560"}, "f6908e55-36e1-44b8-8a1c-0b61ecad8974": {"doc_hash": "b91ae6aed09b958ad0db8c57075580cc5dbe9d3234998bde8ac2dd95a8966d01", "ref_doc_id": "2894560"}, "923bdf78-1227-46a9-85a9-d41ddc0d73db": {"doc_hash": "c8c9ac1255cc004985a0aafd04354e1f92b88523a34549c9d616d18f0249fc41", "ref_doc_id": "2894560"}, "dd3fb12f-097c-4110-9a61-c0e7ce834393": {"doc_hash": "3a8484ddcf7c3280afe661f045698cbe7f2636db456a39de1bc36774da0aecb9", "ref_doc_id": "2894560"}, "a129138a-226b-42f0-8cd2-86553e5f67b4": {"doc_hash": "79ce813f2e347b83a31af5a9c83f99624baa3a30fe1daecbde2ae29a516f4e9b", "ref_doc_id": "2894560"}, "73686731-c8e5-4c7f-a269-37af8834d750": {"doc_hash": "fed06a6f6f569c31b63bd852a386c7a729e8901af7924a92b998d06940fb2497", "ref_doc_id": "2894560"}, "d7499800-b881-43ce-8615-ac87576cbce3": {"doc_hash": "1c2ffc3eca81ef8b6c584a40731fef40d8c73356bd521d98c6b74931fca28d11", "ref_doc_id": "2894560"}, "5f2d015d-6bc6-4eac-9c23-a8127cb27636": {"doc_hash": "68b78867f4ddc16758da14a8addd951d37f8c3004c4c7efade3a39f1dc593eaa", "ref_doc_id": "32472154"}, "66331e57-f85d-468e-97a3-6f878fba0a9e": {"doc_hash": "4bf9dfccd7057f5a02f776719451af5627382c4cb7f7b1e54f6c5e8bd3c992fe", "ref_doc_id": "32472154"}, "5477aace-7847-4390-b5f8-466bbdf1a9ba": {"doc_hash": "537c5796da87ae540ba2e03b32e396286003b297e24d963aeae2a7f7d41299a9", "ref_doc_id": "32472154"}, "fb6f1d2c-da47-4d18-b44f-f977de3f3d9a": {"doc_hash": "1a876a6433a4ceb4f227ed73d3d0df2be988f475dbf7efa05d522c50b592319f", "ref_doc_id": "32472154"}, "60be2bba-4bc5-431b-b48f-e8b47131c06e": {"doc_hash": "ccfe96d9636bb7759877586291f84de38e3b57ec75e3cc93acb7fcec4b2e7956", "ref_doc_id": "32472154"}, "2be6c3c9-24d6-4339-8c8c-98b4b2bb7160": {"doc_hash": "294e5445d58454abb293add53c64d260d9f8a1deeac58188ed5a28225bcd85b8", "ref_doc_id": "32472154"}, "d15b1341-804e-426b-97e0-a1d73328bd5e": {"doc_hash": "09dcfab3f907be974a5ba060117d52df97863955c6c3ffc67f168027ea1caddf", "ref_doc_id": "32472154"}, "55807351-f087-4663-813f-0399077c90fe": {"doc_hash": "7630e998aa14d81f893183b1559984cece1a66bf939352ed23985b2bd24bb01f", "ref_doc_id": "32472154"}, "682470e6-b604-496c-bc21-bc958d9caf62": {"doc_hash": "bbcd61324f8329f2301b6b48fa9da21d0856791ddcf50b5b017e00c844c5a7ad", "ref_doc_id": "32472154"}, "f8b1ffb6-17c7-4339-af7b-899c4528a21e": {"doc_hash": "70b739311b55a76ac5f691bec58deeb1d0bae2a055cf32cba449473d9df71c81", "ref_doc_id": "32472154"}, "48cbff38-cf1e-4c6f-a74b-b271ac130d9a": {"doc_hash": "203d799683eb9588c44580e498fcc0da5ec133394c65f1fdf1570d9e78483c8a", "ref_doc_id": "32472154"}, "da74462b-7f92-4b30-a154-291d49d9b3a1": {"doc_hash": "a86d7c31655b78cd073763d5410367f0fe709ed56783e29415eb14c577f1bff7", "ref_doc_id": "32472154"}, "ca4ed15b-8a74-45ad-8851-193a04db4413": {"doc_hash": "6b8ada9065c62e30cf7cda3b948509978fa1085d0de585a7946fff38ff879bcd", "ref_doc_id": "32472154"}, "d8063aa9-302d-4bb7-a7cf-a3d3b2fdb83b": {"doc_hash": "14d92b98b7f874110c097c8552b19fb05f90896a2793dd7675f3ca88a9bb4946", "ref_doc_id": "32472154"}, "121b47e8-914a-432b-abf7-54c888e3dcaa": {"doc_hash": "bff1ffc7829a4df7a9f0a99b2f40bab260abe2c38a7698cb8ce9c77184b12417", "ref_doc_id": "40409788"}, "981bb578-8268-41a2-b1ae-1b3cd02958f5": {"doc_hash": "ec25a31db27e14def7d2876f2be3b484fc90731068663d84ebc1819cc9e8425f", "ref_doc_id": "40409788"}, "af19dddc-cce4-4e87-a7fe-87d7a1cb1be2": {"doc_hash": "bda2ebb583c9a8b676b2ed17a0659b8ce0f799f84dc1716f9625a1c6cfa61bf1", "ref_doc_id": "40409788"}, "1c071c84-da1c-4646-904b-02c49ed0f7eb": {"doc_hash": "2f251fa8d7d1e0c52028303717f9715af1e44bb4769fe1d5722d9947c7d65a16", "ref_doc_id": "40409788"}, "cee819b4-b95e-4f1a-99d9-6f7a657c53b7": {"doc_hash": "007afd1be5de0db82730cee4e08eac3223697ed7d8cc657a2c6d95ec54e373d9", "ref_doc_id": "40409788"}, "013e5c8a-180a-4426-ab64-ed043a254d99": {"doc_hash": "d7f3665ce0568050df9042dc14d2b20f266f9ef4d639df8277fe5fe3db1dbed7", "ref_doc_id": "40409788"}, "0f03deee-09fb-4d92-b6a6-678a329bb62d": {"doc_hash": "d669ab12718c1502c2854ed11cc11c14f95f65bf81edfce7bd40333927f7f4f4", "ref_doc_id": "40409788"}, "46f103c5-2e21-4651-a84a-0b458a4079ba": {"doc_hash": "702551c10d7f7170d374907a743e0776b4cac616b46e25a4ecdbd88ed8f4d3b0", "ref_doc_id": "40409788"}, "8774cd75-2e0e-42df-b4d4-79367dc8e15d": {"doc_hash": "caa1afbf2cacc6b06ab77bf006b420a4edd36df99d7ef35f3a3512cb05ba4052", "ref_doc_id": "40409788"}, "af625bcb-0af1-4f09-bfb0-b77e8b49f68b": {"doc_hash": "d90c2cbdf4d09b492ee2ea267befbd3b36de85f40b3864c323fbca0c255ecfaf", "ref_doc_id": "40409788"}, "9de57a1a-7b2c-4662-9cdb-5e91ce43397d": {"doc_hash": "252de977c7e4754b3005c9a4608b805345e90dc118908f8e879ee2798f2693e2", "ref_doc_id": "40409788"}, "c74943a4-e7f6-4e6b-b251-f93e0db189e9": {"doc_hash": "aaad958f2a02f0aa6beb7bced4a98b5ef621274e5424304d2c7647d42313945c", "ref_doc_id": "40409788"}, "7bdf5309-49ff-43e7-991c-33c2a0b8f862": {"doc_hash": "f914196a2f4d0f4742ac2d2ddd83556efd8581746726cf79c286bd968cd8fb19", "ref_doc_id": "40409788"}, "78698999-8539-4538-be6f-8bb7f9daa430": {"doc_hash": "703a30f66fb0b7dd4496e96fa97e0b800bd3ea1454d47c3e5508816479c50854", "ref_doc_id": "40409788"}, "4849d0ff-f29c-4600-8258-c409d146c621": {"doc_hash": "b163152590e9ffbcb338e2d964e03e99ff4c9fddb445dfaf4b7c100ea6f0af1f", "ref_doc_id": "40409788"}, "c765a06d-ca46-4e77-b968-4483510cfde3": {"doc_hash": "0cfa6b15c6a0b00307622d53db5d7d8dc3caca30abfd65393dbc14d76215e434", "ref_doc_id": "40409788"}, "e6a296fc-77b4-427b-b8c3-8e0f34b82846": {"doc_hash": "52c992e9cb923aaf5cee0aca8819eed9c8a036ffacd4aecc5ead7dd923f53bf3", "ref_doc_id": "40409788"}, "f9a50d00-f27b-4bd6-bc7d-d95bc4de8338": {"doc_hash": "bf25a37d927f4daa8b7ef2f2e34df49aa0e44ba0eab54b545b2bd4f867e91d9f", "ref_doc_id": "61603971"}, "0b86388c-beea-4223-9a0d-8c6d393bcd6b": {"doc_hash": "ce259c09c9f4728238b74c3104867eb8cd74144350143de3df5d839f2cc30a0f", "ref_doc_id": "61603971"}, "41a1debd-b938-4d7d-af6c-ca99cc5bcf15": {"doc_hash": "01965bed3651d81a8b2c915dfa47f2b795df15bae2d3f596463bccf820f37c62", "ref_doc_id": "61603971"}, "ef739916-d2e2-4fa3-bbd9-616865383e62": {"doc_hash": "525e6b50001cd4458ad3047e60cb9cede1ba1211d86baa13b07daab8697d383c", "ref_doc_id": "61603971"}, "ed38813f-0eac-452b-9117-cf0f44bbfff1": {"doc_hash": "b61103699dd264f54f30c682a84cb9356150849d7baad608f26e9b6e6f8d4921", "ref_doc_id": "61603971"}, "a2aa3ec3-8598-4e55-a098-cec317d0cab9": {"doc_hash": "7982d510654bd18c01e65884679d852dc8c324d46819ab89ed70016443333ce9", "ref_doc_id": "61603971"}, "9409186e-9f01-4fb0-86bd-f865ae3e6168": {"doc_hash": "4ef7814f0baba97156ca7983a7cc2f579ea7b30c34f4f42eac21b8850ef986ed", "ref_doc_id": "61603971"}, "b54c2232-05ed-4379-b9dc-cb492fb32cfe": {"doc_hash": "1c1b99b96875750af1f05494433df0ab5fd70d2491d9e0411c96945e87bb4793", "ref_doc_id": "61603971"}, "49dcb929-2a70-4cb0-b822-727c29f95ef0": {"doc_hash": "7c740b7230d55339076955fa0565633a953db4134ed27a45f325e61c4717411a", "ref_doc_id": "61603971"}, "724aa0bc-a5f6-455e-b58c-35e5096abcb8": {"doc_hash": "aa2fc1e8639d6c97e1dbcbadf09b4de7178351e63e7c7fba9a90169a8837a619", "ref_doc_id": "61603971"}, "b5cc7826-8fdf-4f18-9690-6a0f6e9666d6": {"doc_hash": "d1f7fb4226a8c6de92dce7846f6ad576dcec02704cd41c1abb2c0ddd2ab3db51", "ref_doc_id": "61603971"}, "634dea5a-efc4-43ea-955b-2abd4315cc9d": {"doc_hash": "53d5fd77cd0a901cc92ccf571850ee2a8ca3762ee5949a02c4386df2c9e6c4ed", "ref_doc_id": "61603971"}, "f395caaf-43b5-49fd-a3f0-52adef4b24ed": {"doc_hash": "68ae2586e7c7881aee2af7a639890cbd3b95faebd00241febb69dc08b557099c", "ref_doc_id": "61603971"}, "f066afd2-28bb-40db-970b-3396b82b1c81": {"doc_hash": "52baa33aadf139b97f43063d1fb947ee848fb09446f533cf46ac3544ea2801f5", "ref_doc_id": "61603971"}, "f285ebfe-fe9f-4e85-91a7-d61981c83929": {"doc_hash": "0106f513bde97d96be03790d74919e5cd5942a5201ef40f3147fc744468997ac", "ref_doc_id": "61603971"}, "192fb953-5dfd-4cef-8bc9-d69e9c31cd7c": {"doc_hash": "3467b58d67e82ab5fca9954ca8a55814bdf304dc0b98c50bb3b4a3f0291dc061", "ref_doc_id": "61603971"}, "2831b82a-0486-43d0-82d9-7a8c3fd34ffd": {"doc_hash": "c6568f5755cfb0122dc20ec898d1f49d062447ba805dc6cd391eac189d9b6faa", "ref_doc_id": "61603971"}, "5c7864b7-7e73-480b-abc7-0f32a4ba58b4": {"doc_hash": "a5e9d871b1a2de43e695f9527082796a83c7f0396508301bb05dbb18948616c0", "ref_doc_id": "61603971"}, "c6f0df42-7971-4899-bc01-80df1d0d4437": {"doc_hash": "18632a3aff013e0b83cb2cea42e1d305c2845c150dc015c35425f2f59d640332", "ref_doc_id": "61603971"}, "3425bb88-fbf3-41e6-bb0e-e155241c50bf": {"doc_hash": "f8e6abac10d4823dfeeb5e25b80caeaeda9c2a3fdd1fbc4b407de871d25ae0d7", "ref_doc_id": "61603971"}, "b7ebef3e-57cc-4301-b2c9-15108895f961": {"doc_hash": "841b94c251015bf99e38c82c6a29dd11ad8910111b4ef93cfd74361c3df78ce7", "ref_doc_id": "61603971"}, "91b78da4-0ccc-4443-89f7-645288e44c7b": {"doc_hash": "a25a82aab3b105c719bef5bc7aa75f414051e6183390781087654ce1bdeac499", "ref_doc_id": "61603971"}, "5c93d5ff-3b43-42ed-a8db-75bd37d6fdfe": {"doc_hash": "ab4f1a35b42d57532d1555e23c6baad93a03ebf47477f6e79e701a009d52b230", "ref_doc_id": "61603971"}, "ab6cd1e9-83bc-4498-92b8-213d423cee17": {"doc_hash": "ab510c37fcccd1026ca466f2d5684b517cc1c591083d59c8490d4161e27d42de", "ref_doc_id": "61603971"}, "6cbd51e0-9b2d-4a5e-b1bc-2d6e0ec5319b": {"doc_hash": "5b1970be53eae7dbebd2f9cd5dc1091a69fb93c04d21838aea84485d302ccc39", "ref_doc_id": "61603971"}, "6c26c77c-b097-41f9-b8d1-08540ac7f52c": {"doc_hash": "b84b6b4dada8ce4ff66d1874c554d023289f795ecfdd3b4046db69e0079222a2", "ref_doc_id": "61603971"}, "8a2d42a2-89ee-4094-bfd5-0f2f3a9edce3": {"doc_hash": "a37057fe00d397aef43a5dc78a6bf1f7f438223ad52bbfaddc7f845a89e356ea", "ref_doc_id": "61603971"}, "cd60046a-9e9e-4e59-8541-1d83db84b525": {"doc_hash": "e77522ce962d6abaa7237570c5f4c0d869824cc777e4c437bdf606419a5babbb", "ref_doc_id": "61603971"}, "f4a269b4-1563-4c1d-b21e-b2c486b4f642": {"doc_hash": "b9622511d85a8f775fb832b8e0d1d610eb5579a6a8f9df43fcad6426e8f16bae", "ref_doc_id": "73248112"}, "45e022bb-d543-418b-b178-99dd54dbd97d": {"doc_hash": "ee8ac10c842286a258c2650a047bee7b02a6db33bf4afd8db32dcaa97bd281ce", "ref_doc_id": "73248112"}, "2133f949-5e6c-476c-93e9-b5b58babf676": {"doc_hash": "03a85ad17989d30a294d1e762e80f0083fe791b279ceb1a5cb88da050bec421b", "ref_doc_id": "73248112"}, "45165cf5-2f91-46e9-8120-e189da9c6856": {"doc_hash": "98ce2d03113b10ee481b952497add727bb652cda48ad943e3d059180f0482d8e", "ref_doc_id": "73248112"}, "03ce6362-f4c2-4193-94bc-e8966b35b2a3": {"doc_hash": "b2c3c83fe9786c6926c1de8fa9315e9e216c7a11dbec7b19fbd7680074871c8e", "ref_doc_id": "73248112"}, "48292cf3-781f-48ad-831b-16af86de6482": {"doc_hash": "251b95ede9d9a0795bc62fb7789602de3f1b3272625f073adc2716899cbaa81e", "ref_doc_id": "73248112"}, "9b1df2db-33cb-4735-9757-228b5f60da1f": {"doc_hash": "590243fd79cc2c168158f9430dd1a0762e5dff9cbd769f2078fd058ad333bbf1", "ref_doc_id": "73248112"}, "91fea428-64c5-4cd4-978d-5f6e0635a14c": {"doc_hash": "b693c81085f701ae94920cd909fc870b500683dc1cf2d5a502e87ece5cb8e578", "ref_doc_id": "73248112"}, "0fac1882-1fbc-4f88-b959-d6fd402c550b": {"doc_hash": "75f4ec7132697de57f1042d1976366fe30673a5cf813fd11ea6298f46e646f80", "ref_doc_id": "73248112"}, "9724b494-75a9-4ac5-a1f3-ba33fbee793f": {"doc_hash": "8b328a0a55467e3c2d10f056c69c7b5e3263c476953a09a0d6d16a94c3991d78", "ref_doc_id": "73248112"}, "23b46642-dd08-4d28-b562-845164885d3e": {"doc_hash": "cc8f3d10fe07cf9102a415b45ec7901195b4ecd7c6be1d499371883bbc25e76e", "ref_doc_id": "73248112"}, "2937669c-6ac1-45c9-a6a6-1bc2dcd6c894": {"doc_hash": "1302f525e3158dfaa4502381d881ae9d8e4ae0655d1dc9fce078d9c2eb8aa426", "ref_doc_id": "73248112"}, "4b0905d6-dfce-4d93-8cbf-883a293511ad": {"doc_hash": "79268ce4fdf901299c177c9d185d2335d1b4d20d75754159a0d6942af5449403", "ref_doc_id": "73248112"}, "9b8dc498-61d1-4003-8a80-5f3b2462142b": {"doc_hash": "3431e8527c271fc48b0136f384a41119d401c651ea59b8fd38733731677fb115", "ref_doc_id": "73248112"}, "3d9ed974-5b0d-4623-b0e8-ce03b4e082b6": {"doc_hash": "e401cc07892bede8db3a08998a30bf710aaa2201e4215c580c5229bfecb9cecd", "ref_doc_id": "586357"}, "7b447c0d-5a60-405a-bcfe-c6ed26cc5338": {"doc_hash": "a51e13790ed1c2d7ea5584cf7adf8d71197432d1effe22036f4321db26ea850d", "ref_doc_id": "586357"}, "bdfcbf9a-0817-422c-825b-51877467fd14": {"doc_hash": "7216c69cf5cfd2365bfcb24e11de5377e73fbe7297c3132733519a0238358453", "ref_doc_id": "586357"}, "b04524bc-6796-4c4c-a4cd-7f0e8fcf2ac4": {"doc_hash": "9a9539119a33d4524a4b5ee550c565ee21d9b3db97546ebb574a2c4b13f5908f", "ref_doc_id": "586357"}, "0eda3fc6-d5e3-4190-b3c3-0af70b6748e7": {"doc_hash": "4999b953648ab21b25cc958b401ba8e0aa6c10f699d1837dbdfb2d5e97f7051f", "ref_doc_id": "586357"}, "9dd44733-c265-4329-99e6-4e254d3a6553": {"doc_hash": "2e4500e825bb0bb476ee7a45b9632bef672ece4ab05bf681f99526e88e2cfc10", "ref_doc_id": "586357"}, "6ceb34b9-66c3-4a86-9459-4f33b1a50d7f": {"doc_hash": "c19f7a9eade4a2e076070e9277c1fda340c6c507344f9b9b1c7a182b4df62628", "ref_doc_id": "586357"}, "10798049-51e8-480a-a388-00fad2912bd8": {"doc_hash": "4096803f80cf31cd16e12a9208aaa4b30b362b371e2b844abe017725a2676095", "ref_doc_id": "586357"}, "8ff03e25-071c-404f-99d4-4824afdbd881": {"doc_hash": "300e9ee5ff2c52831a6b59137150e35df0e0694ecf430b960fbad171912c0958", "ref_doc_id": "586357"}, "b277bf26-e080-4d95-9088-b9c69407f85d": {"doc_hash": "467a817ecedaa1dd7ba26612fb90c8c4f8e2a50caacedb113b4c9aa5f1f32433", "ref_doc_id": "586357"}, "8182a4f9-ad06-4f9c-b7bb-ed35c906a561": {"doc_hash": "312555720cecea3b445c8d1b66062156285e847c713c5044a12b0f262984bc33", "ref_doc_id": "586357"}, "55eb2b02-b8da-458d-92c5-81e7c707aaf3": {"doc_hash": "b26d8c3fa54e4aa4743aab8378c8c3e86db7ead2d0fc6db1d8353decab2cf899", "ref_doc_id": "586357"}, "6020b7f7-5892-4b47-9133-b2d8cc4da41b": {"doc_hash": "5b082c702a65624e0e85fb5aeb581848d2a56ed4cdee1009adf384df042d31cc", "ref_doc_id": "726659"}, "71156f56-bdea-427d-b8d2-6e4cbb90c821": {"doc_hash": "39fb6d37ae9cefac1fd50317ff33b9f527d3c4814cfd8567ebe1b8e33a42f02b", "ref_doc_id": "726659"}, "88c90ed4-92ac-42d5-b3dd-82b6ead7ed98": {"doc_hash": "f59ff68580575288bd00efb8020d40a5eece4db132a01f3563418f0076136ca2", "ref_doc_id": "726659"}, "85af1381-a703-4b44-87a9-ea69dbee7a1d": {"doc_hash": "2596496496cf3e4d336143d2fb6bc2d9ad44cad3b72cd3d0856060ecea1d7401", "ref_doc_id": "726659"}, "7f08f025-39b5-4bd9-abfe-bd27d2985975": {"doc_hash": "028a39594893e147f6555b989e562622fd6c62c28160f3ead7a3a17afa9463ee", "ref_doc_id": "726659"}, "5d9af55c-9d45-4243-b86e-a8f3d4e0d324": {"doc_hash": "666b1ff84d56108d0dd8f4aa4cccdbb19ebc26ff9687bb76b9acc40a9576812f", "ref_doc_id": "726659"}}, "docstore/ref_doc_info": {"1164": {"node_ids": ["c03f7ad5-ff51-4896-9a8c-95683963c654", "6da4fb61-9581-45e5-af32-bffd363db8cd", "f8255131-fd09-4fee-98d5-f3c677856163", "bab36993-1f2c-467b-a48f-2d76d349e462", "dac361c8-9f61-4ba4-b075-f5d4389295ca", "9ebeca90-ffa5-45db-ba03-e39ed2751154", "f6930d55-ee66-424b-82a6-941c359daf14", "63a9bdd0-7722-40df-ae9e-df7011ac1d4f", "ce96c984-6bb1-4d3f-ada1-2aa6035ebf59", "1014d9dc-9ae9-4dd1-ac14-0ada66e4a9ae", "f1900eb9-9794-4c79-9358-48a3619b395a", "a770c7d6-5fd8-43ca-930e-241f530884a9", "748bfbfe-c62e-4446-af81-ff84db352218", "d6ec0057-9df7-44c8-a9ac-fadef7b4c449", "582c2c70-e701-470b-85d3-692e9bf1d4dc", "b305739e-f2bd-401f-aecc-710ed8a1673d", "940a7ba9-7764-41b2-92a6-fcfac7e6e3a0", "d4f67fb4-9378-4832-bd9b-85d367e9cd28", "1eb737bb-e068-4b59-a724-cd3acea8f8bb", "e791a355-3211-4038-90d1-367802583262", "9ed57cc2-be4a-4bbb-83e4-c0584faf7c66", "d3ead8bc-b4a2-4d8b-abda-272b2327c406"], "metadata": {}}, "2894560": {"node_ids": ["bf5a447d-15e9-4ad8-a417-680587a46b11", "337000d0-3fe4-4aae-a2ae-d2dd68a65cbd", "06c55d0d-c5bc-4be0-b343-a1dadbe3c7f5", "a9f41060-c6a3-42c7-ae1a-6777970c67c4", "2ede79d6-a38d-4ad4-9072-14d7f6fa65bb", "e7cdee5d-f787-4990-b187-cef056780dbd", "a05374f6-a217-493a-91c9-70fdc6dfe087", "e832520c-2c13-4055-9a3e-4df1f765c0e9", "feb0aa40-8067-4bb4-8062-cae21a5c75f5", "e001d43a-dfc3-457c-a172-4baaa93b33a8", "16df7dc2-c5b0-4226-b2cb-ce8011e53851", "529e8857-e054-41cf-9d4b-b9b218b902a3", "c1073fb2-a12d-4dc1-8d1e-fe0e81452a49", "c5bc599c-4fed-4424-a581-e4084dc88cc6", "b5df004a-a492-45c4-944c-b32f65bf9718", "f6908e55-36e1-44b8-8a1c-0b61ecad8974", "923bdf78-1227-46a9-85a9-d41ddc0d73db", "dd3fb12f-097c-4110-9a61-c0e7ce834393", "a129138a-226b-42f0-8cd2-86553e5f67b4", "73686731-c8e5-4c7f-a269-37af8834d750", "d7499800-b881-43ce-8615-ac87576cbce3"], "metadata": {}}, "32472154": {"node_ids": ["5f2d015d-6bc6-4eac-9c23-a8127cb27636", "66331e57-f85d-468e-97a3-6f878fba0a9e", "5477aace-7847-4390-b5f8-466bbdf1a9ba", "fb6f1d2c-da47-4d18-b44f-f977de3f3d9a", "60be2bba-4bc5-431b-b48f-e8b47131c06e", "2be6c3c9-24d6-4339-8c8c-98b4b2bb7160", "d15b1341-804e-426b-97e0-a1d73328bd5e", "55807351-f087-4663-813f-0399077c90fe", "682470e6-b604-496c-bc21-bc958d9caf62", "f8b1ffb6-17c7-4339-af7b-899c4528a21e", "48cbff38-cf1e-4c6f-a74b-b271ac130d9a", "da74462b-7f92-4b30-a154-291d49d9b3a1", "ca4ed15b-8a74-45ad-8851-193a04db4413", "d8063aa9-302d-4bb7-a7cf-a3d3b2fdb83b"], "metadata": {}}, "40409788": {"node_ids": ["121b47e8-914a-432b-abf7-54c888e3dcaa", "981bb578-8268-41a2-b1ae-1b3cd02958f5", "af19dddc-cce4-4e87-a7fe-87d7a1cb1be2", "1c071c84-da1c-4646-904b-02c49ed0f7eb", "cee819b4-b95e-4f1a-99d9-6f7a657c53b7", "013e5c8a-180a-4426-ab64-ed043a254d99", "0f03deee-09fb-4d92-b6a6-678a329bb62d", "46f103c5-2e21-4651-a84a-0b458a4079ba", "8774cd75-2e0e-42df-b4d4-79367dc8e15d", "af625bcb-0af1-4f09-bfb0-b77e8b49f68b", "9de57a1a-7b2c-4662-9cdb-5e91ce43397d", "c74943a4-e7f6-4e6b-b251-f93e0db189e9", "7bdf5309-49ff-43e7-991c-33c2a0b8f862", "78698999-8539-4538-be6f-8bb7f9daa430", "4849d0ff-f29c-4600-8258-c409d146c621", "c765a06d-ca46-4e77-b968-4483510cfde3", "e6a296fc-77b4-427b-b8c3-8e0f34b82846"], "metadata": {}}, "61603971": {"node_ids": ["f9a50d00-f27b-4bd6-bc7d-d95bc4de8338", "0b86388c-beea-4223-9a0d-8c6d393bcd6b", "41a1debd-b938-4d7d-af6c-ca99cc5bcf15", "ef739916-d2e2-4fa3-bbd9-616865383e62", "ed38813f-0eac-452b-9117-cf0f44bbfff1", "a2aa3ec3-8598-4e55-a098-cec317d0cab9", "9409186e-9f01-4fb0-86bd-f865ae3e6168", "b54c2232-05ed-4379-b9dc-cb492fb32cfe", "49dcb929-2a70-4cb0-b822-727c29f95ef0", "724aa0bc-a5f6-455e-b58c-35e5096abcb8", "b5cc7826-8fdf-4f18-9690-6a0f6e9666d6", "634dea5a-efc4-43ea-955b-2abd4315cc9d", "f395caaf-43b5-49fd-a3f0-52adef4b24ed", "f066afd2-28bb-40db-970b-3396b82b1c81", "f285ebfe-fe9f-4e85-91a7-d61981c83929", "192fb953-5dfd-4cef-8bc9-d69e9c31cd7c", "2831b82a-0486-43d0-82d9-7a8c3fd34ffd", "5c7864b7-7e73-480b-abc7-0f32a4ba58b4", "c6f0df42-7971-4899-bc01-80df1d0d4437", "3425bb88-fbf3-41e6-bb0e-e155241c50bf", "b7ebef3e-57cc-4301-b2c9-15108895f961", "91b78da4-0ccc-4443-89f7-645288e44c7b", "5c93d5ff-3b43-42ed-a8db-75bd37d6fdfe", "ab6cd1e9-83bc-4498-92b8-213d423cee17", "6cbd51e0-9b2d-4a5e-b1bc-2d6e0ec5319b", "6c26c77c-b097-41f9-b8d1-08540ac7f52c", "8a2d42a2-89ee-4094-bfd5-0f2f3a9edce3", "cd60046a-9e9e-4e59-8541-1d83db84b525"], "metadata": {}}, "73248112": {"node_ids": ["f4a269b4-1563-4c1d-b21e-b2c486b4f642", "45e022bb-d543-418b-b178-99dd54dbd97d", "2133f949-5e6c-476c-93e9-b5b58babf676", "45165cf5-2f91-46e9-8120-e189da9c6856", "03ce6362-f4c2-4193-94bc-e8966b35b2a3", "48292cf3-781f-48ad-831b-16af86de6482", "9b1df2db-33cb-4735-9757-228b5f60da1f", "91fea428-64c5-4cd4-978d-5f6e0635a14c", "0fac1882-1fbc-4f88-b959-d6fd402c550b", "9724b494-75a9-4ac5-a1f3-ba33fbee793f", "23b46642-dd08-4d28-b562-845164885d3e", "2937669c-6ac1-45c9-a6a6-1bc2dcd6c894", "4b0905d6-dfce-4d93-8cbf-883a293511ad", "9b8dc498-61d1-4003-8a80-5f3b2462142b"], "metadata": {}}, "586357": {"node_ids": ["3d9ed974-5b0d-4623-b0e8-ce03b4e082b6", "7b447c0d-5a60-405a-bcfe-c6ed26cc5338", "bdfcbf9a-0817-422c-825b-51877467fd14", "b04524bc-6796-4c4c-a4cd-7f0e8fcf2ac4", "0eda3fc6-d5e3-4190-b3c3-0af70b6748e7", "9dd44733-c265-4329-99e6-4e254d3a6553", "6ceb34b9-66c3-4a86-9459-4f33b1a50d7f", "10798049-51e8-480a-a388-00fad2912bd8", "8ff03e25-071c-404f-99d4-4824afdbd881", "b277bf26-e080-4d95-9088-b9c69407f85d", "8182a4f9-ad06-4f9c-b7bb-ed35c906a561", "55eb2b02-b8da-458d-92c5-81e7c707aaf3"], "metadata": {}}, "726659": {"node_ids": ["6020b7f7-5892-4b47-9133-b2d8cc4da41b", "71156f56-bdea-427d-b8d2-6e4cbb90c821", "88c90ed4-92ac-42d5-b3dd-82b6ead7ed98", "85af1381-a703-4b44-87a9-ea69dbee7a1d", "7f08f025-39b5-4bd9-abfe-bd27d2985975", "5d9af55c-9d45-4243-b86e-a8f3d4e0d324"], "metadata": {}}}, "docstore/data": {"c03f7ad5-ff51-4896-9a8c-95683963c654": {"__data__": {"id_": "c03f7ad5-ff51-4896-9a8c-95683963c654", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "f7d89d37b65b972cacfc270c355208a838fdb4a4e05772c89023bfcd0917947d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6da4fb61-9581-45e5-af32-bffd363db8cd", "node_type": "1", "metadata": {}, "hash": "2d8ba8a05a669f3b5aee510c60a31f0e89dd099e2f0fdd3c307da7c5f1939b70", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.\nHigh-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., language models and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"\nVarious subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields. Some companies, such as OpenAI, Google DeepMind and Meta, aim to create artificial general intelligence (AGI)\u2014AI that can complete virtually any cognitive task at least as well as a human.\nArtificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism throughout its history, followed by periods of disappointment and loss of funding, known as AI winters. Funding and interest vastly increased after 2012 when graphics processing units started being used to accelerate neural networks and deep learning outperformed previous AI techniques. This growth accelerated further after 2017 with the transformer architecture. In the 2020s, an ongoing period of rapid progress in advanced generative AI became known as the AI boom. Generative AI's ability to create and modify content has led to several unintended consequences and harms, while raising ethical concerns about AI's long-term effects and potential existential risks, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\n\n\n== Goals ==\nThe general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.\n\n\n=== Reasoning and problem-solving ===\nEarly researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions. By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics.\nMany of these algorithms are insufficient for solving large reasoning problems because they experience a \"combinatorial explosion\": They become exponentially slower as the problems grow. Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments. Accurate and efficient reasoning is an unsolved problem.\n\n\n=== Knowledge representation ===\n\nKnowledge representation and knowledge engineering allow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval, scene interpretation, clinical decision support, knowledge discovery (mining \"interesting\" and actionable inferences from large databases), and other areas.\nA knowledge base is a body of knowledge represented in a form that can be used by a program. An ontology is the set of objects, relations, concepts, and properties used by a particular domain of knowledge. Knowledge bases need to represent things such as objects, properties, categories, and relations between objects; situations, events, states, and time; causes and effects; knowledge about knowledge (what we know about what other people know); default reasoning (things that humans assume are true until they are told differently and will remain true even when other facts are changing); and many other aspects and domains of knowledge.\nAmong the most difficult problems in knowledge representation are the breadth of commonsense knowledge (the set of atomic facts that the average person knows is enormous); and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as \"facts\" or \"statements\" that they could express verbally). There is also the difficulty of knowledge acquisition, the problem of obtaining knowledge for AI applications.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 5358, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6da4fb61-9581-45e5-af32-bffd363db8cd": {"__data__": {"id_": "6da4fb61-9581-45e5-af32-bffd363db8cd", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "f7d89d37b65b972cacfc270c355208a838fdb4a4e05772c89023bfcd0917947d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c03f7ad5-ff51-4896-9a8c-95683963c654", "node_type": "1", "metadata": {}, "hash": "b6e429dd2057f2880a69a43bce5f6c1e40f9aa784c054e4980402537f27b68f6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f8255131-fd09-4fee-98d5-f3c677856163", "node_type": "1", "metadata": {}, "hash": "809179e80ff050502d1cc8051f08f0ab2708e1f50dc30d37842e511f047f17b7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Planning and decision-making ===\nAn \"agent\" is anything that perceives and takes actions in the world. A rational agent has goals or preferences and takes actions to make them happen. In automated planning, the agent has a specific goal. In automated decision-making, the agent has preferences\u2014there are some situations it would prefer to be in, and some situations it is trying to avoid. The decision-making agent assigns a number to each situation (called the \"utility\") that measures how much the agent prefers it. For each possible action, it can calculate the \"expected utility\": the utility of all possible outcomes of the action, weighted by the probability that the outcome will occur. It can then choose the action with the maximum expected utility.\nIn classical planning, the agent knows exactly what the effect of any action will be. In most real-world problems, however, the agent may not be certain about the situation they are in (it is \"unknown\" or \"unobservable\") and it may not know for certain what will happen after each possible action (it is not \"deterministic\"). It must choose an action by making a probabilistic guess and then reassess the situation to see if the action worked.\nIn some problems, the agent's preferences may be uncertain, especially if there are other agents or humans involved. These can be learned (e.g., with inverse reinforcement learning), or the agent can seek information to improve its preferences. Information value theory can be used to weigh the value of exploratory or experimental actions. The space of possible future actions and situations is typically intractably large, so the agents must take actions and evaluate situations while being uncertain of what the outcome will be.\nA Markov decision process has a transition model that describes the probability that a particular action will change the state in a particular way and a reward function that supplies the utility of each state and the cost of each action. A policy associates a decision with each possible state. The policy could be calculated (e.g., by iteration), be heuristic, or it can be learned.\nGame theory describes the rational behavior of multiple interacting agents and is used in AI programs that make decisions that involve other agents.\n\n\n=== Learning ===\nMachine learning is the study of programs that can improve their performance on a given task automatically. It has been a part of AI from the beginning.\n\nThere are several kinds of machine learning. Unsupervised learning analyzes a stream of data and finds patterns and makes predictions without any other guidance. Supervised learning requires labeling the training data with the expected answers, and comes in two main varieties: classification (where the program must learn to predict what category the input belongs in) and regression (where the program must deduce a numeric function based on numeric input).\nIn reinforcement learning, the agent is rewarded for good responses and punished for bad ones. The agent learns to choose responses that are classified as \"good\". Transfer learning is when the knowledge gained from one problem is applied to a new problem. Deep learning is a type of machine learning that runs inputs through biologically inspired artificial neural networks for all of these types of learning.\nComputational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization.\n\n\n=== Natural language processing ===\nNatural language processing (NLP) allows programs to read, write and communicate in human languages. Specific problems include speech recognition, speech synthesis, machine translation, information extraction, information retrieval and question answering.\nEarly work, based on Noam Chomsky's generative grammar and semantic networks, had difficulty with word-sense disambiguation unless restricted to small domains called \"micro-worlds\" (due to the common sense knowledge problem). Margaret Masterman believed that it was meaning and not grammar that was the key to understanding languages, and that thesauri and not dictionaries should be the basis of computational language structure.\nModern deep learning techniques for NLP include word embedding (representing words, typically as vectors encoding their meaning), transformers (a deep learning architecture using an attention mechanism), and others. In 2019, generative pre-trained transformer (or \"GPT\") language models began to generate coherent text, and by 2023, these models were able to get human-level scores on the bar exam, SAT test, GRE test, and many other real-world applications.\n\n\n=== Perception ===\nMachine perception is the ability to use input from sensors (such as cameras, microphones, wireless signals, active lidar, sonar, radar, and tactile sensors) to deduce aspects of the world. Computer vision is the ability to analyze visual input.\nThe field includes speech recognition, image classification, facial recognition, object recognition, object tracking, and robotic perception.", "mimetype": "text/plain", "start_char_idx": 5361, "end_char_idx": 10434, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f8255131-fd09-4fee-98d5-f3c677856163": {"__data__": {"id_": "f8255131-fd09-4fee-98d5-f3c677856163", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "f7d89d37b65b972cacfc270c355208a838fdb4a4e05772c89023bfcd0917947d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6da4fb61-9581-45e5-af32-bffd363db8cd", "node_type": "1", "metadata": {}, "hash": "2d8ba8a05a669f3b5aee510c60a31f0e89dd099e2f0fdd3c307da7c5f1939b70", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bab36993-1f2c-467b-a48f-2d76d349e462", "node_type": "1", "metadata": {}, "hash": "d25119c20c44c8c3dd6cd5488af1f1aa23f7c1a7ad49ee6aade2878fbcff4c9f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Perception ===\nMachine perception is the ability to use input from sensors (such as cameras, microphones, wireless signals, active lidar, sonar, radar, and tactile sensors) to deduce aspects of the world. Computer vision is the ability to analyze visual input.\nThe field includes speech recognition, image classification, facial recognition, object recognition, object tracking, and robotic perception.\n\n\n=== Social intelligence ===\n\nAffective computing is a field that comprises systems that recognize, interpret, process, or simulate human feeling, emotion, and mood. For example, some virtual assistants are programmed to speak conversationally or even to banter humorously; it makes them appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate human\u2013computer interaction.\nHowever, this tends to give na\u00efve users an unrealistic conception of the intelligence of existing computer agents. Moderate successes related to affective computing include textual sentiment analysis and, more recently, multimodal sentiment analysis, wherein AI classifies the effects displayed by a videotaped subject.\n\n\n=== General intelligence ===\nA machine with artificial general intelligence would be able to solve a wide variety of problems with breadth and versatility similar to human intelligence.\n\n\n== Techniques ==\nAI research uses a wide variety of techniques to accomplish the goals above.\n\n\n=== Search and optimization ===\nAI can solve many problems by intelligently searching through many possible solutions. There are two very different kinds of search used in AI: state space search and local search.\n\n\n==== State space search ====\nState space search searches through a tree of possible states to try to find a goal state. For example, planning algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called means-ends analysis.\nSimple exhaustive searches are rarely sufficient for most real-world problems: the search space (the number of places to search) quickly grows to astronomical numbers. The result is a search that is too slow or never completes. \"Heuristics\" or \"rules of thumb\" can help prioritize choices that are more likely to reach a goal.\nAdversarial search is used for game-playing programs, such as chess or Go. It searches through a tree of possible moves and countermoves, looking for a winning position.\n\n\n==== Local search ====\n Local search uses mathematical optimization to find a solution to a problem. It begins with some form of guess and refines it incrementally.\nGradient descent is a type of local search that optimizes a set of numerical parameters by incrementally adjusting them to minimize a loss function. Variants of gradient descent are commonly used to train neural networks, through the backpropagation algorithm.\nAnother type of local search is evolutionary computation, which aims to iteratively improve a set of candidate solutions by \"mutating\" and \"recombining\" them, selecting only the fittest to survive each generation.\nDistributed search processes can coordinate via swarm intelligence algorithms. Two popular swarm algorithms used in search are particle swarm optimization (inspired by bird flocking) and ant colony optimization (inspired by ant trails).\n\n\n=== Logic ===\nFormal logic is used for reasoning and knowledge representation.\nFormal logic comes in two main forms: propositional logic (which operates on statements that are true or false and uses logical connectives such as \"and\", \"or\", \"not\" and \"implies\") and predicate logic (which also operates on objects, predicates and relations and uses quantifiers such as \"Every X is a Y\" and \"There are some Xs that are Ys\").\nDeductive reasoning in logic is the process of proving a new statement (conclusion) from other statements that are given and assumed to be true (the premises). Proofs can be structured as proof trees, in which nodes are labelled by sentences, and children nodes are connected to parent nodes by inference rules.\nGiven a problem and a set of premises, problem-solving reduces to searching for a proof tree whose root node is labelled by a solution of the problem and whose leaf nodes are labelled by premises or axioms. In the case of Horn clauses, problem-solving search can be performed by reasoning forwards from the premises or backwards from the problem. In the more general case of the clausal form of first-order logic, resolution is a single, axiom-free rule of inference, in which a problem is solved by proving a contradiction from premises that include the negation of the problem to be solved.\nInference in both Horn clause logic and first-order logic is undecidable, and therefore intractable. However, backward reasoning with Horn clauses, which underpins computation in the logic programming language Prolog, is Turing complete. Moreover, its efficiency is competitive with computation in other symbolic programming languages.\nFuzzy logic assigns a \"degree of truth\" between 0 and 1. It can therefore handle propositions that are vague and partially true.\nNon-monotonic logics, including logic programming with negation as failure, are designed to handle default reasoning. Other specialized versions of logic have been developed to describe many complex domains.", "mimetype": "text/plain", "start_char_idx": 10028, "end_char_idx": 15327, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bab36993-1f2c-467b-a48f-2d76d349e462": {"__data__": {"id_": "bab36993-1f2c-467b-a48f-2d76d349e462", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "f7d89d37b65b972cacfc270c355208a838fdb4a4e05772c89023bfcd0917947d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f8255131-fd09-4fee-98d5-f3c677856163", "node_type": "1", "metadata": {}, "hash": "809179e80ff050502d1cc8051f08f0ab2708e1f50dc30d37842e511f047f17b7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "dac361c8-9f61-4ba4-b075-f5d4389295ca", "node_type": "1", "metadata": {}, "hash": "a5f995670d84d48c5c4e3d4fa68f85e00bb7b405ea5af4ba524969eaaa7d1c79", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Probabilistic methods for uncertain reasoning ===\n\nMany problems in AI (including reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of tools to solve these problems using methods from probability theory and economics. Precise mathematical tools have been developed that analyze how an agent can make choices and plan, using decision theory, decision analysis, and information value theory. These tools include models such as Markov decision processes, dynamic decision networks, game theory and mechanism design.\nBayesian networks are a tool that can be used for reasoning (using the Bayesian inference algorithm), learning (using the expectation\u2013maximization algorithm), planning (using decision networks) and perception (using dynamic Bayesian networks).\nProbabilistic algorithms can also be used for filtering, prediction, smoothing, and finding explanations for streams of data, thus helping perception systems analyze processes that occur over time (e.g., hidden Markov models or Kalman filters).\n\n\n=== Classifiers and statistical learning methods ===\nThe simplest AI applications can be divided into two types: classifiers (e.g., \"if shiny then diamond\"), on one hand, and controllers (e.g., \"if diamond then pick up\"), on the other hand. Classifiers are functions that use pattern matching to determine the closest match. They can be fine-tuned based on chosen examples using supervised learning. Each pattern (also called an \"observation\") is labeled with a certain predefined class. All the observations combined with their class labels are known as a data set. When a new observation is received, that observation is classified based on previous experience.\nThere are many kinds of classifiers in use. The decision tree is the simplest and most widely used symbolic machine learning algorithm. K-nearest neighbor algorithm was the most widely used analogical AI until the mid-1990s, and Kernel methods such as the support vector machine (SVM) displaced k-nearest neighbor in the 1990s.\nThe naive Bayes classifier is reportedly the \"most widely used learner\" at Google, due in part to its scalability.\nNeural networks are also used as classifiers.\n\n\n=== Artificial neural networks ===\n\nAn artificial neural network is based on a collection of nodes also known as artificial neurons, which loosely model the neurons in a biological brain. It is trained to recognise patterns; once trained, it can recognise those patterns in fresh data. There is an input, at least one hidden layer of nodes and an output. Each node applies a function and once the weight crosses its specified threshold, the data is transmitted to the next layer. A network is typically called a deep neural network if it has at least 2 hidden layers.\nLearning algorithms for neural networks use local search to choose the weights that will get the right output for each input during training. The most common training technique is the backpropagation algorithm. Neural networks learn to model complex relationships between inputs and outputs and find patterns in data. In theory, a neural network can learn any function.\nIn feedforward neural networks the signal passes in only one direction. Recurrent neural networks feed the output signal back into the input, which allows short-term memories of previous input events. Long short term memory is the most successful architecture for recurrent neural networks. Perceptrons use only a single layer of neurons; deep learning uses multiple layers. Convolutional neural networks strengthen the connection between neurons that are \"close\" to each other\u2014this is especially important in image processing, where a local set of neurons must identify an \"edge\" before the network can identify an object.\n\n\n=== Deep learning ===\n\nDeep learning uses several layers of neurons between the network's inputs and outputs. The multiple layers can progressively extract higher-level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits, letters, or faces.\nDeep learning has profoundly improved the performance of programs in many important subfields of artificial intelligence, including computer vision, speech recognition, natural language processing, image classification, and others. The reason that deep learning performs so well in so many applications is not known as of 2021. The sudden success of deep learning in 2012\u20132015 did not occur because of some new discovery or theoretical breakthrough (deep neural networks and backpropagation had been described by many people, as far back as the 1950s) but because of two factors: the incredible increase in computer power (including the hundred-fold increase in speed by switching to GPUs) and the availability of vast amounts of training data, especially the giant curated datasets used for benchmark testing, such as ImageNet.", "mimetype": "text/plain", "start_char_idx": 15330, "end_char_idx": 20366, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "dac361c8-9f61-4ba4-b075-f5d4389295ca": {"__data__": {"id_": "dac361c8-9f61-4ba4-b075-f5d4389295ca", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "f7d89d37b65b972cacfc270c355208a838fdb4a4e05772c89023bfcd0917947d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bab36993-1f2c-467b-a48f-2d76d349e462", "node_type": "1", "metadata": {}, "hash": "d25119c20c44c8c3dd6cd5488af1f1aa23f7c1a7ad49ee6aade2878fbcff4c9f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9ebeca90-ffa5-45db-ba03-e39ed2751154", "node_type": "1", "metadata": {}, "hash": "281e36f21da11259ff60e1443782179572613d9bcdf293d9c09124f391de14ff", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== GPT ===\nGenerative pre-trained transformers (GPT) are large language models (LLMs) that generate text based on the semantic relationships between words in sentences. Text-based GPT models are pre-trained on a large corpus of text that can be from the Internet. The pretraining consists of predicting the next token (a token being usually a word, subword, or punctuation). Throughout this pretraining, GPT models accumulate knowledge about the world and can then generate human-like text by repeatedly predicting the next token. Typically, a subsequent training phase makes the model more truthful, useful, and harmless, usually with a technique called reinforcement learning from human feedback (RLHF). Current GPT models are prone to generating falsehoods called \"hallucinations\". These can be reduced with RLHF and quality data, but the problem has been getting worse for reasoning systems. Such systems are used in chatbots, which allow people to ask a question or request a task in simple text.\nCurrent models and services include ChatGPT, Claude, Gemini, Copilot, and Meta AI. Multimodal GPT models can process different types of data (modalities) such as images, videos, sound, and text.\n\n\n=== Hardware and software ===\n\nIn the late 2010s, graphics processing units (GPUs) that were increasingly designed with AI-specific enhancements and used with specialized TensorFlow software had replaced previously used central processing unit (CPUs) as the dominant means for large-scale (commercial and academic) machine learning models' training. Specialized programming languages such as Prolog were used in early AI research, but general-purpose programming languages like Python have become predominant.\nThe transistor density in integrated circuits has been observed to roughly double every 18 months\u2014a trend known as Moore's law, named after the Intel co-founder Gordon Moore, who first identified it. Improvements in GPUs have been even faster, a trend sometimes called Huang's law, named after Nvidia co-founder and CEO Jensen Huang.\n\n\n== Applications ==\nAI and machine learning technology is used in most of the essential applications of the 2020s, including: search engines (such as Google Search), targeting online advertisements, recommendation systems (offered by Netflix, YouTube or Amazon), driving internet traffic, targeted advertising (AdSense, Facebook), virtual assistants (such as Siri or Alexa), autonomous vehicles (including drones, ADAS and self-driving cars), automatic language translation (Microsoft Translator, Google Translate), facial recognition (Apple's FaceID or Microsoft's DeepFace and Google's FaceNet) and image labeling (used by Facebook, Apple's Photos and TikTok). The deployment of AI may be overseen by a chief automation officer (CAO).\n\n\n=== Health and medicine ===\n\nThe application of AI in medicine and medical research has the potential to increase patient care and quality of life. Through the lens of the Hippocratic Oath, medical professionals are ethically compelled to use AI, if applications can more accurately diagnose and treat patients.\nFor medical research, AI is an important tool for processing and integrating big data. This is particularly important for organoid and tissue engineering development which use microscopy imaging as a key technique in fabrication. It has been suggested that AI can overcome discrepancies in funding allocated to different fields of research. New AI tools can deepen the understanding of biomedically relevant pathways. For example, AlphaFold 2 (2021) demonstrated the ability to approximate, in hours rather than months, the 3D structure of a protein. In 2023, it was reported that AI-guided drug discovery helped find a class of antibiotics capable of killing two different types of drug-resistant bacteria. In 2024, researchers used machine learning to accelerate the search for Parkinson's disease drug treatments. Their aim was to identify compounds that block the clumping, or aggregation, of alpha-synuclein (the protein that characterises Parkinson's disease). They were able to speed up the initial screening process ten-fold and reduce the cost by a thousand-fold.", "mimetype": "text/plain", "start_char_idx": 20369, "end_char_idx": 24537, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9ebeca90-ffa5-45db-ba03-e39ed2751154": {"__data__": {"id_": "9ebeca90-ffa5-45db-ba03-e39ed2751154", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "f7d89d37b65b972cacfc270c355208a838fdb4a4e05772c89023bfcd0917947d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "dac361c8-9f61-4ba4-b075-f5d4389295ca", "node_type": "1", "metadata": {}, "hash": "a5f995670d84d48c5c4e3d4fa68f85e00bb7b405ea5af4ba524969eaaa7d1c79", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f6930d55-ee66-424b-82a6-941c359daf14", "node_type": "1", "metadata": {}, "hash": "4c2937c60468eadf27fc3cd2e91056881a10985c354ae19039f62dfdcdc77098", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Games ===\n\nGame playing programs have been used since the 1950s to demonstrate and test AI's most advanced techniques. Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov, on 11 May 1997. In 2011, in a Jeopardy! quiz show exhibition match, IBM's question answering system, Watson, defeated the two greatest Jeopardy! champions, Brad Rutter and Ken Jennings, by a significant margin. In March 2016, AlphaGo won 4 out of 5 games of Go in a match with Go champion Lee Sedol, becoming the first computer Go-playing system to beat a professional Go player without handicaps. Then, in 2017, it defeated Ke Jie, who was the best Go player in the world. Other programs handle imperfect-information games, such as the poker-playing program Pluribus. DeepMind developed increasingly generalistic reinforcement learning models, such as with MuZero, which could be trained to play chess, Go, or Atari games. In 2019, DeepMind's AlphaStar achieved grandmaster level in StarCraft II, a particularly challenging real-time strategy game that involves incomplete knowledge of what happens on the map. In 2021, an AI agent competed in a PlayStation Gran Turismo competition, winning against four of the world's best Gran Turismo drivers using deep reinforcement learning. In 2024, Google DeepMind introduced SIMA, a type of AI capable of autonomously playing nine previously unseen open-world video games by observing screen output, as well as executing short, specific tasks in response to natural language instructions.\n\n\n=== Mathematics ===\nLarge language models, such as GPT-4, Gemini, Claude, Llama or Mistral, are increasingly used in mathematics. These probabilistic models are versatile, but can also produce wrong answers in the form of hallucinations. They sometimes need a large database of mathematical problems to learn from, but also methods such as supervised fine-tuning or trained classifiers with human-annotated data to improve answers for new problems and learn from corrections. A February 2024 study showed that the performance of some language models for reasoning capabilities in solving math problems not included in their training data was low, even for problems with only minor deviations from trained data. One technique to improve their performance involves training the models to produce correct reasoning steps, rather than just the correct result. The Alibaba Group developed a version of its Qwen models called Qwen2-Math, that achieved state-of-the-art performance on several mathematical benchmarks, including 84% accuracy on the MATH dataset of competition mathematics problems. In January 2025, Microsoft proposed the technique rStar-Math that leverages Monte Carlo tree search and step-by-step reasoning, enabling a relatively small language model like Qwen-7B to solve 53% of the AIME 2024 and 90% of the MATH benchmark problems.\nAlternatively, dedicated models for mathematical problem solving with higher precision for the outcome including proof of theorems have been developed such as AlphaTensor, AlphaGeometry, AlphaProof and AlphaEvolve all from Google DeepMind, Llemma from EleutherAI or Julius.\nWhen natural language is used to describe mathematical problems, converters can transform such prompts into a formal language such as Lean to define mathematical tasks.\nSome models have been developed to solve challenging problems and reach good results in benchmark tests, others to serve as educational tools in mathematics.\nTopological deep learning integrates various topological approaches.\n\n\n=== Finance ===\nFinance is one of the fastest growing sectors where applied AI tools are being deployed: from retail online banking to investment advice and insurance, where automated \"robot advisers\" have been in use for some years.\nAccording to Nicolas Firzli, director of the World Pensions & Investments Forum, it may be too early to see the emergence of highly innovative AI-informed financial products and services. He argues that \"the deployment of AI tools will simply further automatise things: destroying tens of thousands of jobs in banking, financial planning, and pension advice in the process, but I'm not sure it will unleash a new wave of [e.g., sophisticated] pension innovation.\"\n\n\n=== Military ===\n\nVarious countries are deploying AI military applications. The main applications enhance command and control, communications, sensors, integration and interoperability. Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous and autonomous vehicles. AI technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions, target acquisition, coordination and deconfliction of distributed Joint Fires between networked combat vehicles, both human-operated and autonomous.\nAI has been used in military operations in Iraq, Syria, Israel and Ukraine.\n\n\n=== Generative AI ===", "mimetype": "text/plain", "start_char_idx": 24540, "end_char_idx": 29546, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f6930d55-ee66-424b-82a6-941c359daf14": {"__data__": {"id_": "f6930d55-ee66-424b-82a6-941c359daf14", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "f7d89d37b65b972cacfc270c355208a838fdb4a4e05772c89023bfcd0917947d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9ebeca90-ffa5-45db-ba03-e39ed2751154", "node_type": "1", "metadata": {}, "hash": "281e36f21da11259ff60e1443782179572613d9bcdf293d9c09124f391de14ff", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "63a9bdd0-7722-40df-ae9e-df7011ac1d4f", "node_type": "1", "metadata": {}, "hash": "572bebce70a54a709deba05a60b7be6bded186199501335075633dd269e281f2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Military ===\n\nVarious countries are deploying AI military applications. The main applications enhance command and control, communications, sensors, integration and interoperability. Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous and autonomous vehicles. AI technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions, target acquisition, coordination and deconfliction of distributed Joint Fires between networked combat vehicles, both human-operated and autonomous.\nAI has been used in military operations in Iraq, Syria, Israel and Ukraine.\n\n\n=== Generative AI ===\n\n\n=== Agents ===\n\nAI agents are software entities designed to perceive their environment, make decisions, and take actions autonomously to achieve specific goals. These agents can interact with users, their environment, or other agents. AI agents are used in various applications, including virtual assistants, chatbots, autonomous vehicles, game-playing systems, and industrial robotics. AI agents operate within the constraints of their programming, available computational resources, and hardware limitations. This means they are restricted to performing tasks within their defined scope and have finite memory and processing capabilities. In real-world applications, AI agents often face time constraints for decision-making and action execution. Many AI agents incorporate learning algorithms, enabling them to improve their performance over time through experience or training. Using machine learning, AI agents can adapt to new situations and optimise their behaviour for their designated tasks.\n\n\n=== Sexuality ===\nApplications of AI in this domain include AI-enabled menstruation and fertility trackers that analyze user data to offer predictions, AI-integrated sex toys (e.g., teledildonics), AI-generated sexual education content, and AI agents that simulate sexual and romantic partners (e.g., Replika).  AI is also used for the production of non-consensual deepfake pornography, raising significant ethical and legal concerns.\nAI technologies have also been used to attempt to identify online gender-based violence and online sexual grooming of minors.\n\n\n=== Other industry-specific tasks ===\nThere are also thousands of successful AI applications used to solve specific problems for specific industries or institutions. In a 2017 survey, one in five companies reported having incorporated \"AI\" in some offerings or processes. A few examples are energy storage, medical diagnosis, military logistics, applications that predict the result of judicial decisions, foreign policy, or supply chain management.\nAI applications for evacuation and disaster management are growing. AI has been used to investigate patterns in large-scale and small-scale evacuations using historical data from GPS, videos or social media. Furthermore, AI can provide real-time information on the evacuation conditions.\nIn agriculture, AI has helped farmers to increase yield and identify areas that need irrigation, fertilization, pesticide treatments. Agronomists use AI to conduct research and development. AI has been used to predict the ripening time for crops such as tomatoes, monitor soil moisture, operate agricultural robots, conduct predictive analytics, classify livestock pig call emotions, automate greenhouses, detect diseases and pests, and save water.\nArtificial intelligence is used in astronomy to analyze increasing amounts of available data and applications, mainly for \"classification, regression, clustering, forecasting, generation, discovery, and the development of new scientific insights.\" For example, it is used for discovering exoplanets, forecasting solar activity, and distinguishing between signals and instrumental effects in gravitational wave astronomy. Additionally, it could be used for activities in space, such as space exploration, including the analysis of data from space missions, real-time science decisions of spacecraft, space debris avoidance, and more autonomous operation.\nDuring the 2024 Indian elections, US$50 million was spent on authorized AI-generated content, notably by creating deepfakes of allied (including sometimes deceased) politicians to better engage with voters, and by translating speeches to various local languages.\n\n\n== Ethics ==\n\nAI has potential benefits and potential risks. AI may be able to advance science and find solutions for serious problems: Demis Hassabis of DeepMind hopes to \"solve intelligence, and then use that to solve everything else\". However, as the use of AI has become widespread, several unintended consequences and risks have been identified. In-production systems can sometimes not factor ethics and bias into their AI training processes, especially when the AI algorithms are inherently unexplainable in deep learning.\n\n\n=== Risks and harm ===", "mimetype": "text/plain", "start_char_idx": 28828, "end_char_idx": 33774, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "63a9bdd0-7722-40df-ae9e-df7011ac1d4f": {"__data__": {"id_": "63a9bdd0-7722-40df-ae9e-df7011ac1d4f", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "f7d89d37b65b972cacfc270c355208a838fdb4a4e05772c89023bfcd0917947d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f6930d55-ee66-424b-82a6-941c359daf14", "node_type": "1", "metadata": {}, "hash": "4c2937c60468eadf27fc3cd2e91056881a10985c354ae19039f62dfdcdc77098", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ce96c984-6bb1-4d3f-ada1-2aa6035ebf59", "node_type": "1", "metadata": {}, "hash": "3a4d82c02400a437d3713186697c03c3eaba2693b712a12824e55172fde11532", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Ethics ==\n\nAI has potential benefits and potential risks. AI may be able to advance science and find solutions for serious problems: Demis Hassabis of DeepMind hopes to \"solve intelligence, and then use that to solve everything else\". However, as the use of AI has become widespread, several unintended consequences and risks have been identified. In-production systems can sometimes not factor ethics and bias into their AI training processes, especially when the AI algorithms are inherently unexplainable in deep learning.\n\n\n=== Risks and harm ===\n\n\n==== Privacy and copyright ====\n\nMachine learning algorithms require large amounts of data. The techniques used to acquire this data have raised concerns about privacy, surveillance and copyright.\nAI-powered devices and services, such as virtual assistants and IoT products, continuously collect personal information, raising concerns about intrusive data gathering and unauthorized access by third parties. The loss of privacy is further exacerbated by AI's ability to process and combine vast amounts of data, potentially leading to a surveillance society where individual activities are constantly monitored and analyzed without adequate safeguards or transparency.\nSensitive user data collected may include online activity records, geolocation data, video, or audio. For example, in order to build speech recognition algorithms, Amazon has recorded millions of private conversations and allowed temporary workers to listen to and transcribe some of them. Opinions about this widespread surveillance range from those who see it as a necessary evil to those for whom it is clearly unethical and a violation of the right to privacy.\nAI developers argue that this is the only way to deliver valuable applications and have developed several techniques that attempt to preserve privacy while still obtaining the data, such as data aggregation, de-identification and differential privacy. Since 2016, some privacy experts, such as Cynthia Dwork, have begun to view privacy in terms of fairness. Brian Christian wrote that experts have pivoted \"from the question of 'what they know' to the question of 'what they're doing with it'.\"\nGenerative AI is often trained on unlicensed copyrighted works, including in domains such as images or computer code; the output is then used under the rationale of \"fair use\". Experts disagree about how well and under what circumstances this rationale will hold up in courts of law; relevant factors may include \"the purpose and character of the use of the copyrighted work\" and \"the effect upon the potential market for the copyrighted work\". Website owners who do not wish to have their content scraped can indicate it in a \"robots.txt\" file. In 2023, leading authors (including John Grisham and Jonathan Franzen) sued AI companies for using their work to train generative AI. Another discussed approach is to envision a separate sui generis system of protection for creations generated by AI to ensure fair attribution and compensation for human authors.\n\n\n==== Dominance by tech giants ====\nThe commercial AI scene is dominated by Big Tech companies such as Alphabet Inc., Amazon, Apple Inc., Meta Platforms, and Microsoft. Some of these players already own the vast majority of existing cloud infrastructure and computing power from data centers, allowing them to entrench further in the marketplace.\n\n\n==== Power needs and environmental impacts ====\n\nIn January 2024, the International Energy Agency (IEA) released Electricity 2024, Analysis and Forecast to 2026, forecasting electric power use. This is the first IEA report to make projections for data centers and power consumption for artificial intelligence and cryptocurrency. The report states that power demand for these uses might double by 2026, with additional electric power usage equal to electricity used by the whole Japanese nation.\nProdigious power consumption by AI is responsible for the growth of fossil fuel use, and might delay closings of obsolete, carbon-emitting coal energy facilities. There is a feverish rise in the construction of data centers throughout the US, making large technology firms (e.g., Microsoft, Meta, Google, Amazon) into voracious consumers of electric power. Projected electric consumption is so immense that there is concern that it will be fulfilled no matter the source. A ChatGPT search involves the use of 10 times the electrical energy as a Google search. The large firms are in haste to find power sources \u2013 from nuclear energy to geothermal to fusion. The tech firms argue that \u2013 in the long view \u2013 AI will be eventually kinder to the environment, but they need the energy now. AI makes the power grid more efficient and \"intelligent\", will assist in the growth of nuclear power, and track overall carbon emissions, according to technology firms.\nA 2024 Goldman Sachs Research Paper, AI Data Centers and the Coming US Power Demand Surge, found \"US power demand (is) likely to experience growth not seen in a generation....\" and forecasts that, by 2030, US data centers will consume 8% of US power, as opposed to 3% in 2022, presaging growth for the electrical power generation industry by a variety of means.", "mimetype": "text/plain", "start_char_idx": 33221, "end_char_idx": 38425, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ce96c984-6bb1-4d3f-ada1-2aa6035ebf59": {"__data__": {"id_": "ce96c984-6bb1-4d3f-ada1-2aa6035ebf59", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "f7d89d37b65b972cacfc270c355208a838fdb4a4e05772c89023bfcd0917947d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "63a9bdd0-7722-40df-ae9e-df7011ac1d4f", "node_type": "1", "metadata": {}, "hash": "572bebce70a54a709deba05a60b7be6bded186199501335075633dd269e281f2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1014d9dc-9ae9-4dd1-ac14-0ada66e4a9ae", "node_type": "1", "metadata": {}, "hash": "b5dbd1384a94b93bd48bee9750710e49b012773ab43262065e76924e530dccee", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "A ChatGPT search involves the use of 10 times the electrical energy as a Google search. The large firms are in haste to find power sources \u2013 from nuclear energy to geothermal to fusion. The tech firms argue that \u2013 in the long view \u2013 AI will be eventually kinder to the environment, but they need the energy now. AI makes the power grid more efficient and \"intelligent\", will assist in the growth of nuclear power, and track overall carbon emissions, according to technology firms.\nA 2024 Goldman Sachs Research Paper, AI Data Centers and the Coming US Power Demand Surge, found \"US power demand (is) likely to experience growth not seen in a generation....\" and forecasts that, by 2030, US data centers will consume 8% of US power, as opposed to 3% in 2022, presaging growth for the electrical power generation industry by a variety of means. Data centers' need for more and more electrical power is such that they might max out the electrical grid. The Big Tech companies counter that AI can be used to maximize the utilization of the grid by all.\nIn 2024, the Wall Street Journal reported that big AI companies have begun negotiations with the US nuclear power providers to provide electricity to the data centers. In March 2024 Amazon purchased a Pennsylvania nuclear-powered data center for US$650 million. Nvidia CEO Jensen Huang said nuclear power is a good option for the data centers.\nIn September 2024, Microsoft announced an agreement with Constellation Energy to re-open the Three Mile Island nuclear power plant to provide Microsoft with 100% of all electric power produced by the plant for 20 years. Reopening the plant, which suffered a partial nuclear meltdown of its Unit 2 reactor in 1979, will require Constellation to get through strict regulatory processes which will include extensive safety scrutiny from the US Nuclear Regulatory Commission. If approved (this will be the first ever US re-commissioning of a nuclear plant), over 835 megawatts of power \u2013 enough for 800,000 homes \u2013 of energy will be produced. The cost for re-opening and upgrading is estimated at US$1.6 billion and is dependent on tax breaks for nuclear power contained in the 2022 US Inflation Reduction Act. The US government and the state of Michigan are investing almost US$2 billion to reopen the Palisades Nuclear reactor on Lake Michigan. Closed since 2022, the plant is planned to be reopened in October 2025. The Three Mile Island facility will be renamed the Crane Clean Energy Center after Chris Crane, a nuclear proponent and former CEO of Exelon who was responsible for Exelon's spinoff of Constellation.\nAfter the last approval in September 2023, Taiwan suspended the approval of data centers north of Taoyuan with a capacity of more than 5 MW in 2024, due to power supply shortages. Taiwan aims to phase out nuclear power by 2025. On the other hand, Singapore imposed a ban on the opening of data centers in 2019 due to electric power, but in 2022, lifted this ban.\nAlthough most nuclear plants in Japan have been shut down after the 2011 Fukushima nuclear accident, according to an October 2024 Bloomberg article in Japanese, cloud gaming services company Ubitus, in which Nvidia has a stake, is looking for land in Japan near nuclear power plant for a new data center for generative AI. Ubitus CEO Wesley Kuo said nuclear power plants are the most efficient, cheap and stable power for AI.\nOn 1 November 2024, the Federal Energy Regulatory Commission (FERC) rejected an application submitted by Talen Energy for approval to supply some electricity from the nuclear power station Susquehanna to Amazon's data center. \nAccording to the Commission Chairman Willie L. Phillips, it is a burden on the electricity grid as well as a significant cost shifting concern to households and other business sectors.\nIn 2025, a report prepared by the International Energy Agency estimated the greenhouse gas emissions from the energy consumption of AI at 180 million tons. By 2035, these emissions could rise to 300-500 million tonnes depending on what measures will be taken. This is below 1.5% of the energy sector emissions. The emissions reduction potential of AI was estimated at 5% of the energy sector emissions, but rebound effects (for example if people switch from public transport to autonomous cars) can reduce it.", "mimetype": "text/plain", "start_char_idx": 37583, "end_char_idx": 41901, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1014d9dc-9ae9-4dd1-ac14-0ada66e4a9ae": {"__data__": {"id_": "1014d9dc-9ae9-4dd1-ac14-0ada66e4a9ae", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "f7d89d37b65b972cacfc270c355208a838fdb4a4e05772c89023bfcd0917947d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ce96c984-6bb1-4d3f-ada1-2aa6035ebf59", "node_type": "1", "metadata": {}, "hash": "3a4d82c02400a437d3713186697c03c3eaba2693b712a12824e55172fde11532", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f1900eb9-9794-4c79-9358-48a3619b395a", "node_type": "1", "metadata": {}, "hash": "e7d98fc8e12c14336af790dd1a5e31113a0e44f5f2851b02269ae983697ae8a7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "On 1 November 2024, the Federal Energy Regulatory Commission (FERC) rejected an application submitted by Talen Energy for approval to supply some electricity from the nuclear power station Susquehanna to Amazon's data center. \nAccording to the Commission Chairman Willie L. Phillips, it is a burden on the electricity grid as well as a significant cost shifting concern to households and other business sectors.\nIn 2025, a report prepared by the International Energy Agency estimated the greenhouse gas emissions from the energy consumption of AI at 180 million tons. By 2035, these emissions could rise to 300-500 million tonnes depending on what measures will be taken. This is below 1.5% of the energy sector emissions. The emissions reduction potential of AI was estimated at 5% of the energy sector emissions, but rebound effects (for example if people switch from public transport to autonomous cars) can reduce it.\n\n\n==== Misinformation ====\n\nYouTube, Facebook and others use recommender systems to guide users to more content. These AI programs were given the goal of maximizing user engagement (that is, the only goal was to keep people watching). The AI learned that users tended to choose misinformation, conspiracy theories, and extreme partisan content, and, to keep them watching, the AI recommended more of it. Users also tended to watch more content on the same subject, so the AI led people into filter bubbles where they received multiple versions of the same misinformation. This convinced many users that the misinformation was true, and ultimately undermined trust in institutions, the media and the government. The AI program had correctly learned to maximize its goal, but the result was harmful to society. After the U.S. election in 2016, major technology companies took some steps to mitigate the problem.\nIn the early 2020s, generative AI began to create images, audio, and texts that are virtually indistinguishable from real photographs, recordings, or human writing, while realistic AI-generated videos became feasible in the mid-2020s. It is possible for bad actors to use this technology to create massive amounts of misinformation or propaganda; one such potential malicious use is deepfakes for computational propaganda. AI pioneer Geoffrey Hinton expressed concern about AI enabling \"authoritarian leaders to manipulate their electorates\" on a large scale, among other risks.\nAI researchers at Microsoft, OpenAI, universities and other organisations have suggested using \"personhood credentials\" as a way to overcome online deception enabled by AI models.", "mimetype": "text/plain", "start_char_idx": 40980, "end_char_idx": 43570, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f1900eb9-9794-4c79-9358-48a3619b395a": {"__data__": {"id_": "f1900eb9-9794-4c79-9358-48a3619b395a", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "f7d89d37b65b972cacfc270c355208a838fdb4a4e05772c89023bfcd0917947d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1014d9dc-9ae9-4dd1-ac14-0ada66e4a9ae", "node_type": "1", "metadata": {}, "hash": "b5dbd1384a94b93bd48bee9750710e49b012773ab43262065e76924e530dccee", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a770c7d6-5fd8-43ca-930e-241f530884a9", "node_type": "1", "metadata": {}, "hash": "8acb1a98d9ddc1a43e5703ee9840a69e641d631ee44e2b5af62748a60c4f8794", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Algorithmic bias and fairness ====\n\nMachine learning applications will be biased if they learn from biased data. The developers may not be aware that the bias exists. Bias can be introduced by the way training data is selected and by the way a model is deployed. If a biased algorithm is used to make decisions that can seriously harm people (as it can in medicine, finance, recruitment, housing or policing) then the algorithm may cause discrimination. The field of fairness studies how to prevent harms from algorithmic biases.\nOn June 28, 2015, Google Photos's new image labeling feature mistakenly identified Jacky Alcine and a friend as \"gorillas\" because they were black. The system was trained on a dataset that contained very few images of black people, a problem called \"sample size disparity\". Google \"fixed\" this problem by preventing the system from labelling anything as a \"gorilla\". Eight years later, in 2023, Google Photos still could not identify a gorilla, and neither could similar products from Apple, Facebook, Microsoft and Amazon.\nCOMPAS is a commercial program widely used by U.S. courts to assess the likelihood of a defendant becoming a recidivist. In 2016, Julia Angwin at ProPublica discovered that COMPAS exhibited racial bias, despite the fact that the program was not told the races of the defendants. Although the error rate for both whites and blacks was calibrated equal at exactly 61%, the errors for each race were different\u2014the system consistently overestimated the chance that a black person would re-offend and would underestimate the chance that a white person would not re-offend. In 2017, several researchers showed that it was mathematically impossible for COMPAS to accommodate all possible measures of fairness when the base rates of re-offense were different for whites and blacks in the data.\nA program can make biased decisions even if the data does not explicitly mention a problematic feature (such as \"race\" or \"gender\"). The feature will correlate with other features (like \"address\", \"shopping history\" or \"first name\"), and the program will make the same decisions based on these features as it would on \"race\" or \"gender\". Moritz Hardt said \"the most robust fact in this research area is that fairness through blindness doesn't work.\"\nCriticism of COMPAS highlighted that machine learning models are designed to make \"predictions\" that are only valid if we assume that the future will resemble the past. If they are trained on data that includes the results of racist decisions in the past, machine learning models must predict that racist decisions will be made in the future. If an application then uses these predictions as recommendations, some of these \"recommendations\" will likely be racist. Thus, machine learning is not well suited to help make decisions in areas where there is hope that the future will be better than the past. It is descriptive rather than prescriptive.\nBias and unfairness may go undetected because the developers are overwhelmingly white and male: among AI engineers, about 4% are black and 20% are women.\nThere are various conflicting definitions and mathematical models of fairness. These notions depend on ethical assumptions, and are influenced by beliefs about society. One broad category is distributive fairness, which focuses on the outcomes, often identifying groups and seeking to compensate for statistical disparities. Representational fairness tries to ensure that AI systems do not reinforce negative stereotypes or render certain groups invisible. Procedural fairness focuses on the decision process rather than the outcome. The most relevant notions of fairness may depend on the context, notably the type of AI application and the stakeholders. The subjectivity in the notions of bias and fairness makes it difficult for companies to operationalize them. Having access to sensitive attributes such as race or gender is also considered by many AI ethicists to be necessary in order to compensate for biases, but it may conflict with anti-discrimination laws.\nAt its 2022 Conference on Fairness, Accountability, and Transparency (ACM FAccT 2022), the Association for Computing Machinery, in Seoul, South Korea, presented and published findings that recommend that until AI and robotics systems are demonstrated to be free of bias mistakes, they are unsafe, and the use of self-learning neural networks trained on vast, unregulated sources of flawed internet data should be curtailed.", "mimetype": "text/plain", "start_char_idx": 43573, "end_char_idx": 48062, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a770c7d6-5fd8-43ca-930e-241f530884a9": {"__data__": {"id_": "a770c7d6-5fd8-43ca-930e-241f530884a9", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "f7d89d37b65b972cacfc270c355208a838fdb4a4e05772c89023bfcd0917947d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f1900eb9-9794-4c79-9358-48a3619b395a", "node_type": "1", "metadata": {}, "hash": "e7d98fc8e12c14336af790dd1a5e31113a0e44f5f2851b02269ae983697ae8a7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "748bfbfe-c62e-4446-af81-ff84db352218", "node_type": "1", "metadata": {}, "hash": "256371a07578bc23e597d7f516f3e7f0272fbc7023f171740ce5e4684c32a177", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Lack of transparency ====\n\nMany AI systems are so complex that their designers cannot explain how they reach their decisions. Particularly with deep neural networks, in which there are many non-linear relationships between inputs and outputs. But some popular explainability techniques exist.\nIt is impossible to be certain that a program is operating correctly if no one knows how exactly it works. There have been many cases where a machine learning program passed rigorous tests, but nevertheless learned something different than what the programmers intended. For example, a system that could identify skin diseases better than medical professionals was found to actually have a strong tendency to classify images with a ruler as \"cancerous\", because pictures of malignancies typically include a ruler to show the scale. Another machine learning system designed to help effectively allocate medical resources was found to classify patients with asthma as being at \"low risk\" of dying from pneumonia. Having asthma is actually a severe risk factor, but since the patients having asthma would usually get much more medical care, they were relatively unlikely to die according to the training data. The correlation between asthma and low risk of dying from pneumonia was real, but misleading.\nPeople who have been harmed by an algorithm's decision have a right to an explanation. Doctors, for example, are expected to clearly and completely explain to their colleagues the reasoning behind any decision they make. Early drafts of the European Union's General Data Protection Regulation in 2016 included an explicit statement that this right exists. Industry experts noted that this is an unsolved problem with no solution in sight. Regulators argued that nevertheless the harm is real: if the problem has no solution, the tools should not be used.\nDARPA established the XAI (\"Explainable Artificial Intelligence\") program in 2014 to try to solve these problems.\nSeveral approaches aim to address the transparency problem. SHAP enables to visualise the contribution of each feature to the output. LIME can locally approximate a model's outputs with a simpler, interpretable model. Multitask learning provides a large number of outputs in addition to the target classification. These other outputs can help developers deduce what the network has learned. Deconvolution, DeepDream and other generative methods can allow developers to see what different layers of a deep network for computer vision have learned, and produce output that can suggest what the network is learning. For generative pre-trained transformers, Anthropic developed a technique based on dictionary learning that associates patterns of neuron activations with human-understandable concepts.\n\n\n==== Bad actors and weaponized AI ====\n\nArtificial intelligence provides a number of tools that are useful to bad actors, such as authoritarian governments, terrorists, criminals or rogue states.\nA lethal autonomous weapon is a machine that locates, selects and engages human targets without human supervision. Widely available AI tools can be used by bad actors to develop inexpensive autonomous weapons and, if produced at scale, they are potentially weapons of mass destruction. Even when used in conventional warfare, they currently cannot reliably choose targets and could potentially kill an innocent person. In 2014, 30 nations (including China) supported a ban on autonomous weapons under the United Nations' Convention on Certain Conventional Weapons, however the United States and others disagreed. By 2015, over fifty countries were reported to be researching battlefield robots.\nAI tools make it easier for authoritarian governments to efficiently control their citizens in several ways. Face and voice recognition allow widespread surveillance. Machine learning, operating this data, can classify potential enemies of the state and prevent them from hiding. Recommendation systems can precisely target propaganda and misinformation for maximum effect. Deepfakes and generative AI aid in producing misinformation. Advanced AI can make authoritarian centralized decision-making more competitive than liberal and decentralized systems such as markets. It lowers the cost and difficulty of digital warfare and advanced spyware. All these technologies have been available since 2020 or earlier\u2014AI facial recognition systems are already being used for mass surveillance in China.\nThere are many other ways in which AI is expected to help bad actors, some of which can not be foreseen. For example, machine-learning AI is able to design tens of thousands of toxic molecules in a matter of hours.", "mimetype": "text/plain", "start_char_idx": 48065, "end_char_idx": 52734, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "748bfbfe-c62e-4446-af81-ff84db352218": {"__data__": {"id_": "748bfbfe-c62e-4446-af81-ff84db352218", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "f7d89d37b65b972cacfc270c355208a838fdb4a4e05772c89023bfcd0917947d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a770c7d6-5fd8-43ca-930e-241f530884a9", "node_type": "1", "metadata": {}, "hash": "8acb1a98d9ddc1a43e5703ee9840a69e641d631ee44e2b5af62748a60c4f8794", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d6ec0057-9df7-44c8-a9ac-fadef7b4c449", "node_type": "1", "metadata": {}, "hash": "cbe88d40bc8ba70e49b83621505af8b9841e4e188b141b4ce8b26df6acf43d9f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Technological unemployment ====\n\nEconomists have frequently highlighted the risks of redundancies from AI, and speculated about unemployment if there is no adequate social policy for full employment.\nIn the past, technology has tended to increase rather than reduce total employment, but economists acknowledge that \"we're in uncharted territory\" with AI. A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term unemployment, but they generally agree that it could be a net benefit if productivity gains are redistributed. Risk estimates vary; for example, in the 2010s, Michael Osborne and Carl Benedikt Frey estimated 47% of U.S. jobs are at \"high risk\" of potential automation, while an OECD report classified only 9% of U.S. jobs as \"high risk\". The methodology of speculating about future employment levels has been criticised as lacking evidential foundation, and for implying that technology, rather than social policy, creates unemployment, as opposed to redundancies. In April 2023, it was reported that 70% of the jobs for Chinese video game illustrators had been eliminated by generative artificial intelligence.\nUnlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; The Economist stated in 2015 that \"the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution\" is \"worth taking seriously\". Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy.\nFrom the early days of the development of artificial intelligence, there have been arguments, for example, those put forward by Joseph Weizenbaum, about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculation and qualitative, value-based judgement.", "mimetype": "text/plain", "start_char_idx": 52737, "end_char_idx": 54779, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d6ec0057-9df7-44c8-a9ac-fadef7b4c449": {"__data__": {"id_": "d6ec0057-9df7-44c8-a9ac-fadef7b4c449", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "f7d89d37b65b972cacfc270c355208a838fdb4a4e05772c89023bfcd0917947d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "748bfbfe-c62e-4446-af81-ff84db352218", "node_type": "1", "metadata": {}, "hash": "256371a07578bc23e597d7f516f3e7f0272fbc7023f171740ce5e4684c32a177", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "582c2c70-e701-470b-85d3-692e9bf1d4dc", "node_type": "1", "metadata": {}, "hash": "2822f2aa1a88985766ac61b72ff1e33699980458f8204ff3e7188ed0fbbd0484", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Existential risk ====\n\nIt has been argued AI will become so powerful that humanity may irreversibly lose control of it. This could, as physicist Stephen Hawking stated, \"spell the end of the human race\". This scenario has been common in science fiction, when a computer or robot suddenly develops a human-like \"self-awareness\" (or \"sentience\" or \"consciousness\") and becomes a malevolent character. These sci-fi scenarios are misleading in several ways.\nFirst, AI does not require human-like sentience to be an existential risk. Modern AI programs are given specific goals and use learning and intelligence to achieve them. Philosopher Nick Bostrom argued that if one gives almost any goal to a sufficiently powerful AI, it may choose to destroy humanity to achieve it (he used the example of a paperclip maximizer). Stuart Russell gives the example of household robot that tries to find a way to kill its owner to prevent it from being unplugged, reasoning that \"you can't fetch the coffee if you're dead.\" In order to be safe for humanity, a superintelligence would have to be genuinely aligned with humanity's morality and values so that it is \"fundamentally on our side\".\nSecond, Yuval Noah Harari argues that AI does not require a robot body or physical control to pose an existential risk. The essential parts of civilization are not physical. Things like ideologies, law, government, money and the economy are built on language; they exist because there are stories that billions of people believe. The current prevalence of misinformation suggests that an AI could use language to convince people to believe anything, even to take actions that are destructive.\nThe opinions amongst experts and industry insiders are mixed, with sizable fractions both concerned and unconcerned by risk from eventual superintelligent AI. Personalities such as Stephen Hawking, Bill Gates, and Elon Musk, as well as AI pioneers such as Yoshua Bengio, Stuart Russell, Demis Hassabis, and Sam Altman, have expressed concerns about existential risk from AI.\nIn May 2023, Geoffrey Hinton announced his resignation from Google in order to be able to \"freely speak out about the risks of AI\" without \"considering how this impacts Google\". He notably mentioned risks of an AI takeover, and stressed that in order to avoid the worst outcomes, establishing safety guidelines will require cooperation among those competing in use of AI.\nIn 2023, many leading AI experts endorsed the joint statement that \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war\".\nSome other researchers were more optimistic. AI pioneer J\u00fcrgen Schmidhuber did not sign the joint statement, emphasising that in 95% of all cases, AI research is about making \"human lives longer and healthier and easier.\" While the tools that are now being used to improve lives can also be used by bad actors, \"they can also be used against the bad actors.\" Andrew Ng also argued that \"it's a mistake to fall for the doomsday hype on AI\u2014and that regulators who do will only benefit vested interests.\" Yann LeCun \"scoffs at his peers' dystopian scenarios of supercharged misinformation and even, eventually, human extinction.\" In the early 2010s, experts argued that the risks are too distant in the future to warrant research or that humans will be valuable from the perspective of a superintelligent machine. However, after 2016, the study of current and future risks and possible solutions became a serious area of research.\n\n\n=== Ethical machines and alignment ===\n\nFriendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans. Eliezer Yudkowsky, who coined the term, argues that developing friendly AI should be a higher research priority: it may require a large investment and it must be completed before AI becomes an existential risk.\nMachines with intelligence have the potential to use their intelligence to make ethical decisions. The field of machine ethics provides machines with ethical principles and procedures for resolving ethical dilemmas.\nThe field of machine ethics is also called computational morality,\nand was founded at an AAAI symposium in 2005.\nOther approaches include Wendell Wallach's \"artificial moral agents\" and Stuart J. Russell's three principles for developing provably beneficial machines.", "mimetype": "text/plain", "start_char_idx": 54782, "end_char_idx": 59205, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "582c2c70-e701-470b-85d3-692e9bf1d4dc": {"__data__": {"id_": "582c2c70-e701-470b-85d3-692e9bf1d4dc", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "f7d89d37b65b972cacfc270c355208a838fdb4a4e05772c89023bfcd0917947d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d6ec0057-9df7-44c8-a9ac-fadef7b4c449", "node_type": "1", "metadata": {}, "hash": "cbe88d40bc8ba70e49b83621505af8b9841e4e188b141b4ce8b26df6acf43d9f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b305739e-f2bd-401f-aecc-710ed8a1673d", "node_type": "1", "metadata": {}, "hash": "0725c3115d23449ccf06dc3cc3d15c5b2c462d61c485842dc5e88972ec6014f7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Ethical machines and alignment ===\n\nFriendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans. Eliezer Yudkowsky, who coined the term, argues that developing friendly AI should be a higher research priority: it may require a large investment and it must be completed before AI becomes an existential risk.\nMachines with intelligence have the potential to use their intelligence to make ethical decisions. The field of machine ethics provides machines with ethical principles and procedures for resolving ethical dilemmas.\nThe field of machine ethics is also called computational morality,\nand was founded at an AAAI symposium in 2005.\nOther approaches include Wendell Wallach's \"artificial moral agents\" and Stuart J. Russell's three principles for developing provably beneficial machines.\n\n\n=== Open source ===\nActive organizations in the AI open-source community include Hugging Face, Google, EleutherAI and Meta. Various AI models, such as Llama 2, Mistral or Stable Diffusion, have been made open-weight, meaning that their architecture and trained parameters (the \"weights\") are publicly available. Open-weight models can be freely fine-tuned, which allows companies to specialize them with their own data and for their own use-case. Open-weight models are useful for research and innovation but can also be misused. Since they can be fine-tuned, any built-in security measure, such as objecting to harmful requests, can be trained away until it becomes ineffective. Some researchers warn that future AI models may develop dangerous capabilities (such as the potential to drastically facilitate bioterrorism) and that once released on the Internet, they cannot be deleted everywhere if needed. They recommend pre-release audits and cost-benefit analyses.\n\n\n=== Frameworks ===\nArtificial intelligence projects can be guided by ethical considerations during the design, development, and implementation of an AI system. An AI framework such as the Care and Act Framework, developed by the Alan Turing Institute and based on the SUM values, outlines four main ethical dimensions, defined as follows:\n\nRespect the dignity of individual people\nConnect with other people sincerely, openly, and inclusively\nCare for the wellbeing of everyone\nProtect social values, justice, and the public interest\nOther developments in ethical frameworks include those decided upon during the Asilomar Conference, the Montreal Declaration for Responsible AI, and the IEEE's Ethics of Autonomous Systems initiative, among others; however, these principles are not without criticism, especially regarding the people chosen to contribute to these frameworks.\nPromotion of the wellbeing of the people and communities that these technologies affect requires consideration of the social and ethical implications at all stages of AI system design, development and implementation, and collaboration between job roles such as data scientists, product managers, data engineers, domain experts, and delivery managers.\nThe UK AI Safety Institute released in 2024 a testing toolset called 'Inspect' for AI safety evaluations available under an MIT open-source licence which is freely available on GitHub and can be improved with third-party packages. It can be used to evaluate AI models in a range of areas including core knowledge, ability to reason, and autonomous capabilities.", "mimetype": "text/plain", "start_char_idx": 58344, "end_char_idx": 61765, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b305739e-f2bd-401f-aecc-710ed8a1673d": {"__data__": {"id_": "b305739e-f2bd-401f-aecc-710ed8a1673d", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "f7d89d37b65b972cacfc270c355208a838fdb4a4e05772c89023bfcd0917947d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "582c2c70-e701-470b-85d3-692e9bf1d4dc", "node_type": "1", "metadata": {}, "hash": "2822f2aa1a88985766ac61b72ff1e33699980458f8204ff3e7188ed0fbbd0484", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "940a7ba9-7764-41b2-92a6-fcfac7e6e3a0", "node_type": "1", "metadata": {}, "hash": "7f6e2dc6185f57eaa9260760cddc93f36cfdcc19fde5e460f03d8f8090bc7c02", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Regulation ===\n\nThe regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating AI; it is therefore related to the broader regulation of algorithms. The regulatory and policy landscape for AI is an emerging issue in jurisdictions globally. According to AI Index at Stanford, the annual number of AI-related laws passed in the 127 survey countries jumped from one passed in 2016 to 37 passed in 2022 alone. Between 2016 and 2020, more than 30 countries adopted dedicated strategies for AI. Most EU member states had released national AI strategies, as had Canada, China, India, Japan, Mauritius, the Russian Federation, Saudi Arabia, United Arab Emirates, U.S., and Vietnam. Others were in the process of elaborating their own AI strategy, including Bangladesh, Malaysia and Tunisia. The Global Partnership on Artificial Intelligence was launched in June 2020, stating a need for AI to be developed in accordance with human rights and democratic values, to ensure public confidence and trust in the technology. Henry Kissinger, Eric Schmidt, and Daniel Huttenlocher published a joint statement in November 2021 calling for a government commission to regulate AI. In 2023, OpenAI leaders published recommendations for the governance of superintelligence, which they believe may happen in less than 10 years. In 2023, the United Nations also launched an advisory body to provide recommendations on AI governance; the body comprises technology company executives, government officials and academics. In 2024, the Council of Europe created the first international legally binding treaty on AI, called the \"Framework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule of Law\". It was adopted by the European Union, the United States, the United Kingdom, and other signatories.\nIn a 2022 Ipsos survey, attitudes towards AI varied greatly by country; 78% of Chinese citizens, but only 35% of Americans, agreed that \"products and services using AI have more benefits than drawbacks\". A 2023 Reuters/Ipsos poll found that 61% of Americans agree, and 22% disagree, that AI poses risks to humanity. In a 2023 Fox News poll, 35% of Americans thought it \"very important\", and an additional 41% thought it \"somewhat important\", for the federal government to regulate AI, versus 13% responding \"not very important\" and 8% responding \"not at all important\".\nIn November 2023, the first global AI Safety Summit was held in Bletchley Park in the UK to discuss the near and far term risks of AI and the possibility of mandatory and voluntary regulatory frameworks. 28 countries including the United States, China, and the European Union issued a declaration at the start of the summit, calling for international co-operation to manage the challenges and risks of artificial intelligence. In May 2024 at the AI Seoul Summit, 16 global AI tech companies agreed to safety commitments on the development of AI.\n\n\n== History ==\n\nThe study of mechanical or \"formal\" reasoning began with philosophers and mathematicians in antiquity. The study of logic led directly to Alan Turing's theory of computation, which suggested that a machine, by shuffling symbols as simple as \"0\" and \"1\", could simulate any conceivable form of mathematical reasoning. This, along with concurrent discoveries in cybernetics, information theory and neurobiology, led researchers to consider the possibility of building an \"electronic brain\". They developed several areas of research that would become part of AI, such as McCulloch and Pitts design for \"artificial neurons\" in 1943, and Turing's influential 1950 paper 'Computing Machinery and Intelligence', which introduced the Turing test and showed that \"machine intelligence\" was plausible.\nThe field of AI research was founded at a workshop at Dartmouth College in 1956. The attendees became the leaders of AI research in the 1960s. They and their students produced programs that the press described as \"astonishing\": computers were learning checkers strategies, solving word problems in algebra, proving logical theorems and speaking English. Artificial intelligence laboratories were set up at a number of British and U.S. universities in the latter 1950s and early 1960s.\nResearchers in the 1960s and the 1970s were convinced that their methods would eventually succeed in creating a machine with general intelligence and considered this the goal of their field. In 1965 Herbert Simon predicted, \"machines will be capable, within twenty years, of doing any work a man can do\". In 1967 Marvin Minsky agreed, writing that \"within a generation ... the problem of creating 'artificial intelligence' will substantially be solved\". They had, however, underestimated the difficulty of the problem. In 1974, both the U.S.", "mimetype": "text/plain", "start_char_idx": 61768, "end_char_idx": 66583, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "940a7ba9-7764-41b2-92a6-fcfac7e6e3a0": {"__data__": {"id_": "940a7ba9-7764-41b2-92a6-fcfac7e6e3a0", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "f7d89d37b65b972cacfc270c355208a838fdb4a4e05772c89023bfcd0917947d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b305739e-f2bd-401f-aecc-710ed8a1673d", "node_type": "1", "metadata": {}, "hash": "0725c3115d23449ccf06dc3cc3d15c5b2c462d61c485842dc5e88972ec6014f7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d4f67fb4-9378-4832-bd9b-85d367e9cd28", "node_type": "1", "metadata": {}, "hash": "a6d4ffb897ee2a5cf294610ba9675ead2664454bb56c3b8a9fd35370e1f94181", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "They and their students produced programs that the press described as \"astonishing\": computers were learning checkers strategies, solving word problems in algebra, proving logical theorems and speaking English. Artificial intelligence laboratories were set up at a number of British and U.S. universities in the latter 1950s and early 1960s.\nResearchers in the 1960s and the 1970s were convinced that their methods would eventually succeed in creating a machine with general intelligence and considered this the goal of their field. In 1965 Herbert Simon predicted, \"machines will be capable, within twenty years, of doing any work a man can do\". In 1967 Marvin Minsky agreed, writing that \"within a generation ... the problem of creating 'artificial intelligence' will substantially be solved\". They had, however, underestimated the difficulty of the problem. In 1974, both the U.S. and British governments cut off exploratory research in response to the criticism of Sir James Lighthill and ongoing pressure from the U.S. Congress to fund more productive projects. Minsky and Papert's book Perceptrons was understood as proving that artificial neural networks would never be useful for solving real-world tasks, thus discrediting the approach altogether. The \"AI winter\", a period when obtaining funding for AI projects was difficult, followed.\nIn the early 1980s, AI research was revived by the commercial success of expert systems, a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan's fifth generation computer project inspired the U.S. and British governments to restore funding for academic research. However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began.\nUp to this point, most of AI's funding had gone to projects that used high-level symbols to represent mental objects like plans, goals, beliefs, and known facts. In the 1980s, some researchers began to doubt that this approach would be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition, and began to look into \"sub-symbolic\" approaches. Rodney Brooks rejected \"representation\" in general and focussed directly on engineering machines that move and survive. Judea Pearl, Lotfi Zadeh, and others developed methods that handled incomplete and uncertain information by making reasonable guesses rather than precise logic. But the most important development was the revival of \"connectionism\", including neural network research, by Geoffrey Hinton and others. In 1990, Yann LeCun successfully showed that convolutional neural networks can recognize handwritten digits, the first of many successful applications of neural networks.\nAI gradually restored its reputation in the late 1990s and early 21st century by exploiting formal mathematical methods and by finding specific solutions to specific problems. This \"narrow\" and \"formal\" focus allowed researchers to produce verifiable results and collaborate with other fields (such as statistics, economics and mathematics). By 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as \"artificial intelligence\" (a tendency known as the AI effect).\nHowever, several academic researchers became concerned that AI was no longer pursuing its original goal of creating versatile, fully intelligent machines. Beginning around 2002, they founded the subfield of artificial general intelligence (or \"AGI\"), which had several well-funded institutions by the 2010s.\nDeep learning began to dominate industry benchmarks in 2012 and was adopted throughout the field.\nFor many specific tasks, other methods were abandoned.\nDeep learning's success was based on both hardware improvements (faster computers, graphics processing units, cloud computing) and access to large amounts of data (including curated datasets, such as ImageNet). Deep learning's success led to an enormous increase in interest and funding in AI. The amount of machine learning research (measured by total publications) increased by 50% in the years 2015\u20132019.\n\nIn 2016, issues of fairness and the misuse of technology were catapulted into center stage at machine learning conferences, publications vastly increased, funding became available, and many researchers re-focussed their careers on these issues. The alignment problem became a serious field of academic study.\nIn the late 2010s and early 2020s, AGI companies began to deliver programs that created enormous interest. In 2015, AlphaGo, developed by DeepMind, beat the world champion Go player. The program taught only the game's rules and developed a strategy by itself.", "mimetype": "text/plain", "start_char_idx": 65700, "end_char_idx": 70546, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d4f67fb4-9378-4832-bd9b-85d367e9cd28": {"__data__": {"id_": "d4f67fb4-9378-4832-bd9b-85d367e9cd28", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "f7d89d37b65b972cacfc270c355208a838fdb4a4e05772c89023bfcd0917947d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "940a7ba9-7764-41b2-92a6-fcfac7e6e3a0", "node_type": "1", "metadata": {}, "hash": "7f6e2dc6185f57eaa9260760cddc93f36cfdcc19fde5e460f03d8f8090bc7c02", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1eb737bb-e068-4b59-a724-cd3acea8f8bb", "node_type": "1", "metadata": {}, "hash": "24b2e3abf0b9f077b347a32bde891c5c3fd45f63b5cdbaa1b82e43f595c025c0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Deep learning's success led to an enormous increase in interest and funding in AI. The amount of machine learning research (measured by total publications) increased by 50% in the years 2015\u20132019.\n\nIn 2016, issues of fairness and the misuse of technology were catapulted into center stage at machine learning conferences, publications vastly increased, funding became available, and many researchers re-focussed their careers on these issues. The alignment problem became a serious field of academic study.\nIn the late 2010s and early 2020s, AGI companies began to deliver programs that created enormous interest. In 2015, AlphaGo, developed by DeepMind, beat the world champion Go player. The program taught only the game's rules and developed a strategy by itself. GPT-3 is a large language model that was released in 2020 by OpenAI and is capable of generating high-quality human-like text. ChatGPT, launched on November 30, 2022, became the fastest-growing consumer software application in history, gaining over 100 million users in two months. It marked what is widely regarded as AI's breakout year, bringing it into the public consciousness. These programs, and others, inspired an aggressive AI boom, where large companies began investing billions of dollars in AI research. According to AI Impacts, about US$50 billion annually was invested in \"AI\" around 2022 in the U.S. alone and about 20% of the new U.S. Computer Science PhD graduates have specialized in \"AI\". About 800,000 \"AI\"-related U.S. job openings existed in 2022. According to PitchBook research, 22% of newly funded startups in 2024 claimed to be AI companies.\n\n\n== Philosophy ==\n\nPhilosophical debates have historically sought to determine the nature of intelligence and how to make intelligent machines. Another major focus has been whether machines can be conscious, and the associated ethical implications. Many other topics in philosophy are relevant to AI, such as epistemology and free will. Rapid advancements have intensified public discussions on the philosophy and ethics of AI.\n\n\n=== Defining artificial intelligence ===\n\nAlan Turing wrote in 1950 \"I propose to consider the question 'can machines think'?\" He advised changing the question from whether a machine \"thinks\", to \"whether or not it is possible for machinery to show intelligent behaviour\". He devised the Turing test, which measures the ability of a machine to simulate human conversation. Since we can only observe the behavior of the machine, it does not matter if it is \"actually\" thinking or literally has a \"mind\". Turing notes that we can not determine these things about other people but \"it is usual to have a polite convention that everyone thinks.\"\n\nRussell and Norvig agree with Turing that intelligence must be defined in terms of external behavior, not internal structure. However, they are critical that the test requires the machine to imitate humans. \"Aeronautical engineering texts\", they wrote, \"do not define the goal of their field as making 'machines that fly so exactly like pigeons that they can fool other pigeons.'\" AI founder John McCarthy agreed, writing that \"Artificial intelligence is not, by definition, simulation of human intelligence\".\nMcCarthy defines intelligence as \"the computational part of the ability to achieve goals in the world\". Another AI founder, Marvin Minsky, similarly describes it as \"the ability to solve hard problems\". The leading AI textbook defines it as the study of agents that perceive their environment and take actions that maximize their chances of achieving defined goals. These definitions view intelligence in terms of well-defined problems with well-defined solutions, where both the difficulty of the problem and the performance of the program are direct measures of the \"intelligence\" of the machine\u2014and no other philosophical discussion is required, or may not even be possible.\nAnother definition has been adopted by Google, a major practitioner in the field of AI. This definition stipulates the ability of systems to synthesize information as the manifestation of intelligence, similar to the way it is defined in biological intelligence.\nSome authors have suggested in practice, that the definition of AI is vague and difficult to define, with contention as to whether classical algorithms should be categorised as AI, with many companies during the early 2020s AI boom using the term as a marketing buzzword, often even if they did \"not actually use AI in a material way\".\n\n\n=== Evaluating approaches to AI ===\nNo established unifying theory or paradigm has guided AI research for most of its history. The unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so much so that some sources, especially in the business world, use the term \"artificial intelligence\" to mean \"machine learning with neural networks\"). This approach is mostly sub-symbolic, soft and narrow. Critics argue that these questions may have to be revisited by future generations of AI researchers.", "mimetype": "text/plain", "start_char_idx": 69780, "end_char_idx": 74815, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1eb737bb-e068-4b59-a724-cd3acea8f8bb": {"__data__": {"id_": "1eb737bb-e068-4b59-a724-cd3acea8f8bb", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "f7d89d37b65b972cacfc270c355208a838fdb4a4e05772c89023bfcd0917947d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d4f67fb4-9378-4832-bd9b-85d367e9cd28", "node_type": "1", "metadata": {}, "hash": "a6d4ffb897ee2a5cf294610ba9675ead2664454bb56c3b8a9fd35370e1f94181", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e791a355-3211-4038-90d1-367802583262", "node_type": "1", "metadata": {}, "hash": "480c29dd28ef61d17e581baf61abac6e26c3fde5ba4a50b019889e6a6efd2ec6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Evaluating approaches to AI ===\nNo established unifying theory or paradigm has guided AI research for most of its history. The unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so much so that some sources, especially in the business world, use the term \"artificial intelligence\" to mean \"machine learning with neural networks\"). This approach is mostly sub-symbolic, soft and narrow. Critics argue that these questions may have to be revisited by future generations of AI researchers.\n\n\n==== Symbolic AI and its limits ====\nSymbolic AI (or \"GOFAI\") simulated the high-level conscious reasoning that people use when they solve puzzles, express legal reasoning and do mathematics. They were highly successful at \"intelligent\" tasks such as algebra or IQ tests. In the 1960s, Newell and Simon proposed the physical symbol systems hypothesis: \"A physical symbol system has the necessary and sufficient means of general intelligent action.\"\nHowever, the symbolic approach failed on many tasks that humans solve easily, such as learning, recognizing an object or commonsense reasoning. Moravec's paradox is the discovery that high-level \"intelligent\" tasks were easy for AI, but low level \"instinctive\" tasks were extremely difficult. Philosopher Hubert Dreyfus had argued since the 1960s that human expertise depends on unconscious instinct rather than conscious symbol manipulation, and on having a \"feel\" for the situation, rather than explicit symbolic knowledge. Although his arguments had been ridiculed and ignored when they were first presented, eventually, AI research came to agree with him.\nThe issue is not resolved: sub-symbolic reasoning can make many of the same inscrutable mistakes that human intuition does, such as algorithmic bias. Critics such as Noam Chomsky argue continuing research into symbolic AI will still be necessary to attain general intelligence, in part because sub-symbolic AI is a move away from explainable AI: it can be difficult or impossible to understand why a modern statistical AI program made a particular decision. The emerging field of neuro-symbolic artificial intelligence attempts to bridge the two approaches.\n\n\n==== Neat vs. scruffy ====\n\n\"Neats\" hope that intelligent behavior is described using simple, elegant principles (such as logic, optimization, or neural networks). \"Scruffies\" expect that it necessarily requires solving a large number of unrelated problems. Neats defend their programs with theoretical rigor, scruffies rely mainly on incremental testing to see if they work. This issue was actively discussed in the 1970s and 1980s, but eventually was seen as irrelevant. Modern AI has elements of both.\n\n\n==== Soft vs. hard computing ====\n\nFinding a provably correct or optimal solution is intractable for many important problems. Soft computing is a set of techniques, including genetic algorithms, fuzzy logic and neural networks, that are tolerant of imprecision, uncertainty, partial truth and approximation. Soft computing was introduced in the late 1980s and most successful AI programs in the 21st century are examples of soft computing with neural networks.\n\n\n==== Narrow vs. general AI ====\n\nAI researchers are divided as to whether to pursue the goals of artificial general intelligence and superintelligence directly or to solve as many specific problems as possible (narrow AI) in hopes these solutions will lead indirectly to the field's long-term goals. General intelligence is difficult to define and difficult to measure, and modern AI has had more verifiable successes by focusing on specific problems with specific solutions. The sub-field of artificial general intelligence studies this area exclusively.\n\n\n=== Machine consciousness, sentience, and mind ===\n\nThere is no settled consensus in philosophy of mind on whether a machine can have a mind, consciousness and mental states in the same sense that human beings do. This issue considers the internal experiences of the machine, rather than its external behavior. Mainstream AI research considers this issue irrelevant because it does not affect the goals of the field: to build machines that can solve problems using intelligence. Russell and Norvig add that \"[t]he additional project of making a machine conscious in exactly the way humans are is not one that we are equipped to take on.\" However, the question has become central to the philosophy of mind. It is also typically the central question at issue in artificial intelligence in fiction.", "mimetype": "text/plain", "start_char_idx": 74278, "end_char_idx": 78810, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e791a355-3211-4038-90d1-367802583262": {"__data__": {"id_": "e791a355-3211-4038-90d1-367802583262", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "f7d89d37b65b972cacfc270c355208a838fdb4a4e05772c89023bfcd0917947d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1eb737bb-e068-4b59-a724-cd3acea8f8bb", "node_type": "1", "metadata": {}, "hash": "24b2e3abf0b9f077b347a32bde891c5c3fd45f63b5cdbaa1b82e43f595c025c0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9ed57cc2-be4a-4bbb-83e4-c0584faf7c66", "node_type": "1", "metadata": {}, "hash": "367f416124e2f2bf1579e43f9050100aacc13ac856e5d53f6e52d79ff139c2bc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Machine consciousness, sentience, and mind ===\n\nThere is no settled consensus in philosophy of mind on whether a machine can have a mind, consciousness and mental states in the same sense that human beings do. This issue considers the internal experiences of the machine, rather than its external behavior. Mainstream AI research considers this issue irrelevant because it does not affect the goals of the field: to build machines that can solve problems using intelligence. Russell and Norvig add that \"[t]he additional project of making a machine conscious in exactly the way humans are is not one that we are equipped to take on.\" However, the question has become central to the philosophy of mind. It is also typically the central question at issue in artificial intelligence in fiction.\n\n\n==== Consciousness ====\n\nDavid Chalmers identified two problems in understanding the mind, which he named the \"hard\" and \"easy\" problems of consciousness. The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how this feels or why it should feel like anything at all, assuming we are right in thinking that it truly does feel like something (Dennett's consciousness illusionism says this is an illusion). While human information processing is easy to explain, human subjective experience is difficult to explain. For example, it is easy to imagine a color-blind person who has learned to identify which objects in their field of view are red, but it is not clear what would be required for the person to know what red looks like.\n\n\n==== Computationalism and functionalism ====\n\nComputationalism is the position in the philosophy of mind that the human mind is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the mind\u2013body problem. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers Jerry Fodor and Hilary Putnam.\nPhilosopher John Searle characterized this position as \"strong AI\": \"The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.\" Searle challenges this claim with his Chinese room argument, which attempts to show that even a computer capable of perfectly simulating human behavior would not have a mind.\n\n\n==== AI welfare and rights ====\nIt is difficult or impossible to reliably evaluate whether an advanced AI is sentient (has the ability to feel), and if so, to what degree. But if there is a significant chance that a given machine can feel and suffer, then it may be entitled to certain rights or welfare protection measures, similarly to animals. Sapience (a set of capacities related to high intelligence, such as discernment or self-awareness) may provide another moral basis for AI rights. Robot rights are also sometimes proposed as a practical way to integrate autonomous agents into society.\nIn 2017, the European Union considered granting \"electronic personhood\" to some of the most capable AI systems. Similarly to the legal status of companies, it would have conferred rights but also responsibilities. Critics argued in 2018 that granting rights to AI systems would downplay the importance of human rights, and that legislation should focus on user needs rather than speculative futuristic scenarios. They also noted that robots lacked the autonomy to take part in society on their own.\nProgress in AI increased interest in the topic. Proponents of AI welfare and rights often argue that AI sentience, if it emerges, would be particularly easy to deny. They warn that this may be a moral blind spot analogous to slavery or factory farming, which could lead to large-scale suffering if sentient AI is created and carelessly exploited.\n\n\n== Future ==\n\n\n=== Superintelligence and the singularity ===\nA superintelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind. If research into artificial general intelligence produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to what I. J. Good called an \"intelligence explosion\" and Vernor Vinge called a \"singularity\".\nHowever, technologies cannot improve exponentially indefinitely, and typically follow an S-shaped curve, slowing when they reach the physical limits of what the technology can do.", "mimetype": "text/plain", "start_char_idx": 78015, "end_char_idx": 82739, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9ed57cc2-be4a-4bbb-83e4-c0584faf7c66": {"__data__": {"id_": "9ed57cc2-be4a-4bbb-83e4-c0584faf7c66", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "f7d89d37b65b972cacfc270c355208a838fdb4a4e05772c89023bfcd0917947d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e791a355-3211-4038-90d1-367802583262", "node_type": "1", "metadata": {}, "hash": "480c29dd28ef61d17e581baf61abac6e26c3fde5ba4a50b019889e6a6efd2ec6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d3ead8bc-b4a2-4d8b-abda-272b2327c406", "node_type": "1", "metadata": {}, "hash": "2a3c9ca8d179ab9c31627a6adc9606b6e502388da15cf0aecf448d41b37685d1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Future ==\n\n\n=== Superintelligence and the singularity ===\nA superintelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind. If research into artificial general intelligence produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to what I. J. Good called an \"intelligence explosion\" and Vernor Vinge called a \"singularity\".\nHowever, technologies cannot improve exponentially indefinitely, and typically follow an S-shaped curve, slowing when they reach the physical limits of what the technology can do.\n\n\n=== Transhumanism ===\n\nRobot designer Hans Moravec, cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines may merge in the future into cyborgs that are more capable and powerful than either. This idea, called transhumanism, has roots in the writings of Aldous Huxley and Robert Ettinger.\nEdward Fredkin argues that \"artificial intelligence is the next step in evolution\", an idea first proposed by Samuel Butler's \"Darwin among the Machines\" as far back as 1863, and expanded upon by George Dyson in his 1998 book Darwin Among the Machines: The Evolution of Global Intelligence.\n\n\n== In fiction ==\n\nThought-capable artificial beings have appeared as storytelling devices since antiquity, and have been a persistent theme in science fiction.\nA common trope in these works began with Mary Shelley's Frankenstein, where a human creation becomes a threat to its masters. This includes such works as Arthur C. Clarke's and Stanley Kubrick's 2001: A Space Odyssey (both 1968), with HAL 9000, the murderous computer in charge of the Discovery One spaceship, as well as The Terminator (1984) and The Matrix (1999). In contrast, the rare loyal robots such as Gort from The Day the Earth Stood Still (1951) and Bishop from Aliens (1986) are less prominent in popular culture.\nIsaac Asimov introduced the Three Laws of Robotics in many stories, most notably with the \"Multivac\" super-intelligent computer. Asimov's laws are often brought up during lay discussions of machine ethics; while almost all artificial intelligence researchers are familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity.\nSeveral works use AI to force us to confront the fundamental question of what makes us human, showing us artificial beings that have the ability to feel, and thus to suffer. This appears in Karel \u010capek's R.U.R., the films A.I. Artificial Intelligence and Ex Machina, as well as the novel Do Androids Dream of Electric Sheep?, by Philip K. Dick. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence.\n\n\n== See also ==\nArtificial consciousness \u2013 Field in cognitive science\nArtificial intelligence and elections \u2013 Use and impact of AI on political elections\nArtificial intelligence content detection \u2013 Software to detect AI-generated content\nBehavior selection algorithm \u2013 Algorithm that selects actions for intelligent agents\nBusiness process automation \u2013 Automation of business processes\nCase-based reasoning \u2013 Process of solving new problems based on the solutions of similar past problems\nComputational intelligence \u2013 Ability of a computer to learn a specific task from data or experimental observation\nDigital immortality \u2013 Hypothetical concept of storing a personality in digital form\nEmergent algorithm \u2013 Algorithm exhibiting emergent behavior\nFemale gendering of AI technologies \u2013 Gender biases in digital technologyPages displaying short descriptions of redirect targets\nGlossary of artificial intelligence \u2013 List of definitions of terms and concepts commonly used in the study of artificial intelligence\nIntelligence amplification \u2013 Use of information technology to augment human intelligence\nIntelligent agent \u2013 Software agent which acts autonomously\nIntelligent automation \u2013 Software process that combines robotic process automation and artificial intelligence\nMind uploading \u2013 Hypothetical process of digitally emulating a brain\nOrganoid intelligence \u2013 Use of brain cells and brain organoids for intelligent computing\nRobotic process automation \u2013 Form of business process automation technology\nThe Last Day \u2013 1967 Welsh science fiction novel\nWetware computer \u2013 Computer composed of organic material\nDARWIN EU - A European Union initiative coordinated by the European Medicines Agency (EMA) to generate and utilize real-world evidence (RWE) to support the evaluation and supervision of medicines across the EU.\n\n\n== Explanatory notes ==\n\n\n== References ==", "mimetype": "text/plain", "start_char_idx": 82048, "end_char_idx": 86797, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d3ead8bc-b4a2-4d8b-abda-272b2327c406": {"__data__": {"id_": "d3ead8bc-b4a2-4d8b-abda-272b2327c406", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "f7d89d37b65b972cacfc270c355208a838fdb4a4e05772c89023bfcd0917947d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9ed57cc2-be4a-4bbb-83e4-c0584faf7c66", "node_type": "1", "metadata": {}, "hash": "367f416124e2f2bf1579e43f9050100aacc13ac856e5d53f6e52d79ff139c2bc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Explanatory notes ==\n\n\n== References ==\n\n\n=== AI textbooks ===\nThe two most widely used textbooks in 2023 (see the Open Syllabus):\n\nRussell, Stuart J.; Norvig, Peter (2021). Artificial Intelligence: A Modern Approach (4th ed.). Hoboken: Pearson. ISBN 978-0-1346-1099-3. LCCN 20190474.\nRich, Elaine; Knight, Kevin; Nair, Shivashankar B (2010). Artificial Intelligence (3rd ed.). New Delhi: Tata McGraw Hill India. ISBN 978-0-0700-8770-5.\nThe four most widely used AI textbooks in 2008:\n\nOther textbooks:\n\nErtel, Wolfgang (2017). Introduction to Artificial Intelligence (2nd ed.). Springer. ISBN 978-3-3195-8486-7.\nCiaramella, Alberto; Ciaramella, Marco (2024). Introduction to Artificial Intelligence: from data analysis to generative AI (1st ed.). Intellisemantic Editions. ISBN 978-8-8947-8760-3.\n\n\n=== History of AI ===\n\n\n=== Other sources ===\n\n\n== Further reading ==\n\n\n== External links ==\n\n\"Artificial Intelligence\". Internet Encyclopedia of Philosophy.", "mimetype": "text/plain", "start_char_idx": 86755, "end_char_idx": 87715, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bf5a447d-15e9-4ad8-a417-680587a46b11": {"__data__": {"id_": "bf5a447d-15e9-4ad8-a417-680587a46b11", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2894560", "node_type": "4", "metadata": {}, "hash": "3f693a0322bab49ee1a9c95b0fad8b26f3b517c00c36665addff054ec94514ce", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "337000d0-3fe4-4aae-a2ae-d2dd68a65cbd", "node_type": "1", "metadata": {}, "hash": "e39044c4a507606b3d5ed7f4af9627a71ea95b3cbebcd46fa99bebff785e2173", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The history of artificial intelligence (AI) began in antiquity, with myths, stories, and rumors of artificial beings endowed with intelligence or consciousness by master craftsmen. The study of logic and formal reasoning from antiquity to the present led directly to the invention of the programmable digital computer in the 1940s, a machine based on abstract mathematical reasoning. This device and the ideas behind it inspired scientists to begin discussing the possibility of building an electronic brain.\nThe field of AI research was founded at a workshop held on the campus of Dartmouth College in 1956. Attendees of the workshop became the leaders of AI research for decades. Many of them predicted that machines as intelligent as humans would exist within a generation. The U.S. government provided millions of dollars with the hope of making this vision come true.\nEventually, it became obvious that researchers had grossly underestimated the difficulty of this feat. In 1974, criticism from James Lighthill and pressure from the U.S.A. Congress led the U.S. and British Governments to stop funding undirected research into artificial intelligence. Seven years later, a visionary initiative by the Japanese Government and the success of expert systems  reinvigorated investment in AI, and by the late 1980s, the industry had grown into a billion-dollar enterprise. However, investors' enthusiasm waned in the 1990s, and the field was criticized in the press and avoided by industry (a period known as an \"AI winter\"). Nevertheless, research and funding continued to grow under other names.\nIn the early 2000s, machine learning was applied to a wide range of problems in academia and industry. The success was due to the availability of powerful computer hardware, the collection of immense data sets, and the application of solid mathematical methods. Soon after, deep learning proved to be a breakthrough technology, eclipsing all other methods. The transformer architecture debuted in 2017 and was used to produce impressive generative AI applications, amongst other use cases.\nInvestment in AI boomed in the 2020s. The recent AI boom, initiated by the development of transformer architecture, led to the rapid scaling and public releases of large language models (LLMs) like ChatGPT. These models exhibit human-like traits of knowledge, attention, and creativity, and have been integrated into various sectors, fueling exponential investment in AI. However, concerns about the potential risks and ethical implications of advanced AI have also emerged, causing debate about the future of AI and its impact on society.\n\n\n== Precursors ==\n\n\n=== Mythical, fictional, and speculative precursors ===\n\n\n==== Myth and legend ====\nIn Greek mythology, Talos was a creature made of bronze who acted as guardian for the island of Crete. He would throw boulders at the ships of invaders and would complete 3 circuits around the island's perimeter daily. According to pseudo-Apollodorus' Bibliotheke, Hephaestus forged Talos with the aid of a cyclops and presented the automaton as a gift to Minos. In the Argonautica, Jason and the Argonauts defeated Talos by removing a plug near his foot, causing the vital ichor to flow out from his body and rendering him lifeless.\nPygmalion was a legendary king and sculptor of Greek mythology, famously represented in Ovid's Metamorphoses. In the 10th book of Ovid's narrative poem, Pygmalion becomes disgusted with women when he witnesses the way in which the Propoetides prostitute themselves. Despite this, he makes offerings at the temple of Venus asking the goddess to bring to him a woman just like a statue he carved.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3661, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "337000d0-3fe4-4aae-a2ae-d2dd68a65cbd": {"__data__": {"id_": "337000d0-3fe4-4aae-a2ae-d2dd68a65cbd", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2894560", "node_type": "4", "metadata": {}, "hash": "3f693a0322bab49ee1a9c95b0fad8b26f3b517c00c36665addff054ec94514ce", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bf5a447d-15e9-4ad8-a417-680587a46b11", "node_type": "1", "metadata": {}, "hash": "476799b0174868703b9ec1d0e4139da796a296f71be7b5cad75d6593e2ffde4c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "06c55d0d-c5bc-4be0-b343-a1dadbe3c7f5", "node_type": "1", "metadata": {}, "hash": "485c11e87e5065fcc05dcf397709b88127901e06fa9823c9846aaa28d2b48e8c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Medieval legends of artificial beings ====\n\nIn Of the Nature of Things, the Swiss alchemist Paracelsus describes a procedure that he claims can fabricate an \"artificial man\". By placing the \"sperm of a man\" in horse dung, and feeding it the \"Arcanum of Mans blood\" after 40 days, the concoction will become a living infant.\nThe earliest written account regarding golem-making is found in the writings of Eleazar ben Judah of Worms in the early 13th century. During the Middle Ages, it was believed that the animation of a Golem could be achieved by insertion of a piece of paper with any of God's names on it, into the mouth of the clay figure. Unlike legendary automata like Brazen Heads, a Golem was unable to speak.\nTakwin, the artificial creation of life, was a frequent topic of Ismaili alchemical manuscripts, especially those attributed to Jabir ibn Hayyan. Islamic alchemists attempted to create a broad range of life through their work, ranging from plants to animals.\nIn Faust: The Second Part of the Tragedy by Johann Wolfgang von Goethe, an alchemically fabricated homunculus, destined to live forever in the flask in which he was made, endeavors to be born into a full human body. Upon the initiation of this transformation, however, the flask shatters and the homunculus dies.\n\n\n==== Modern fiction ====\n\nBy the 19th century, ideas about artificial men and thinking machines became a popular theme in fiction. Notable works like Mary Shelley's Frankenstein  and Karel \u010capek's R.U.R. (Rossum's Universal Robots)\nexplored the concept of artificial life. Speculative essays, such as Samuel Butler's \"Darwin among the Machines\", and Edgar Allan Poe's \"Maelzel's Chess Player\" reflected society's growing interest in machines with artificial intelligence. AI remains a common topic in science fiction today.\n\n\n==== Automata ====\n\nRealistic humanoid automata were built by craftsman from many civilizations, including Yan Shi, Hero of Alexandria, Al-Jazari, Haroun al-Rashid, Jacques de Vaucanson, Leonardo Torres y Quevedo, Pierre Jaquet-Droz and Wolfgang von Kempelen.\nThe oldest known automata were the sacred statues of ancient Egypt and Greece. The faithful believed that craftsman had imbued these figures with very real minds, capable of wisdom and emotion\u2014Hermes Trismegistus wrote that \"by discovering the true nature of the gods, man has been able to reproduce it\". English scholar Alexander Neckham asserted that the Ancient Roman poet Virgil had built a palace with automaton statues.\nDuring the early modern period, these legendary automata were said to possess the magical ability to answer questions put to them. The late medieval alchemist and proto-Protestant Roger Bacon was purported to have fabricated a brazen head, having developed a legend of having been a wizard. These legends were similar to the Norse myth of the Head of M\u00edmir. According to legend, M\u00edmir was known for his intellect and wisdom, and was beheaded in the \u00c6sir-Vanir War. Odin is said to have \"embalmed\" the head with herbs and spoke incantations over it such that M\u00edmir's head remained able to speak wisdom to Odin. Odin then kept the head near him for counsel.", "mimetype": "text/plain", "start_char_idx": 3664, "end_char_idx": 6829, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "06c55d0d-c5bc-4be0-b343-a1dadbe3c7f5": {"__data__": {"id_": "06c55d0d-c5bc-4be0-b343-a1dadbe3c7f5", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2894560", "node_type": "4", "metadata": {}, "hash": "3f693a0322bab49ee1a9c95b0fad8b26f3b517c00c36665addff054ec94514ce", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "337000d0-3fe4-4aae-a2ae-d2dd68a65cbd", "node_type": "1", "metadata": {}, "hash": "e39044c4a507606b3d5ed7f4af9627a71ea95b3cbebcd46fa99bebff785e2173", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a9f41060-c6a3-42c7-ae1a-6777970c67c4", "node_type": "1", "metadata": {}, "hash": "ce1f3763195f91b70c078832846f0b2e5f04b1628d4659fa57b19dced55e43c6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Formal reasoning ===\nArtificial intelligence is based on the assumption that the process of human thought can be mechanized. The study of mechanical\u2014or \"formal\"\u2014reasoning has a long history. Chinese, Indian and Greek philosophers all developed structured methods of formal deduction by the first millennium BCE. Their ideas were developed over the centuries by philosophers such as Aristotle (who gave a formal analysis of the syllogism), Euclid (whose Elements was a model of formal reasoning), al-Khw\u0101rizm\u012b (who developed algebra and gave his name to the word algorithm) and European scholastic philosophers such as William of Ockham and Duns Scotus.\nSpanish philosopher Ramon Llull (1232\u20131315) developed several logical machines devoted to the production of knowledge by logical means; Llull described his machines as mechanical entities that could combine basic and undeniable truths by simple logical operations, produced by the machine by mechanical meanings, in such ways as to produce all the possible knowledge. Llull's work had a great influence on Gottfried Leibniz, who redeveloped his ideas.\n\nIn the 17th century, Leibniz, Thomas Hobbes and Ren\u00e9 Descartes explored the possibility that all rational thought could be made as systematic as algebra or geometry. Hobbes famously wrote in Leviathan: \"For reason ... is nothing but reckoning, that is adding and subtracting\". Leibniz envisioned a universal language of reasoning, the characteristica universalis, which would reduce argumentation to calculation so that \"there would be no more need of disputation between two philosophers than between two accountants. For it would suffice to take their pencils in hand, down to their slates, and to say each other (with a friend as witness, if they liked): Let us calculate.\" These philosophers had begun to articulate the physical symbol system hypothesis that would become the guiding faith of AI research.\nThe study of mathematical logic provided the essential breakthrough that made artificial intelligence seem plausible. The foundations had been set by such works as Boole's The Laws of Thought and Frege's Begriffsschrift. Building on Frege's system, Russell and Whitehead presented a formal treatment of the foundations of mathematics in their masterpiece, the Principia Mathematica in 1913. Inspired by Russell's success, David Hilbert challenged mathematicians of the 1920s and 30s to answer this fundamental question: \"can all of mathematical reasoning be formalized?\" His question was answered by G\u00f6del's incompleteness proof, Turing's machine and Church's Lambda calculus.\n\nTheir answer was surprising in two ways. First, they proved that there were, in fact, limits to what mathematical logic could accomplish. But second (and more important for AI) their work suggested that, within these limits, any form of mathematical reasoning could be mechanized. The Church-Turing thesis implied that a mechanical device, shuffling symbols as simple as 0 and 1, could imitate any conceivable process of mathematical deduction. The key insight was the Turing machine\u2014a simple theoretical construct that captured the essence of abstract symbol manipulation. This invention would inspire a handful of scientists to begin discussing the possibility of thinking machines.\n\n\n=== Computer science ===\n\nCalculating machines were designed or built in antiquity and throughout history by many people, including \nGottfried Leibniz,\nJoseph Marie Jacquard, \nCharles Babbage,\nPercy Ludgate,\nLeonardo Torres Quevedo,\nVannevar Bush,\nand others. Ada Lovelace speculated that Babbage's machine was \"a thinking or ... reasoning machine\", but warned \"It is desirable to guard against the possibility of exaggerated ideas that arise as to the powers\" of the machine.\nThe first modern computers were the massive machines of the Second World War (such as Konrad Zuse's Z3, Alan Turing's Heath Robinson and Colossus, Atanasoff and Berry's ABC and ENIAC at the University of Pennsylvania). ENIAC was based on the theoretical foundation laid by Alan Turing and developed by John von Neumann, and proved to be the most influential.", "mimetype": "text/plain", "start_char_idx": 6832, "end_char_idx": 10952, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a9f41060-c6a3-42c7-ae1a-6777970c67c4": {"__data__": {"id_": "a9f41060-c6a3-42c7-ae1a-6777970c67c4", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2894560", "node_type": "4", "metadata": {}, "hash": "3f693a0322bab49ee1a9c95b0fad8b26f3b517c00c36665addff054ec94514ce", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "06c55d0d-c5bc-4be0-b343-a1dadbe3c7f5", "node_type": "1", "metadata": {}, "hash": "485c11e87e5065fcc05dcf397709b88127901e06fa9823c9846aaa28d2b48e8c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2ede79d6-a38d-4ad4-9072-14d7f6fa65bb", "node_type": "1", "metadata": {}, "hash": "0535960c4c99d21d0f6bf2fc14402c2c5be5cfb162e1e66fa5d8adfbcc1e756b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Computer science ===\n\nCalculating machines were designed or built in antiquity and throughout history by many people, including \nGottfried Leibniz,\nJoseph Marie Jacquard, \nCharles Babbage,\nPercy Ludgate,\nLeonardo Torres Quevedo,\nVannevar Bush,\nand others. Ada Lovelace speculated that Babbage's machine was \"a thinking or ... reasoning machine\", but warned \"It is desirable to guard against the possibility of exaggerated ideas that arise as to the powers\" of the machine.\nThe first modern computers were the massive machines of the Second World War (such as Konrad Zuse's Z3, Alan Turing's Heath Robinson and Colossus, Atanasoff and Berry's ABC and ENIAC at the University of Pennsylvania). ENIAC was based on the theoretical foundation laid by Alan Turing and developed by John von Neumann, and proved to be the most influential.\n\n\n== Birth of artificial intelligence (1941-56) ==\n\nThe earliest research into thinking machines was inspired by a confluence of ideas that became prevalent in the late 1930s, 1940s, and early 1950s. Recent research in neurology had shown that the brain was an electrical network of neurons that fired in all-or-nothing pulses. Norbert Wiener's cybernetics described control and stability in electrical networks. Claude Shannon's information theory described digital signals (i.e., all-or-nothing signals). Alan Turing's theory of computation showed that any form of computation could be described digitally. The close relationship between these ideas suggested that it might be possible to construct an \"electronic brain\".\nIn the 1940s and 50s, a handful of scientists from a variety of fields (mathematics, psychology, engineering, economics and political science) explored several research directions that would be vital to later AI research. Alan Turing was among the first people to seriously investigate the theoretical possibility of \"machine intelligence\". The field of \"artificial intelligence research\" was founded as an academic discipline in 1956.\n\n\n=== Turing Test ===\n\nIn 1950 Turing published a landmark paper \"Computing Machinery and Intelligence\", in which he speculated about the possibility of creating machines that think. In the paper, he noted that \"thinking\" is difficult to define and devised his famous Turing Test: If a machine could carry on a conversation (over a teleprinter) that was indistinguishable from a conversation with a human being, then it was reasonable to say that the machine was \"thinking\". This simplified version of the problem allowed Turing to argue convincingly that a \"thinking machine\" was at least plausible and the paper answered all the most common objections to the proposition. The Turing Test was the first serious proposal in the philosophy of artificial intelligence.\n\n\n=== Neuroscience and Hebbian theory ===\nDonald Hebb was a Canadian psychologist whose work laid the foundation for modern neuroscience, particularly in understanding learning, memory, and neural plasticity. His most influential book, The Organization of Behavior (1949), introduced the concept of Hebbian learning, often summarized as \"cells that fire together wire together.\"\n\nHebb began formulating the foundational ideas for this book in the early 1940s, particularly during his time at the Yerkes Laboratories of Primate Biology from 1942 to 1947. He made extensive notes between June 1944 and March 1945 and sent a complete draft to his mentor Karl Lashley in 1946. The manuscript for The Organization of Behavior wasn\u2019t published until 1949. The delay was due to various factors, including World War II and shifts in academic focus. By the time it was published, several of his peers had already published related ideas, making Hebb\u2019s work seem less groundbreaking at first glance. However, his synthesis of psychological and neurophysiological principles became a cornerstone of neuroscience and machine learning.\n\n\n=== Artificial neural networks ===\nWalter Pitts and Warren McCulloch analyzed networks of idealized artificial neurons and showed how they might perform simple logical functions in 1943. They were the first to describe what later researchers would call a neural network. The paper was influenced by Turing's paper 'On Computable Numbers' from 1936 using similar two-state boolean 'neurons', but was the first to apply it to neuronal function. One of the students inspired by Pitts and McCulloch was Marvin Minsky who was a 24-year-old graduate student at the time. In 1951 Minsky and Dean Edmonds built the first neural net machine, the SNARC. Minsky would later become one of the most important leaders and innovators in AI.\n\n\n=== Cybernetic robots ===\nExperimental robots such as W. Grey Walter's turtles and the Johns Hopkins Beast, were built in the 1950s. These machines did not use computers, digital electronics or symbolic reasoning; they were controlled entirely by analog circuitry.", "mimetype": "text/plain", "start_char_idx": 10117, "end_char_idx": 14997, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2ede79d6-a38d-4ad4-9072-14d7f6fa65bb": {"__data__": {"id_": "2ede79d6-a38d-4ad4-9072-14d7f6fa65bb", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2894560", "node_type": "4", "metadata": {}, "hash": "3f693a0322bab49ee1a9c95b0fad8b26f3b517c00c36665addff054ec94514ce", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a9f41060-c6a3-42c7-ae1a-6777970c67c4", "node_type": "1", "metadata": {}, "hash": "ce1f3763195f91b70c078832846f0b2e5f04b1628d4659fa57b19dced55e43c6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e7cdee5d-f787-4990-b187-cef056780dbd", "node_type": "1", "metadata": {}, "hash": "776badf9e3d84ca9416fccb5776814d8950e7f7f7d33caf3d1dd42b1609ed3a9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Cybernetic robots ===\nExperimental robots such as W. Grey Walter's turtles and the Johns Hopkins Beast, were built in the 1950s. These machines did not use computers, digital electronics or symbolic reasoning; they were controlled entirely by analog circuitry.\n\n\n=== Game AI ===\nIn 1951, using the Ferranti Mark 1 machine of the University of Manchester, Christopher Strachey wrote a checkers program and Dietrich Prinz wrote one for chess. Arthur Samuel's checkers program, the subject of his 1959 paper \"Some Studies in Machine Learning Using the Game of Checkers\", eventually achieved sufficient skill to challenge a respectable amateur. Samuel's program was among the first uses of what would later be called machine learning. Game AI would continue to be used as a measure of progress in AI throughout its history.\n\n\n=== Symbolic reasoning and the Logic Theorist ===\n\nWhen access to digital computers became possible in the mid-fifties, a few scientists instinctively recognized that a machine that could manipulate numbers could also manipulate symbols and that the manipulation of symbols could well be the essence of human thought. This was a new approach to creating thinking machines.\nIn 1955, Allen Newell and future Nobel Laureate Herbert A. Simon created the \"Logic Theorist\", with help from J. C. Shaw. The program would eventually prove 38 of the first 52 theorems in Russell and Whitehead's Principia Mathematica, and find new and more elegant proofs for some. Simon said that they had \"solved the venerable mind/body problem, explaining how a system composed of matter can have the properties of mind.\" The symbolic reasoning paradigm they introduced would dominate AI research and funding until the middle 90s, as well as inspire the cognitive revolution.\n\n\n=== Dartmouth Workshop ===\n\nThe Dartmouth workshop of 1956 was a pivotal event that marked the formal inception of AI as an academic discipline. It was organized by Marvin Minsky and John McCarthy, with the support of two senior scientists Claude Shannon and Nathan Rochester of IBM. The proposal for the conference stated they intended to test the assertion that \"every aspect of learning or any other feature of intelligence can be so precisely described that a machine can be made to simulate it\". The term \"Artificial Intelligence\" was introduced by John McCarthy at the workshop. \nThe participants included Ray Solomonoff, Oliver Selfridge, Trenchard More, Arthur Samuel, Allen Newell and Herbert A. Simon, all of whom would create important programs during the first decades of AI research. At the workshop Newell and Simon debuted the \"Logic Theorist\". The workshop was the moment that AI gained its name, its mission, its first major success and its key players, and is widely considered the birth of AI.\n\n\n=== Cognitive revolution ===\n\nIn the autumn of 1956, Newell and Simon also presented the Logic Theorist at a meeting of the Special Interest Group in Information Theory at the Massachusetts Institute of Technology (MIT). At the same meeting, Noam Chomsky discussed his generative grammar, and George Miller described his landmark paper \"The Magical Number Seven, Plus or Minus Two\". Miller wrote \"I left the symposium with a conviction, more intuitive than rational, that experimental psychology, theoretical linguistics, and the computer simulation of cognitive processes were all pieces from a larger whole.\"\nThis meeting was the beginning of the \"cognitive revolution\"\u2014an interdisciplinary paradigm shift in psychology, philosophy, computer science and neuroscience. It inspired the creation of the sub-fields of symbolic artificial intelligence, generative linguistics, cognitive science, cognitive psychology, cognitive neuroscience and the philosophical schools of computationalism and functionalism. All these fields used related tools to model the mind and results discovered in one field were relevant to the others.\nThe cognitive approach allowed researchers to consider \"mental objects\" like thoughts, plans, goals, facts or memories, often analyzed using high level symbols in functional networks. These objects had been forbidden as \"unobservable\" by earlier paradigms such as behaviorism. Symbolic mental objects would become the major focus of AI research and funding for the next several decades.\n\n\n== Early successes (1956-1974) ==\nThe programs developed in the years after the Dartmouth Workshop were, to most people, simply \"astonishing\": computers were solving algebra word problems, proving theorems in geometry and learning to speak English. Few at the time would have believed that such \"intelligent\" behavior by machines was possible at all. Researchers expressed an intense optimism in private and in print, predicting that a fully intelligent machine would be built in less than 20 years. Government agencies like the Defense Advanced Research Projects Agency (DARPA, then known as \"ARPA\") poured money into the field. Artificial Intelligence laboratories were set up at a number of British and US universities in the latter 1950s and early 1960s.", "mimetype": "text/plain", "start_char_idx": 14733, "end_char_idx": 19801, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e7cdee5d-f787-4990-b187-cef056780dbd": {"__data__": {"id_": "e7cdee5d-f787-4990-b187-cef056780dbd", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2894560", "node_type": "4", "metadata": {}, "hash": "3f693a0322bab49ee1a9c95b0fad8b26f3b517c00c36665addff054ec94514ce", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2ede79d6-a38d-4ad4-9072-14d7f6fa65bb", "node_type": "1", "metadata": {}, "hash": "0535960c4c99d21d0f6bf2fc14402c2c5be5cfb162e1e66fa5d8adfbcc1e756b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a05374f6-a217-493a-91c9-70fdc6dfe087", "node_type": "1", "metadata": {}, "hash": "80e94e2a7611a11aed8538cc5827e301dd1bb988beca6c6e0785d72661674dec", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Early successes (1956-1974) ==\nThe programs developed in the years after the Dartmouth Workshop were, to most people, simply \"astonishing\": computers were solving algebra word problems, proving theorems in geometry and learning to speak English. Few at the time would have believed that such \"intelligent\" behavior by machines was possible at all. Researchers expressed an intense optimism in private and in print, predicting that a fully intelligent machine would be built in less than 20 years. Government agencies like the Defense Advanced Research Projects Agency (DARPA, then known as \"ARPA\") poured money into the field. Artificial Intelligence laboratories were set up at a number of British and US universities in the latter 1950s and early 1960s.\n\n\n=== Approaches ===\nThere were many successful programs and new directions in the late 50s and 1960s. Among the most influential were these:\n\n\n==== Reasoning, planning and problem solving as search ====\nMany early AI programs used the same basic algorithm. To achieve some goal (like winning a game or proving a theorem), they proceeded step by step towards it (by making a move or a deduction) as if searching through a maze, backtracking whenever they reached a dead end. The principal difficulty was that, for many problems, the number of possible paths through the \"maze\" was astronomical (a situation known as a \"combinatorial explosion\"). Researchers would reduce the search space by using heuristics that would eliminate paths that were unlikely to lead to a solution.\nNewell and Simon tried to capture a general version of this algorithm in a program called the \"General Problem Solver\". Other \"searching\" programs were able to accomplish impressive tasks like solving problems in geometry and algebra, such as Herbert Gelernter's Geometry Theorem Prover (1958) and Symbolic Automatic Integrator (SAINT), written by Minsky's student James Slagle in 1961. Other programs searched through goals and subgoals to plan actions, like the STRIPS system developed at Stanford to control the behavior of the robot Shakey.\n\n\n==== Natural language ====\n\nAn important goal of AI research is to allow computers to communicate in natural languages like English. An early success was Daniel Bobrow's program STUDENT, which could solve high school algebra word problems.\nA semantic net represents concepts (e.g. \"house\", \"door\") as nodes, and relations among concepts as links between the nodes (e.g. \"has-a\"). The first AI program to use a semantic net was written by Ross Quillian and the most successful (and controversial) version was Roger Schank's Conceptual dependency theory.\nJoseph Weizenbaum's ELIZA could carry out conversations that were so realistic that users occasionally were fooled into thinking they were communicating with a human being and not a computer program (see ELIZA effect). But in fact, ELIZA simply gave a canned response or repeated back what was said to it, rephrasing its response with a few grammar rules. ELIZA was the first chatbot.\n\n\n==== Micro-worlds ====\nIn the late 60s, Marvin Minsky and Seymour Papert of the MIT AI Laboratory proposed that AI research should focus on artificially simple situations known as micro-worlds. They pointed out that in successful sciences like physics, basic principles were often best understood using simplified models like frictionless planes or perfectly rigid bodies. Much of the research focused on a \"blocks world,\" which consists of colored blocks of various shapes and sizes arrayed on a flat surface.\nThis paradigm led to innovative work in machine vision by Gerald Sussman, Adolfo Guzman, David Waltz (who invented \"constraint propagation\"), and especially Patrick Winston. At the same time, Minsky and Papert built a robot arm that could stack blocks, bringing the blocks world to life. Terry Winograd's SHRDLU could communicate in ordinary English sentences about the micro-world, plan operations and execute them.", "mimetype": "text/plain", "start_char_idx": 19043, "end_char_idx": 22993, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a05374f6-a217-493a-91c9-70fdc6dfe087": {"__data__": {"id_": "a05374f6-a217-493a-91c9-70fdc6dfe087", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2894560", "node_type": "4", "metadata": {}, "hash": "3f693a0322bab49ee1a9c95b0fad8b26f3b517c00c36665addff054ec94514ce", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e7cdee5d-f787-4990-b187-cef056780dbd", "node_type": "1", "metadata": {}, "hash": "776badf9e3d84ca9416fccb5776814d8950e7f7f7d33caf3d1dd42b1609ed3a9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e832520c-2c13-4055-9a3e-4df1f765c0e9", "node_type": "1", "metadata": {}, "hash": "6f82b960216dc86789c3dcbf6a609318bac9658491b858d8b45febfca62d4ef6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Micro-worlds ====\nIn the late 60s, Marvin Minsky and Seymour Papert of the MIT AI Laboratory proposed that AI research should focus on artificially simple situations known as micro-worlds. They pointed out that in successful sciences like physics, basic principles were often best understood using simplified models like frictionless planes or perfectly rigid bodies. Much of the research focused on a \"blocks world,\" which consists of colored blocks of various shapes and sizes arrayed on a flat surface.\nThis paradigm led to innovative work in machine vision by Gerald Sussman, Adolfo Guzman, David Waltz (who invented \"constraint propagation\"), and especially Patrick Winston. At the same time, Minsky and Papert built a robot arm that could stack blocks, bringing the blocks world to life. Terry Winograd's SHRDLU could communicate in ordinary English sentences about the micro-world, plan operations and execute them.\n\n\n==== Perceptrons and early neural networks ====\n\nIn the 1960s funding was primarily directed towards laboratories researching symbolic AI, however several people still pursued research in neural networks.\n\nThe perceptron, a single-layer neural network was introduced in 1958 by Frank Rosenblatt (who had been a schoolmate of Marvin Minsky at the Bronx High School of Science). Like most AI researchers, he was optimistic about their power, predicting that a perceptron \"may eventually be able to learn, make decisions, and translate languages.\" Rosenblatt was primarily funded by Office of Naval Research.\nBernard Widrow and his student Ted Hoff built ADALINE (1960) and MADALINE (1962), which had up to 1000 adjustable weights. A group at Stanford Research Institute led by Charles A. Rosen and Alfred E. (Ted) Brain built two neural network machines named MINOS I (1960) and II (1963), mainly funded by U.S. Army Signal Corps. MINOS II had 6600 adjustable weights, and was controlled with an SDS 910 computer in a configuration named MINOS III (1968), which could classify symbols on army maps, and recognize hand-printed characters on Fortran coding sheets. Most of neural network research during this early period involved building and using bespoke hardware, rather than simulation on digital computers.\nHowever, partly due to lack of results and partly due to competition from symbolic AI research, the MINOS project ran out of funding in 1966. Rosenblatt failed to secure continued funding in the 1960s. In 1969, research came to a sudden halt with the publication of Minsky and Papert's 1969 book Perceptrons. It suggested that there were severe limitations to what perceptrons could do and that Rosenblatt's predictions had been grossly exaggerated. The effect of the book was that virtually no research was funded in connectionism for 10 years. The competition for government funding ended with the victory of symbolic AI approaches over neural networks.\nMinsky (who had worked on SNARC) became a staunch objector to pure connectionist AI. Widrow (who had worked on ADALINE) turned to adaptive signal processing. The SRI group (which worked on MINOS) turned to symbolic AI and robotics.\nThe main problem was the inability to train multilayered networks (versions of backpropagation had already been used in other fields but it was unknown to these researchers). The AI community became aware of backpropogation in the 80s, and, in the 21st century, neural networks would become enormously successful, fulfilling all of Rosenblatt's optimistic predictions. Rosenblatt did not live to see this, however, as he died in a boating accident in 1971.\n\n\n=== Optimism ===\nThe first generation of AI researchers made these predictions about their work:\n\n1958, H. A. Simon and Allen Newell: \"within ten years a digital computer will be the world's chess champion\" and \"within ten years a digital computer will discover and prove an important new mathematical theorem.\"\n1965, H. A. Simon: \"machines will be capable, within twenty years, of doing any work a man can do.\"\n1967, Marvin Minsky: \"Within a generation... the problem of creating 'artificial intelligence' will substantially be solved.\"\n1970, Marvin Minsky (in Life magazine): \"In from three to eight years we will have a machine with the general intelligence of an average human being.\"", "mimetype": "text/plain", "start_char_idx": 22066, "end_char_idx": 26340, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e832520c-2c13-4055-9a3e-4df1f765c0e9": {"__data__": {"id_": "e832520c-2c13-4055-9a3e-4df1f765c0e9", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2894560", "node_type": "4", "metadata": {}, "hash": "3f693a0322bab49ee1a9c95b0fad8b26f3b517c00c36665addff054ec94514ce", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a05374f6-a217-493a-91c9-70fdc6dfe087", "node_type": "1", "metadata": {}, "hash": "80e94e2a7611a11aed8538cc5827e301dd1bb988beca6c6e0785d72661674dec", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "feb0aa40-8067-4bb4-8062-cae21a5c75f5", "node_type": "1", "metadata": {}, "hash": "aa4e7d4e8393edf08ceef46d1d57f3674577f4b273d3357d29ff350e04eb9eac", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Optimism ===\nThe first generation of AI researchers made these predictions about their work:\n\n1958, H. A. Simon and Allen Newell: \"within ten years a digital computer will be the world's chess champion\" and \"within ten years a digital computer will discover and prove an important new mathematical theorem.\"\n1965, H. A. Simon: \"machines will be capable, within twenty years, of doing any work a man can do.\"\n1967, Marvin Minsky: \"Within a generation... the problem of creating 'artificial intelligence' will substantially be solved.\"\n1970, Marvin Minsky (in Life magazine): \"In from three to eight years we will have a machine with the general intelligence of an average human being.\"\n\n\n=== Financing ===\nIn June 1963, MIT received a $2.2 million grant from the newly created Advanced Research Projects Agency (ARPA, later known as DARPA). The money was used to fund project MAC which subsumed the \"AI Group\" founded by Minsky and McCarthy five years earlier. DARPA continued to provide $3 million each year until the 70s. DARPA made similar grants to Newell and Simon's program at Carnegie Mellon University and to Stanford University's AI Lab, founded by John McCarthy in 1963. Another important AI laboratory was established at Edinburgh University by Donald Michie in 1965. These four institutions would continue to be the main centers of AI research and funding in academia for many years.\nThe money was given with few strings attached: J. C. R. Licklider, then the director of ARPA, believed that his organization should \"fund people, not projects!\" and allowed researchers to pursue whatever directions might interest them.  This created a freewheeling atmosphere at MIT that gave birth to the hacker culture, but this \"hands off\" approach did not last.\n\n\n== First AI Winter (1974\u20131980) ==\nIn the 1970s, AI was subject to critiques and financial setbacks. AI researchers had failed to appreciate the difficulty of the problems they faced. Their tremendous optimism had raised public expectations impossibly high, and when the promised results failed to materialize, funding targeted at AI was severely reduced. The lack of success indicated the techniques being used by AI researchers at the time were insufficient to achieve their goals.\nThese setbacks did not affect the growth and progress of the field, however. The funding cuts only impacted a handful of major laboratories and the critiques were largely ignored. General public interest in the field continued to grow, the number of researchers increased dramatically, and new ideas were explored in logic programming, commonsense reasoning and many other areas. Historian Thomas Haigh argued in 2023 that there was no winter, and AI researcher Nils Nilsson described this period as the most \"exciting\" time to work in AI.", "mimetype": "text/plain", "start_char_idx": 25652, "end_char_idx": 28441, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "feb0aa40-8067-4bb4-8062-cae21a5c75f5": {"__data__": {"id_": "feb0aa40-8067-4bb4-8062-cae21a5c75f5", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2894560", "node_type": "4", "metadata": {}, "hash": "3f693a0322bab49ee1a9c95b0fad8b26f3b517c00c36665addff054ec94514ce", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e832520c-2c13-4055-9a3e-4df1f765c0e9", "node_type": "1", "metadata": {}, "hash": "6f82b960216dc86789c3dcbf6a609318bac9658491b858d8b45febfca62d4ef6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e001d43a-dfc3-457c-a172-4baaa93b33a8", "node_type": "1", "metadata": {}, "hash": "d30c1fa3821c9a0ee1c643959181c96abcb3ba8268abec8eaa7f1255a2ed074c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== First AI Winter (1974\u20131980) ==\nIn the 1970s, AI was subject to critiques and financial setbacks. AI researchers had failed to appreciate the difficulty of the problems they faced. Their tremendous optimism had raised public expectations impossibly high, and when the promised results failed to materialize, funding targeted at AI was severely reduced. The lack of success indicated the techniques being used by AI researchers at the time were insufficient to achieve their goals.\nThese setbacks did not affect the growth and progress of the field, however. The funding cuts only impacted a handful of major laboratories and the critiques were largely ignored. General public interest in the field continued to grow, the number of researchers increased dramatically, and new ideas were explored in logic programming, commonsense reasoning and many other areas. Historian Thomas Haigh argued in 2023 that there was no winter, and AI researcher Nils Nilsson described this period as the most \"exciting\" time to work in AI.\n\n\n=== Problems ===\nIn the early seventies, the capabilities of AI programs were limited. Even the most impressive could only handle trivial versions of the problems they were supposed to solve; all the programs were, in some sense, \"toys\". AI researchers had begun to run into several limits that would be only conquered decades later, and others that still stymie the field in the 2020s:\n\nLimited computer power: There was not enough memory or processing speed to accomplish anything truly useful. For example: Ross Quillian's successful work on natural language was demonstrated with a vocabulary of only 20 words, because that was all that would fit in memory. Hans Moravec argued in 1976 that computers were still millions of times too weak to exhibit intelligence. He suggested an analogy: artificial intelligence requires computer power in the same way that aircraft require horsepower. Below a certain threshold, it's impossible, but, as power increases, eventually it could become easy. \"With enough horsepower,\" he wrote, \"anything will fly\".\nIntractability and the combinatorial explosion: In 1972 Richard Karp (building on Stephen Cook's 1971 theorem) showed there are many problems that can only be solved in exponential time. Finding optimal solutions to these problems requires extraordinary amounts of computer time, except when the problems are trivial. This limitation applied to all symbolic AI programs that used search trees and meant that many of the \"toy\" solutions used by AI would never scale to useful systems.\nMoravec's paradox: Early AI research had been very successful at getting computers to do \"intelligent\" tasks like proving theorems, solving geometry problems and playing chess. Their success at these intelligent tasks convinced them that the problem of intelligent behavior had been largely solved. However, they utterly failed to make progress on \"unintelligent\" tasks like recognizing a face or crossing a room without bumping into anything. By the 1980s, researchers would realize that symbolic reasoning was utterly unsuited for these perceptual and sensorimotor tasks and that there were limits to this approach.\nThe breadth of commonsense knowledge: Many important artificial intelligence applications like vision or natural language require enormous amounts of information about the world: the program needs to have some idea of what it might be looking at or what it is talking about. This requires that the program know most of the same things about the world that a child does. Researchers soon discovered that this was a vast amount of information with billions of atomic facts. No one in 1970 could build a database large enough and no one knew how a program might learn so much information.\nRepresenting commonsense reasoning: A number of related problems appeared when researchers tried to represent commonsense reasoning using formal logic or symbols.  Descriptions of very ordinary deductions tended to get longer and longer the more one worked on them, as more and more exceptions, clarifications and distinctions were required. However, when people thought about ordinary concepts they did not rely on precise definitions, rather they seemed to make hundreds of imprecise assumptions, correcting them when necessary using their entire body of commonsense knowledge. Gerald Sussman observed that \"using precise language to describe essentially imprecise concepts doesn't make them any more precise.\"", "mimetype": "text/plain", "start_char_idx": 27419, "end_char_idx": 31894, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e001d43a-dfc3-457c-a172-4baaa93b33a8": {"__data__": {"id_": "e001d43a-dfc3-457c-a172-4baaa93b33a8", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2894560", "node_type": "4", "metadata": {}, "hash": "3f693a0322bab49ee1a9c95b0fad8b26f3b517c00c36665addff054ec94514ce", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "feb0aa40-8067-4bb4-8062-cae21a5c75f5", "node_type": "1", "metadata": {}, "hash": "aa4e7d4e8393edf08ceef46d1d57f3674577f4b273d3357d29ff350e04eb9eac", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "16df7dc2-c5b0-4226-b2cb-ce8011e53851", "node_type": "1", "metadata": {}, "hash": "7af1ca56c758c7bb9a9e2f7cf794766c79860e2517674f3de76bd8f09b5370b4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Decrease in funding ===\n\nThe agencies which funded AI research, such as the British government, DARPA and the National Research Council (NRC) became frustrated with the lack of progress and eventually cut off almost all funding for undirected AI research. The pattern began in 1966 when the Automatic Language Processing Advisory Committee (ALPAC) report criticized machine translation efforts. After spending $20 million, the NRC ended all support. In 1973, the Lighthill report on the state of AI research in the UK criticized the failure of AI to achieve its \"grandiose objectives\" and led to the dismantling of AI research in that country. (The report specifically mentioned the combinatorial explosion problem as a reason for AI's failings.) DARPA was deeply disappointed with researchers working on the Speech Understanding Research program at CMU and canceled an annual grant of $3 million.\nHans Moravec blamed the crisis on the unrealistic predictions of his colleagues. \"Many researchers were caught up in a web of increasing exaggeration.\" However, there was another issue: since the passage of the Mansfield Amendment in 1969, DARPA had been under increasing pressure to fund \"mission-oriented direct research, rather than basic undirected research\". Funding for the creative, freewheeling exploration that had gone on in the 60s would not come from DARPA, which instead directed money at specific projects with clear objectives, such as autonomous tanks and battle management systems.\nThe major laboratories (MIT, Stanford, CMU and Edinburgh) had been receiving generous support from their governments, and when it was withdrawn, these were the only places that were seriously impacted by the budget cuts. The thousands of researchers outside these institutions and the many more thousands that were joining the field were unaffected.\n\n\n=== Philosophical and ethical critiques ===\n\nSeveral philosophers had strong objections to the claims being made by AI researchers. One of the earliest was John Lucas, who argued that G\u00f6del's incompleteness theorem showed that a formal system (such as a computer program) could never see the truth of certain statements, while a human being could. Hubert Dreyfus ridiculed the broken promises of the 1960s and critiqued the assumptions of AI, arguing that human reasoning actually involved very little \"symbol processing\" and a great deal of embodied, instinctive, unconscious \"know how\". John Searle's Chinese Room argument, presented in 1980, attempted to show that a program could not be said to \"understand\" the symbols that it uses (a quality called \"intentionality\"). If the symbols have no meaning for the machine, Searle argued, then the machine can not be described as \"thinking\".\nThese critiques were not taken seriously by AI researchers. Problems like intractability and commonsense knowledge seemed much more immediate and serious. It was unclear what difference \"know how\" or \"intentionality\" made to an actual computer program. MIT's Minsky said of Dreyfus and Searle \"they misunderstand, and should be ignored.\" Dreyfus, who also taught at MIT, was given a cold shoulder: he later said that AI researchers \"dared not be seen having lunch with me.\" Joseph Weizenbaum, the author of ELIZA, was also an outspoken critic of Dreyfus' positions, but he \"deliberately made it plain that [his AI colleagues' treatment of Dreyfus] was not the way to treat a human being,\" and was unprofessional and childish.\nWeizenbaum began to have serious ethical doubts about AI when Kenneth Colby wrote a \"computer program which can conduct psychotherapeutic dialogue\" based on ELIZA. Weizenbaum was disturbed that Colby saw a mindless program as a serious therapeutic tool. A feud began, and the situation was not helped when Colby did not credit Weizenbaum for his contribution to the program. In 1976, Weizenbaum published Computer Power and Human Reason which argued that the misuse of artificial intelligence has the potential to devalue human life.", "mimetype": "text/plain", "start_char_idx": 31897, "end_char_idx": 35899, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "16df7dc2-c5b0-4226-b2cb-ce8011e53851": {"__data__": {"id_": "16df7dc2-c5b0-4226-b2cb-ce8011e53851", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2894560", "node_type": "4", "metadata": {}, "hash": "3f693a0322bab49ee1a9c95b0fad8b26f3b517c00c36665addff054ec94514ce", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e001d43a-dfc3-457c-a172-4baaa93b33a8", "node_type": "1", "metadata": {}, "hash": "d30c1fa3821c9a0ee1c643959181c96abcb3ba8268abec8eaa7f1255a2ed074c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "529e8857-e054-41cf-9d4b-b9b218b902a3", "node_type": "1", "metadata": {}, "hash": "73c2bef57416ebefc50ffe05a6a5e89896a098e827a2118617b736424d878ba2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Logic at Stanford, CMU and Edinburgh ===\nLogic was introduced into AI research as early as 1958, by John McCarthy in his Advice Taker proposal. In 1963, J. Alan Robinson had discovered a simple method to implement deduction on computers, the resolution and unification algorithm. However, straightforward implementations, like those attempted by McCarthy and his students in the late 1960s, were especially intractable: the programs required astronomical numbers of steps to prove simple theorems. A more fruitful approach to logic was developed in the 1970s by Robert Kowalski at the University of Edinburgh, and soon this led to the collaboration with French researchers Alain Colmerauer and Philippe Roussel who created the successful logic programming language Prolog. Prolog uses a subset of logic (Horn clauses, closely related to \"rules\" and \"production rules\") that permit tractable computation. Rules would continue to be influential, providing a foundation for Edward Feigenbaum's expert systems and the continuing work by Allen Newell and Herbert A. Simon that would lead to Soar and their unified theories of cognition.\nCritics of the logical approach noted, as Dreyfus had, that human beings rarely used logic when they solved problems. Experiments by psychologists like Peter Wason, Eleanor Rosch, Amos Tversky, Daniel Kahneman and others provided proof. McCarthy responded that what people do is irrelevant. He argued that what is really needed are machines that can solve problems\u2014not machines that think as people do.\n\n\n=== MIT's \"anti-logic\" approach ===\nAmong the critics of McCarthy's approach were his colleagues across the country at MIT. Marvin Minsky, Seymour Papert and Roger Schank were trying to solve problems like \"story understanding\" and \"object recognition\" that required a machine to think like a person. In order to use ordinary concepts like \"chair\" or \"restaurant\" they had to make all the same illogical assumptions that people normally made. Unfortunately, imprecise concepts like these are hard to represent in logic. MIT chose instead to focus on writing programs that solved a given task without using high-level abstract definitions or general theories of cognition, and measured performance by iterative testing, rather than arguments from first principles. Schank described their \"anti-logic\" approaches as scruffy, as opposed to the neat paradigm used by McCarthy, Kowalski, Feigenbaum, Newell and Simon.\nIn 1975, in a seminal paper, Minsky noted that many of his fellow researchers were using the same kind of tool: a framework that captures all our common sense assumptions about something. For example, if we use the concept of a bird, there is a constellation of facts that immediately come to mind: we might assume that it flies, eats worms and so on (none of which are true for all birds). Minsky associated these assumptions with the general category and they could be inherited by the frames for subcategories and individuals, or over-ridden as necessary. He called these structures frames. Schank used a version of frames he called \"scripts\" to successfully answer questions about short stories in English. Frames would eventually be widely used in software engineering under the name object-oriented programming.\nThe logicians rose to the challenge. Pat Hayes claimed that \"most of 'frames' is just a new syntax for parts of first-order logic.\" But he noted that \"there are one or two apparently minor details which give a lot of trouble, however, especially defaults\".\nRay Reiter admitted that \"conventional logics, such as first-order\nlogic, lack the expressive power to adequately represent the knowledge required for reasoning by default\". He proposed augmenting first-order logic with a closed world assumption that a conclusion holds (by default) if its contrary cannot be shown. He showed how such an assumption corresponds to the common sense assumption made in reasoning with frames. He also showed that it has its \"procedural equivalent\" as negation as failure in Prolog. The closed world assumption, as formulated by Reiter, \"is not a first-order notion. (It is a meta notion.)\" However, Keith Clark showed that negation as finite failure can be understood as reasoning implicitly with definitions in first-order logic including a unique name assumption that different terms denote different individuals.\nDuring the late 1970s and throughout the 1980s, a variety of logics and extensions of first-order logic were developed both for negation as failure in logic programming and for default reasoning more generally. Collectively, these logics have become known as non-monotonic logics.", "mimetype": "text/plain", "start_char_idx": 35902, "end_char_idx": 40557, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "529e8857-e054-41cf-9d4b-b9b218b902a3": {"__data__": {"id_": "529e8857-e054-41cf-9d4b-b9b218b902a3", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2894560", "node_type": "4", "metadata": {}, "hash": "3f693a0322bab49ee1a9c95b0fad8b26f3b517c00c36665addff054ec94514ce", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "16df7dc2-c5b0-4226-b2cb-ce8011e53851", "node_type": "1", "metadata": {}, "hash": "7af1ca56c758c7bb9a9e2f7cf794766c79860e2517674f3de76bd8f09b5370b4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c1073fb2-a12d-4dc1-8d1e-fe0e81452a49", "node_type": "1", "metadata": {}, "hash": "d3ed24549a368d94de1a2a26b0b3a664e5ab3e748fc74eb67204e3ca67d13cdb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Boom (1980\u20131987) ==\nIn the 1980s, a form of AI program called \"expert systems\" was adopted by corporations around the world and knowledge became the focus of mainstream AI research. Governments provided substantial funding, such as Japan's fifth generation computer project and the U.S. Strategic Computing Initiative. \"Overall, the AI industry boomed from a few million dollars in 1980 to billions of dollars in 1988.\"\n\n\n=== Expert systems become widely used ===\nAn expert system is a program that answers questions or solves problems about a specific domain of knowledge, using logical rules that are derived from the knowledge of experts.\nThe earliest examples were developed by Edward Feigenbaum and his students. Dendral, begun in 1965, identified compounds from spectrometer readings. MYCIN, developed in 1972, diagnosed infectious blood diseases. They demonstrated the feasibility of the approach.\nExpert systems restricted themselves to a small domain of specific knowledge (thus avoiding the commonsense knowledge problem) and their simple design made it relatively easy for programs to be built and then modified once they were in place. All in all, the programs proved to be useful: something that AI had not been able to achieve up to this point.\nIn 1980, an expert system called R1 was completed at CMU for the Digital Equipment Corporation. It was an enormous success: it was saving the company 40 million dollars annually by 1986. Corporations around the world began to develop and deploy expert systems and by 1985 they were spending over a billion dollars on AI, most of it to in-house AI departments. An industry grew up to support them, including hardware companies like Symbolics and Lisp Machines and software companies such as IntelliCorp and Aion.\n\n\n=== Government funding increases ===\nIn 1981, the Japanese Ministry of International Trade and Industry set aside $850 million for the Fifth generation computer project. Their objectives were to write programs and build machines that could carry on conversations, translate languages, interpret pictures, and reason like human beings. Much to the chagrin of scruffies, they initially chose Prolog as the primary computer language for the project.\nOther countries responded with new programs of their own. The UK began the \u00a3350 million Alvey project. A consortium of American companies formed the Microelectronics and Computer Technology Corporation (or \"MCC\") to fund large scale projects in AI and information technology. DARPA responded as well, founding the Strategic Computing Initiative and tripling its investment in AI between 1984 and 1988.\n\n\n=== Knowledge revolution ===\nThe power of expert systems came from the expert knowledge they contained. They were part of a new direction in AI research that had been gaining ground throughout the 70s. \"AI researchers were beginning to suspect\u2014reluctantly, for it violated the scientific canon of parsimony\u2014that intelligence might very well be based on the ability to use large amounts of diverse knowledge in different ways,\" writes Pamela McCorduck. \"[T]he great lesson from the 1970s was that intelligent behavior depended very much on dealing with knowledge, sometimes quite detailed knowledge, of a domain where a given task lay\". Knowledge based systems and knowledge engineering became a major focus of AI research in the 1980s. It was hoped that vast databases would solve the commonsense knowledge problem and provide the support that commonsense reasoning required.\nIn the 1980s some researchers attempted to attack the commonsense knowledge problem directly, by creating a massive database that would contain all the mundane facts that the average person knows. Douglas Lenat, who started a database called Cyc, argued that there is no shortcut \u2015 the only way for machines to know the meaning of human concepts is to teach them, one concept at a time, by hand.\n\n\n== New directions in the 1980s ==\nAlthough symbolic knowledge representation and logical reasoning produced useful applications in the 80s and received massive amounts of funding, it was still unable to solve problems in perception, robotics, learning and common sense. A small number of scientists and engineers began to doubt that the symbolic approach would ever be sufficient for these tasks and developed other approaches, such as \"connectionism\", robotics, \"soft\" computing and reinforcement learning. Nils Nilsson called these approaches \"sub-symbolic\".", "mimetype": "text/plain", "start_char_idx": 40560, "end_char_idx": 45021, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c1073fb2-a12d-4dc1-8d1e-fe0e81452a49": {"__data__": {"id_": "c1073fb2-a12d-4dc1-8d1e-fe0e81452a49", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2894560", "node_type": "4", "metadata": {}, "hash": "3f693a0322bab49ee1a9c95b0fad8b26f3b517c00c36665addff054ec94514ce", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "529e8857-e054-41cf-9d4b-b9b218b902a3", "node_type": "1", "metadata": {}, "hash": "73c2bef57416ebefc50ffe05a6a5e89896a098e827a2118617b736424d878ba2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c5bc599c-4fed-4424-a581-e4084dc88cc6", "node_type": "1", "metadata": {}, "hash": "b34c2b5fc3edcf58556548c92c909fa4a9e56a2fb2f4015a19b3e65b80ee4a04", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== New directions in the 1980s ==\nAlthough symbolic knowledge representation and logical reasoning produced useful applications in the 80s and received massive amounts of funding, it was still unable to solve problems in perception, robotics, learning and common sense. A small number of scientists and engineers began to doubt that the symbolic approach would ever be sufficient for these tasks and developed other approaches, such as \"connectionism\", robotics, \"soft\" computing and reinforcement learning. Nils Nilsson called these approaches \"sub-symbolic\".\n\n\n=== Revival of neural networks: \"connectionism\" ===\n\nIn 1982, physicist John Hopfield was able to prove that a form of neural network (now called a \"Hopfield net\") could learn and process information, and provably converges after enough time under any fixed condition. It was a breakthrough, as it was previously thought that nonlinear networks would, in general, evolve chaotically. Around the same time, Geoffrey Hinton and David Rumelhart popularized a method for training neural networks called \"backpropagation\". These two developments helped to revive the exploration of artificial neural networks.\nNeural networks, along with several other similar models, received widespread attention after the 1986 publication of the Parallel Distributed Processing, a two volume collection of papers edited by Rumelhart and psychologist James McClelland. The new field was christened \"connectionism\" and there was a considerable debate between advocates of symbolic AI and the \"connectionists\". Hinton called symbols the \"luminous aether of AI\" \u2013 that is, an unworkable and misleading model of intelligence. This was a direct attack on the principles that inspired the cognitive revolution.\nNeural networks started to advance state of the art in some specialist areas such as protein structure prediction. Following pioneering work from Terry Sejnowski, cascading multilayer perceptrons such as PhD and PsiPred reached near-theoretical maximum accuracy in predicting secondary structure.\nIn 1990, Yann LeCun at Bell Labs used convolutional neural networks to recognize handwritten digits. The system was used widely in 90s, reading zip codes and personal checks. This was the first genuinely useful application of neural networks.\n\n\n=== Robotics and embodied reason ===\n\nRodney Brooks, Hans Moravec and others argued that, in order to show real intelligence, a machine needs to have a body \u2014 it needs to perceive, move, survive and deal with the world. Sensorimotor skills are essential to higher level skills such as commonsense reasoning. They can't be efficiently implemented using abstract symbolic reasoning, so AI should solve the problems of perception, mobility, manipulation and survival without using symbolic representation at all. These robotics researchers advocated building intelligence \"from the bottom up\".\nA precursor to this idea was David Marr, who had come to MIT in the late 1970s from a successful background in theoretical neuroscience to lead the group studying vision. He rejected all symbolic approaches (both McCarthy's logic and Minsky's frames), arguing that AI needed to understand the physical machinery of vision from the bottom up before any symbolic processing took place. (Marr's work would be cut short by leukemia in 1980.)\nIn his 1990 paper \"Elephants Don't Play Chess,\" robotics researcher Brooks took direct aim at the physical symbol system hypothesis, arguing that symbols are not always necessary since \"the world is its own best model. It is always exactly up to date. It always has every detail there is to be known. The trick is to sense it appropriately and often enough.\"\nIn the 1980s and 1990s, many cognitive scientists also rejected the symbol processing model of the mind and argued that the body was essential for reasoning, a theory called the \"embodied mind thesis\".\n\n\n=== Soft computing and probabilistic reasoning ===\nSoft computing uses methods that work with incomplete and imprecise information. They do not attempt to give precise, logical answers, but give results that are only \"probably\" correct. This allowed them to solve problems that precise symbolic methods could not handle. Press accounts often claimed these tools could \"think like a human\".\nJudea Pearl's Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference, an influential 1988 book brought probability and decision theory into AI. Fuzzy logic, developed by Lofti Zadeh in the 60s, began to be more widely used in AI and robotics. Evolutionary computation and artificial neural networks also handle imprecise information, and are classified  as \"soft\". In the 90s and early 2000s many other soft computing tools were developed and put into use, including Bayesian networks, hidden Markov models, information theory and stochastic modeling. These tools in turn depended on advanced mathematical techniques such as classical optimization. For a time in the 1990s and early 2000s, these soft tools were studied by a subfield of AI called \"computational intelligence\".", "mimetype": "text/plain", "start_char_idx": 44461, "end_char_idx": 49534, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c5bc599c-4fed-4424-a581-e4084dc88cc6": {"__data__": {"id_": "c5bc599c-4fed-4424-a581-e4084dc88cc6", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2894560", "node_type": "4", "metadata": {}, "hash": "3f693a0322bab49ee1a9c95b0fad8b26f3b517c00c36665addff054ec94514ce", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c1073fb2-a12d-4dc1-8d1e-fe0e81452a49", "node_type": "1", "metadata": {}, "hash": "d3ed24549a368d94de1a2a26b0b3a664e5ab3e748fc74eb67204e3ca67d13cdb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b5df004a-a492-45c4-944c-b32f65bf9718", "node_type": "1", "metadata": {}, "hash": "caa42b8d3fe4b4d02da56fc4cfc7c0c74f125b78ff2668bdc2c8069d7494ed42", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Reinforcement learning ===\nReinforcement learning gives an agent a reward every time it performs a desired action well, and may give negative rewards (or \"punishments\") when it performs poorly. It was described in the first half of the twentieth century by psychologists using animal models, such as Thorndike, Pavlov and Skinner. In the 1950s, Alan Turing and Arthur Samuel foresaw the role of reinforcement learning in AI.\nA successful and influential research program was led by Richard Sutton and Andrew Barto beginning 1972. Their collaboration revolutionized the study of reinforcement learning and decision making over the four decades. In 1988, Sutton described machine learning in terms of decision theory (i.e., the Markov decision process). This gave the subject a solid theoretical foundation and access to a large body of theoretical results developed in the field of operations research.\nAlso in 1988, Sutton and Barto developed the \"temporal difference\" (TD) learning algorithm, where the agent is rewarded only when its predictions about the future show improvement. It significantly outperformed previous algorithms. TD-learning was used by Gerald Tesauro in 1992 in the program TD-Gammon, which played backgammon as well as the best human players. The program learned the game by playing against itself with zero prior knowledge. In an interesting case of interdisciplinary convergence, neurologists discovered in 1997 that the dopamine reward system in brains also uses a version of the TD-learning algorithm. TD learning would be become highly influential in the 21st century, used in both AlphaGo and AlphaZero.\n\n\n== Second AI winter ==\nThe business community's fascination with AI rose and fell in the 1980s in the classic pattern of an economic bubble. As dozens of companies failed, the perception in the business world was that the technology was not viable. The damage to AI's reputation would last into the 21st century. Inside the field there was little agreement on the reasons for AI's failure to fulfill the dream of human level intelligence that had captured the imagination of the world in the 1960s. Together, all these factors helped to fragment AI into competing subfields focused on particular problems or approaches, sometimes even under new names that disguised the tarnished pedigree of \"artificial intelligence\".\nOver the next 20 years, AI consistently delivered working solutions to specific isolated problems. By the late 1990s, it was being used throughout the technology industry, although somewhat behind the scenes. The success was due to increasing computer power, by collaboration with other fields (such as mathematical optimization and statistics) and using the highest standards of scientific accountability.                                                                            By 2000, AI had achieved some of its oldest goals. The field was both more cautious and more successful than it had ever been.\n\n\n=== AI winter ===\nThe term \"AI winter\" was coined by researchers who had survived the funding cuts of 1974 when they became concerned that enthusiasm for expert systems had spiraled out of control and that disappointment would certainly follow. Their fears were well founded: in the late 1980s and early 1990s, AI suffered a series of financial setbacks.\nThe first indication of a change in weather was the sudden collapse of the market for specialized AI hardware in 1987. Desktop computers from Apple and IBM had been steadily gaining speed and power and in 1987 they became more powerful than the more expensive Lisp machines made by Symbolics and others. There was no longer a good reason to buy them. An entire industry worth half a billion dollars was demolished overnight.\nEventually the earliest successful expert systems, such as XCON, proved too expensive to maintain. They were difficult to update, they could not learn, and they were \"brittle\" (i.e., they could make grotesque mistakes when given unusual inputs). Expert systems proved useful, but only in a few special contexts.\nIn the late 1980s, the Strategic Computing Initiative cut funding to AI \"deeply and brutally\". New leadership at DARPA had decided that AI was not \"the next wave\" and directed funds towards projects that seemed more likely to produce immediate results.\nBy 1991, the impressive list of goals penned in 1981 for Japan's Fifth Generation Project had not been met. Indeed, some of them, like \"carry on a casual conversation\" would not be accomplished for another 30 years. As with other AI projects, expectations had run much higher than what was actually possible.\nOver 300 AI companies had shut down, gone bankrupt, or been acquired by the end of 1993, effectively ending the first commercial wave of AI. In 1994, HP Newquist stated in The Brain Makers that \"The immediate future of artificial intelligence\u2014in its commercial form\u2014seems to rest in part on the continued success of neural networks.\"", "mimetype": "text/plain", "start_char_idx": 49537, "end_char_idx": 54493, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b5df004a-a492-45c4-944c-b32f65bf9718": {"__data__": {"id_": "b5df004a-a492-45c4-944c-b32f65bf9718", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2894560", "node_type": "4", "metadata": {}, "hash": "3f693a0322bab49ee1a9c95b0fad8b26f3b517c00c36665addff054ec94514ce", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c5bc599c-4fed-4424-a581-e4084dc88cc6", "node_type": "1", "metadata": {}, "hash": "b34c2b5fc3edcf58556548c92c909fa4a9e56a2fb2f4015a19b3e65b80ee4a04", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f6908e55-36e1-44b8-8a1c-0b61ecad8974", "node_type": "1", "metadata": {}, "hash": "b91ae6aed09b958ad0db8c57075580cc5dbe9d3234998bde8ac2dd95a8966d01", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== AI behind the scenes ===\nIn the 1990s, algorithms originally developed by AI researchers began to appear as parts of larger systems. AI had solved a lot of very difficult problems and their solutions proved to be useful throughout the technology industry, such as data mining, industrial robotics, logistics, speech recognition, banking software, medical diagnosis and Google's search engine.\nThe field of AI received little or no credit for these successes in the 1990s and early 2000s. Many of AI's greatest innovations have been reduced to the status of just another item in the tool chest of computer science. Nick Bostrom explains: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"\nMany researchers in AI in the 1990s deliberately called their work by other names, such as informatics, knowledge-based systems, \"cognitive systems\" or computational intelligence. In part, this may have been because they considered their field to be fundamentally different from AI, but also the new names help to procure funding. In the commercial world at least, the failed promises of the AI Winter continued to haunt AI research into the 2000s, as the New York Times reported in 2005: \"Computer scientists and software engineers avoided the term artificial intelligence for fear of being viewed as wild-eyed dreamers.\"\n\n\n=== Mathematical rigor, greater collaboration and a narrow focus ===\nAI researchers began to develop and use sophisticated mathematical tools more than they ever had in the past. Most of the new directions in AI relied heavily on mathematical models, including artificial neural networks, probabilistic reasoning, soft computing and reinforcement learning. In the 90s and 2000s, many other highly mathematical tools were adapted for AI. These tools were applied to machine learning, perception and mobility.\nThere was a widespread realization that many of the problems that AI needed to solve were already being worked on by researchers in fields like statistics, mathematics, electrical engineering, economics or operations research. The shared mathematical language allowed both a higher level of collaboration with more established and successful fields and the achievement of results which were measurable and provable; AI had become a more rigorous \"scientific\" discipline.\nAnother key reason for the success in the 90s was that AI researchers focussed on specific problems with verifiable solutions (an approach later derided as narrow AI). This provided useful tools in the present, rather than speculation about the future.\n\n\n=== Intelligent agents ===\nA new paradigm called \"intelligent agents\" became widely accepted during the 1990s. Although earlier researchers had proposed modular \"divide and conquer\" approaches to AI, the intelligent agent did not reach its modern form until Judea Pearl, Allen Newell, Leslie P. Kaelbling, and others brought concepts from decision theory and economics into the study of AI. When the economist's definition of a rational agent was married to computer science's definition of an object or module, the intelligent agent paradigm was complete.\nAn intelligent agent is a system that perceives its environment and takes actions which maximize its chances of success. By this definition, simple programs that solve specific problems are \"intelligent agents\", as are human beings and organizations of human beings, such as firms. The intelligent agent paradigm defines AI research as \"the study of intelligent agents\". This is a generalization of some earlier definitions of AI: it goes beyond studying human intelligence; it studies all kinds of intelligence.\nThe paradigm gave researchers license to study isolated problems and to disagree about methods, but still retain hope that their work could be combined into an agent architecture that would be capable of general intelligence.\n\n\n=== Milestones and Moore's law ===\nOn May 11, 1997, Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov. In 2005, a Stanford robot won the DARPA Grand Challenge by driving autonomously for 131 miles along an unrehearsed desert trail. Two years later, a team from CMU won the DARPA Urban Challenge by autonomously navigating 55 miles in an urban environment while responding to traffic hazards and adhering to traffic laws.\nThese successes were not due to some revolutionary new paradigm, but mostly on the tedious application of engineering skill and on the tremendous increase in the speed and capacity of computers by the 90s. In fact, Deep Blue's computer was 10 million times faster than the Ferranti Mark 1 that Christopher Strachey taught to play chess in 1951. This dramatic increase is measured by Moore's law, which predicts that the speed and memory capacity of computers doubles every two years. The fundamental problem of \"raw computer power\" was slowly being overcome.", "mimetype": "text/plain", "start_char_idx": 54496, "end_char_idx": 59525, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f6908e55-36e1-44b8-8a1c-0b61ecad8974": {"__data__": {"id_": "f6908e55-36e1-44b8-8a1c-0b61ecad8974", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2894560", "node_type": "4", "metadata": {}, "hash": "3f693a0322bab49ee1a9c95b0fad8b26f3b517c00c36665addff054ec94514ce", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b5df004a-a492-45c4-944c-b32f65bf9718", "node_type": "1", "metadata": {}, "hash": "caa42b8d3fe4b4d02da56fc4cfc7c0c74f125b78ff2668bdc2c8069d7494ed42", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "923bdf78-1227-46a9-85a9-d41ddc0d73db", "node_type": "1", "metadata": {}, "hash": "c8c9ac1255cc004985a0aafd04354e1f92b88523a34549c9d616d18f0249fc41", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Big data, deep learning, AGI (2005\u20132017) ==\nIn the first decades of the 21st century, access to large amounts of data (known as \"big data\"), cheaper and faster computers and advanced machine learning techniques were successfully applied to many problems throughout the economy. A turning point was the success of deep learning around 2012 which improved the performance of machine learning on many tasks, including image and video processing, text analysis, and speech recognition. Investment in AI increased along with its capabilities, and by 2016, the market for AI-related products, hardware, and software reached more than $8 billion, and the New York Times reported that interest in AI had reached a \"frenzy\".\nIn 2002, Ben Goertzel and others became concerned that AI had largely abandoned its original goal of producing versatile, fully intelligent machines, and argued in favor of more direct research into artificial general intelligence. By the mid-2010s several companies and institutions had been founded to pursue Artificial General Intelligence (AGI), such as OpenAI and Google's DeepMind. During the same period, new insights into superintelligence raised concerns that AI was an existential threat. The risks and unintended consequences of AI technology became an area of serious academic research after 2016.\n\n\n=== Big data and big machines ===\n\nThe success of machine learning in the 2000s depended on the availability of vast amounts of training data and faster computers. Russell and Norvig wrote that the \"improvement in performance obtained by increasing the size of the data set by two or three orders of magnitude outweighs any improvement that can be made by tweaking the algorithm.\" Geoffrey Hinton recalled that back in the 90s, the problem was that \"our labeled datasets were thousands of times too small. [And] our computers were millions of times too slow.\" This was no longer true by 2010.\nThe most useful data in the 2000s came from curated, labeled data sets created specifically for machine learning and AI. In 2007, a group at UMass Amherst released Labeled Faces in the Wild, an annotated set of images of faces that was widely used to train and test face recognition systems for the next several decades. Fei-Fei Li developed ImageNet, a database of three million images captioned by volunteers using the Amazon Mechanical Turk. Released in 2009, it was a useful body of training data and a benchmark for testing for the next generation of image processing systems. Google released word2vec in 2013 as an open source resource. It used large amounts of data text scraped from the internet and word embedding to create a numeric vector to represent each word. Users were surprised at how well it was able to capture word meanings, for example, ordinary vector addition would give equivalences like China + River = Yangtze, London-England+France = Paris. This database in particular would be essential for the development of large language models in the late 2010s.\nThe explosive growth of the internet gave machine learning programs access to billions of pages of text and images that could be scraped. And, for specific problems, large privately held databases contained the relevant data. McKinsey Global Institute reported that \"by 2009, nearly all sectors in the US economy had at least an average of 200 terabytes of stored data\". This collection of information was known in the 2000s as big data.\nIn a Jeopardy! exhibition match in February 2011, IBM's question answering system Watson defeated the two best Jeopardy! champions, Brad Rutter and Ken Jennings, by a significant margin. Watson's expertise would have been impossible without the information available on the internet.\n\n\n=== Deep learning ===\n\nIn 2012, AlexNet, a deep learning model, developed by Alex Krizhevsky, won the ImageNet Large Scale Visual Recognition Challenge, with significantly fewer errors than the second-place winner. Krizhevsky worked with Geoffrey Hinton at the University of Toronto. This was a turning point in machine learning: over the next few years dozens of other approaches to image recognition were abandoned in favor of deep learning.\nDeep learning uses a multi-layer perceptron. Although this architecture has been known since the 60s, getting it to work requires powerful hardware and large amounts of training data. Before these became \navailable, improving performance of image processing systems required hand-crafted ad hoc features that were difficult to implement. Deep learning was simpler and more general.\nDeep learning was applied to dozens of problems over the next few years (such as speech recognition, machine translation, medical diagnosis, and game playing). In every case it showed enormous gains in performance. Investment and interest in AI boomed as a result.", "mimetype": "text/plain", "start_char_idx": 59528, "end_char_idx": 64345, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "923bdf78-1227-46a9-85a9-d41ddc0d73db": {"__data__": {"id_": "923bdf78-1227-46a9-85a9-d41ddc0d73db", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2894560", "node_type": "4", "metadata": {}, "hash": "3f693a0322bab49ee1a9c95b0fad8b26f3b517c00c36665addff054ec94514ce", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f6908e55-36e1-44b8-8a1c-0b61ecad8974", "node_type": "1", "metadata": {}, "hash": "b91ae6aed09b958ad0db8c57075580cc5dbe9d3234998bde8ac2dd95a8966d01", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "dd3fb12f-097c-4110-9a61-c0e7ce834393", "node_type": "1", "metadata": {}, "hash": "3a8484ddcf7c3280afe661f045698cbe7f2636db456a39de1bc36774da0aecb9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== The alignment problem ===\nIt became fashionable in the 2000s to begin talking about the future of AI again and several popular books considered the possibility of superintelligent machines and what they might mean for human society. Some of this was optimistic (such as Ray Kurzweil's The Singularity is Near), but others warned that a sufficiently powerful AI was existential threat to humanity, such as Nick Bostrom and Eliezer Yudkowsky. The topic became widely covered in the press and many leading intellectuals and politicians commented on the issue.\nAI programs in the 21st century are defined by their goals \u2013 the specific measures that they are designed to optimize. Nick Bostrom's influential 2005 book Superintelligence argued that, if one isn't careful about defining these goals, the machine may cause harm to humanity in the process of achieving a goal. Stuart J. Russell used the example of an intelligent robot that kills its owner to prevent it from being unplugged, reasoning \"you can't fetch the coffee if you're dead\". (This problem is known by the technical term \"instrumental convergence\".) The solution is to align the machine's goal function with the goals of its owner and humanity in general. Thus, the problem of mitigating the risks and unintended consequences of AI became known as \"the value alignment problem\" or AI alignment.\nAt the same time, machine learning systems had begun to have disturbing unintended consequences. Cathy O'Neil explained how statistical algorithms had been among the causes of the 2008 economic crash, Julia Angwin of ProPublica argued that the COMPAS system used by the criminal justice system exhibited racial bias under some measures, others showed that many machine learning systems exhibited some form of racial bias, and there were many other examples of dangerous outcomes that had resulted from machine learning systems.\nIn 2016, the election of Donald Trump and the controversy over the COMPAS system illuminated several problems with the current technological infrastructure, including misinformation, social media algorithms designed to maximize engagement, the misuse of personal data and the trustworthiness of predictive models. Issues of fairness and unintended consequences became significantly more popular at AI conferences, publications vastly increased, funding became available, and many researchers re-focussed their careers on these issues. The value alignment problem became a serious field of academic study.", "mimetype": "text/plain", "start_char_idx": 64348, "end_char_idx": 66842, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "dd3fb12f-097c-4110-9a61-c0e7ce834393": {"__data__": {"id_": "dd3fb12f-097c-4110-9a61-c0e7ce834393", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2894560", "node_type": "4", "metadata": {}, "hash": "3f693a0322bab49ee1a9c95b0fad8b26f3b517c00c36665addff054ec94514ce", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "923bdf78-1227-46a9-85a9-d41ddc0d73db", "node_type": "1", "metadata": {}, "hash": "c8c9ac1255cc004985a0aafd04354e1f92b88523a34549c9d616d18f0249fc41", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a129138a-226b-42f0-8cd2-86553e5f67b4", "node_type": "1", "metadata": {}, "hash": "79ce813f2e347b83a31af5a9c83f99624baa3a30fe1daecbde2ae29a516f4e9b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Artificial general intelligence research ===\nIn the early 2000s, several researchers became concerned that mainstream AI was too focused on \"measurable performance in specific applications\" (known as \"narrow AI\") and had abandoned AI's original goal of creating versatile, fully intelligent machines. An early critic was Nils Nilsson in 1995, and similar opinions were published by AI elder statesmen John McCarthy, Marvin Minsky, and Patrick Winston in 2007\u20132009. Minsky organized a symposium on \"human-level AI\" in 2004. Ben Goertzel adopted the term \"artificial general intelligence\" for the new sub-field, founding a journal and holding conferences beginning in 2008. The new field grew rapidly, buoyed by the continuing success of artificial neural networks and the hope that it was the key to AGI.\nSeveral competing companies, laboratories and foundations were founded to develop AGI in the 2010s. DeepMind was founded in 2010 by three English scientists, Demis Hassabis, Shane Legg and Mustafa Suleyman, with funding from Peter Thiel and later Elon Musk. The founders and financiers were deeply concerned about AI safety and the existential risk of AI. DeepMind's founders had a personal connection with Yudkowsky and Musk was among those who was actively raising the alarm. Hassabis was both worried about the dangers of AGI and optimistic about its power; he hoped they could \"solve AI, then solve everything else.\" The New York Times wrote in 2023 \"At the heart of this competition is a brain-stretching paradox. The people who say they are most worried about AI are among the most determined to create it and enjoy its riches. They have justified their ambition with their strong belief that they alone can keep AI from endangering Earth.\"\nIn 2012, Geoffrey Hinton (who been leading neural network research since the 80s) was approached by Baidu, which wanted to hire him and all his students for an enormous sum. Hinton decided to hold an auction and, at a Lake Tahoe AI conference, they sold themselves to Google for a price of $44 million. Hassabis took notice and sold DeepMind to Google in 2014, on the condition that it would not accept military contracts and would be overseen by an ethics board.\nLarry Page of Google, unlike Musk and Hassabis, was an optimist about the future of AI. Musk and Paige became embroiled in an argument about the risk of AGI at Musk's 2015 birthday party. They had been friends for decades but stopped speaking to each other shortly afterwards. Musk attended the one and only meeting of the DeepMind's ethics board, where it became clear that Google was uninterested in mitigating the harm of AGI. Frustrated by his lack of influence he founded OpenAI in 2015, enlisting Sam Altman to run it and hiring top scientists. OpenAI began as a non-profit, \"free from the economic incentives that were driving Google and other corporations.\" Musk became frustrated again and left the company in 2018. OpenAI turned to Microsoft for continued financial support and Altman and OpenAI formed a for-profit version of the company with more than $1 billion in financing.\nIn 2021, Dario Amodei  and 14 other scientists left OpenAI over concerns that the company was putting profits above safety. They formed Anthropic, which soon had $6 billion in financing from Microsoft and Google.\n\n\n== Large language models, AI boom (2017\u2013present) ==\n\nThe AI boom started with the initial development of key architectures and algorithms such as the transformer architecture in 2017, leading to the scaling and development of large language models exhibiting human-like traits of knowledge, attention and creativity. The new AI era began since 2020, with the public release of scaled large language models (LLMs) such as ChatGPT.", "mimetype": "text/plain", "start_char_idx": 66845, "end_char_idx": 70597, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a129138a-226b-42f0-8cd2-86553e5f67b4": {"__data__": {"id_": "a129138a-226b-42f0-8cd2-86553e5f67b4", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2894560", "node_type": "4", "metadata": {}, "hash": "3f693a0322bab49ee1a9c95b0fad8b26f3b517c00c36665addff054ec94514ce", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "dd3fb12f-097c-4110-9a61-c0e7ce834393", "node_type": "1", "metadata": {}, "hash": "3a8484ddcf7c3280afe661f045698cbe7f2636db456a39de1bc36774da0aecb9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "73686731-c8e5-4c7f-a269-37af8834d750", "node_type": "1", "metadata": {}, "hash": "fed06a6f6f569c31b63bd852a386c7a729e8901af7924a92b998d06940fb2497", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Large language models, AI boom (2017\u2013present) ==\n\nThe AI boom started with the initial development of key architectures and algorithms such as the transformer architecture in 2017, leading to the scaling and development of large language models exhibiting human-like traits of knowledge, attention and creativity. The new AI era began since 2020, with the public release of scaled large language models (LLMs) such as ChatGPT.\n\n\n=== Transformer architecture and large language models ===\n\nIn 2017, the transformer architecture was proposed by Google researchers. It exploits an attention mechanism and became widely used in large language models.\nLarge language models, based on the transformer, were developed by AGI companies: OpenAI released GPT-3 in 2020, and DeepMind released Gato in 2022. These are foundation models: they are trained on vast quantities of unlabeled data and can be adapted to a wide range of downstream tasks.\nThese models can discuss a huge number of topics and display general knowledge. The question naturally arises: are these models an example of artificial general intelligence? Bill Gates was skeptical of the new technology and the hype that surrounded AGI. However, Altman presented him with a live demo of ChatGPT4 passing an advanced biology test. Gates was convinced. In 2023, Microsoft Research tested the model with a large variety of tasks, and concluded that \"it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system\".\nIn 2024, OpenAI o3, a type of advanced reasoning model developed by OpenAI was announced. On the Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI) benchmark developed by Fran\u00e7ois Chollet in 2019, the model achieved an unofficial score of 87.5% on the semi-private test, surpassing the typical human score of 84%. The benchmark is supposed to be a necessary, but not sufficient test for AGI. Speaking of the benchmark, Chollet has said \"You\u2019ll know AGI is here when the exercise of creating tasks that are easy for regular humans but hard for AI becomes simply impossible.\"\n\n\n=== AI boom ===\n\nInvestment in AI grew exponentially after 2020, with venture capital funding for generative AI companies increasing dramatically. Total AI investments rose from $18 billion in 2014 to $119 billion in 2021, with generative AI accounting for approximately 30% of investments by 2023. According to metrics from 2017 to 2021, the United States outranked the rest of the world in terms of venture capital funding, number of startups, and AI patents granted. The commercial AI scene became dominated by American Big Tech companies, whose investments in this area surpassed those from U.S.-based venture capitalists. OpenAI's valuation reached $86 billion by early 2024, while NVIDIA's market capitalization surpassed $3.3 trillion by mid-2024, making it the world's largest company by market capitalization as the demand for AI-capable GPUs surged.\n15.ai, launched in March 2020 by an anonymous MIT researcher, was one of the earliest examples of generative AI gaining widespread public attention during the initial stages of the AI boom. The free web application demonstrated the ability to clone character voices using neural networks with minimal training data, requiring as little as 15 seconds of audio to reproduce a voice\u2014a capability later corroborated by OpenAI in 2024. The service went viral on social media platforms in early 2021, allowing users to generate speech for characters from popular media franchises, and became particularly notable for its pioneering role in popularizing AI voice synthesis for creative content and memes.", "mimetype": "text/plain", "start_char_idx": 70168, "end_char_idx": 73859, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "73686731-c8e5-4c7f-a269-37af8834d750": {"__data__": {"id_": "73686731-c8e5-4c7f-a269-37af8834d750", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2894560", "node_type": "4", "metadata": {}, "hash": "3f693a0322bab49ee1a9c95b0fad8b26f3b517c00c36665addff054ec94514ce", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a129138a-226b-42f0-8cd2-86553e5f67b4", "node_type": "1", "metadata": {}, "hash": "79ce813f2e347b83a31af5a9c83f99624baa3a30fe1daecbde2ae29a516f4e9b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d7499800-b881-43ce-8615-ac87576cbce3", "node_type": "1", "metadata": {}, "hash": "1c2ffc3eca81ef8b6c584a40731fef40d8c73356bd521d98c6b74931fca28d11", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Advent of AI for public use ===\nChatGPT was launched on November 30, 2022, marking a pivotal moment in artificial intelligence's public adoption. Within days of its release it went viral, gaining over 100 million users in two months and becoming the fastest-growing consumer software application in history. The chatbot's ability to engage in human-like conversations, write code, and generate creative content captured public imagination and led to rapid adoption across various sectors including education, business, and research. ChatGPT's success prompted unprecedented responses from major technology companies\u2014Google declared a \"code red\" and rapidly launched Gemini (formerly known as Google Bard), while Microsoft incorporated the technology into Bing Chat.\nThe rapid adoption of these AI technologies sparked intense debate about their implications. Notable AI researchers and industry leaders voiced both optimism and concern about the accelerating pace of development. In March 2023, over 20,000 signatories, including computer scientist Yoshua Bengio, Elon Musk, and Apple co-founder Steve Wozniak, signed an open letter calling for a pause in advanced AI development, citing \"profound risks to society and humanity.\" However, other prominent researchers like Juergen Schmidhuber took a more optimistic view, emphasizing that the majority of AI research aims to make \"human lives longer and healthier and easier.\"\nBy mid-2024, however, the financial sector began to scrutinize AI companies more closely, particularly questioning their capacity to produce a return on investment commensurate with their massive valuations. Some prominent investors raised concerns about market expectations becoming disconnected from fundamental business realities. Jeremy Grantham, co-founder of GMO LLC, warned investors to \"be quite careful\" and drew parallels to previous technology-driven market bubbles. Similarly, Jeffrey Gundlach, CEO of DoubleLine Capital, explicitly compared the AI boom to the dot-com bubble of the late 1990s, suggesting that investor enthusiasm might be outpacing realistic near-term capabilities and revenue potential. These concerns were amplified by the substantial market capitalizations of AI-focused companies, many of which had yet to demonstrate sustainable profitability models.\nIn March 2024, Anthropic released the Claude 3 family of large language models, including Claude 3 Haiku, Sonnet, and Opus. The models demonstrated significant improvements in capabilities across various benchmarks, with Claude 3 Opus notably outperforming leading models from OpenAI and Google. In June 2024, Anthropic released Claude 3.5 Sonnet, which demonstrated improved performance compared to the larger Claude 3 Opus, particularly in areas such as coding, multistep workflows, and image analysis.\n\n\n=== 2024 Nobel Prizes ===\nIn 2024, the Royal Swedish Academy of Sciences awarded Nobel Prizes in recognition of groundbreaking contributions to artificial intelligence. The recipients included:\n\nIn physics: John Hopfield for his work on physics-inspired Hopfield networks, and Geoffrey Hinton for foundational contributions to Boltzmann machines and deep learning.\nIn chemistry: David Baker, Demis Hassabis, and John Jumper for their advancements in protein folding predictions. See AlphaFold.\n\n\n=== Further Study and development of AI ===\nIn January 2025, OpenAI announced a new AI, ChatGPT-Gov, which would be specifically designed for US government agencies to use securely. Open AI said that agencies could utilize ChatGPT Gov on a Microsoft Azure cloud or Azure Government cloud, \"on top of Microsoft\u2019s Azure\u2019s OpenAI Service.\" OpenAI's announcement stated that \"Self-hosting ChatGPT Gov enables agencies to more easily manage their own security, privacy, and compliance requirements, such as stringent cybersecurity frameworks (IL5, CJIS, ITAR, FedRAMP High). Additionally, we believe this infrastructure will expedite internal authorization of OpenAI\u2019s tools for the handling of non-public sensitive data.\"\n\n\n=== Robotic Integration and Practical Applications of Artificial Intelligence (2025\u2013present) ===\nAdvanced artificial intelligence (AI) systems, capable of understanding and responding to human dialogue with high accuracy, have matured to enable seamless integration with robotics, transforming industries such as manufacturing, household automation, healthcare, public services, and materials research. Applications of artificial intelligence also accelerates scientific research through advanced data analysis and hypothesis generation. Countries including China, the United States, and Japan have invested significantly in policies and funding to deploy AI-powered robots, addressing labor shortages, boosting innovation, and enhancing efficiency, while implementing  regulatory frameworks to ensure ethical and safe development.", "mimetype": "text/plain", "start_char_idx": 73862, "end_char_idx": 78732, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d7499800-b881-43ce-8615-ac87576cbce3": {"__data__": {"id_": "d7499800-b881-43ce-8615-ac87576cbce3", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2894560", "node_type": "4", "metadata": {}, "hash": "3f693a0322bab49ee1a9c95b0fad8b26f3b517c00c36665addff054ec94514ce", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "73686731-c8e5-4c7f-a269-37af8834d750", "node_type": "1", "metadata": {}, "hash": "fed06a6f6f569c31b63bd852a386c7a729e8901af7924a92b998d06940fb2497", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Robotic Integration and Practical Applications of Artificial Intelligence (2025\u2013present) ===\nAdvanced artificial intelligence (AI) systems, capable of understanding and responding to human dialogue with high accuracy, have matured to enable seamless integration with robotics, transforming industries such as manufacturing, household automation, healthcare, public services, and materials research. Applications of artificial intelligence also accelerates scientific research through advanced data analysis and hypothesis generation. Countries including China, the United States, and Japan have invested significantly in policies and funding to deploy AI-powered robots, addressing labor shortages, boosting innovation, and enhancing efficiency, while implementing  regulatory frameworks to ensure ethical and safe development.\n\n\n==== China ====\nThe year 2025 has been heralded as the \"Year of AI Robotics,\" marking a pivotal moment in the seamless integration of artificial intelligence (AI) and robotics. In 2025, China invested approximately 730 billion yuan (roughly $100 billion USD) to advance AI and robotics in smart manufacturing and healthcare. The \"14th Five-Year Plan\" (2021\u20132025) prioritized service robots, with AI systems enabling robots to perform complex tasks like assisting in surgeries or automating factory assembly lines. For example, AI-powered humanoid robots in Chinese hospitals can interpret patient requests, deliver supplies, and assist nurses with routine tasks, demonstrating that existing AI conversational capabilities are robust enough for practical robotic applications. Starting in September 2025, China mandated labeling of AI-generated content to ensure transparency and public trust in these technologies.\n\n\n==== United States ====\nIn January 2025, a significant development in AI infrastructure investment occurred with the formation of Stargate LLC. The joint venture, created by OpenAI, SoftBank, Oracle, and MGX, announced plans to invest US$500 billion in AI infrastructure across the United States by 2029, starting with US$100 billion, in order to support the re-industrialization of the United States and provide a strategic capability to protect the national security of America and its allies. The venture was formally announced by U.S. President Donald Trump on January 21, 2025, with SoftBank CEO Masayoshi Son appointed as chairman.\nThe U.S. government allocated approximately $2 billion to integrate AI and robotics in manufacturing and logistics, leveraging AI's ability to process natural language and execute user instructions in 2025. State governments supplemented this with funding for service robots, such as those deployed in warehouses to fulfill verbal commands for inventory management or in eldercare facilities to respond to residents' requests for assistance. These applications highlight that merging advanced AI, already proficient in human interaction, with robotic hardware is a practical step forward. Some funds were directed to defense, including Lethal autonomous weapon and Military robot. In January 2025, Executive Order 14179 established an \"AI Action Plan\" to accelerate innovation and deployment of these technologies.\n\n\n==== Impact ====\nIn the 2020s, increased investments in AI by governments and organizations worldwide have accelerated the advancement of artificial intelligence, driving scientific breakthroughs, boosting workforce productivity, and transforming industries through the automation of complex tasks. By seamlessly integrating advanced AI systems into various sectors, these developments are poised to revolutionize smart manufacturing and service industries, fundamentally transforming everyday life.\n\n\n== See also ==\nHistory of artificial neural networks\nHistory of knowledge representation and reasoning\nHistory of natural language processing\nOutline of artificial intelligence\nProgress in artificial intelligence\nTimeline of artificial intelligence\nTimeline of machine learning\n\n\n== Notes ==\n\n\n== References ==", "mimetype": "text/plain", "start_char_idx": 77901, "end_char_idx": 81919, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5f2d015d-6bc6-4eac-9c23-a8127cb27636": {"__data__": {"id_": "5f2d015d-6bc6-4eac-9c23-a8127cb27636", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32472154", "node_type": "4", "metadata": {}, "hash": "2c6d7e6f84c4a9e5e945746e1ba39555343099af69cd64331fed1375c56fdd56", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "66331e57-f85d-468e-97a3-6f878fba0a9e", "node_type": "1", "metadata": {}, "hash": "4bf9dfccd7057f5a02f776719451af5627382c4cb7f7b1e54f6c5e8bd3c992fe", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In machine learning, deep learning focuses on utilizing multilayered neural networks to perform tasks such as classification, regression, and representation learning. The field takes inspiration from biological neuroscience and is centered around stacking artificial neurons into layers and \"training\" them to process data. The adjective \"deep\" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the network. Methods used can be supervised, semi-supervised or unsupervised.\nSome common deep learning network architectures include fully connected networks, deep belief networks, recurrent neural networks, convolutional neural networks, generative adversarial networks, transformers, and neural radiance fields. These architectures have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.\nEarly forms of neural networks were inspired by information processing and distributed communication nodes in biological systems, particularly the human brain. However, current neural networks do not intend to model the brain function of organisms, and are generally seen as low-quality models for that purpose.\n\n\n== Overview ==\nMost modern deep learning models are based on multi-layered neural networks such as convolutional neural networks and transformers, although they can also include propositional formulas or latent variables organized layer-wise in deep generative models such as the nodes in deep belief networks and deep Boltzmann machines.\nFundamentally, deep learning refers to a class of machine learning algorithms in which a hierarchy of layers is used to transform input data into a progressively more abstract and composite representation. For example, in an image recognition model, the raw input may be an image (represented as a tensor of pixels). The first representational layer may attempt to identify basic shapes such as lines and circles, the second layer may compose and encode arrangements of edges, the third layer may encode a nose and eyes, and the fourth layer may recognize that the image contains a face.\nImportantly, a deep learning process can learn which features to optimally place at which level on its own. Prior to deep learning, machine learning techniques often involved hand-crafted feature engineering to transform the data into a more suitable representation for a classification algorithm to operate on. In the deep learning approach, features are not hand-crafted and the model discovers useful feature representations from the data automatically. This does not eliminate the need for hand-tuning; for example, varying numbers of layers and layer sizes can provide different degrees of abstraction.\nThe word \"deep\" in \"deep learning\" refers to the number of layers through which the data is transformed. More precisely, deep learning systems have a substantial credit assignment path (CAP) depth. The CAP is the chain of transformations from input to output. CAPs describe potentially causal connections between input and output. For a feedforward neural network, the depth of the CAPs is that of the network and is the number of hidden layers plus one (as the output layer is also parameterized). For recurrent neural networks, in which a signal may propagate through a layer more than once, the CAP depth is potentially unlimited. No universally agreed-upon threshold of depth divides shallow learning from deep learning, but most researchers agree that deep learning involves CAP depth higher than two. CAP of depth two has been shown to be a universal approximator in the sense that it can emulate any function. Beyond that, more layers do not add to the function approximator ability of the network. Deep models (CAP > two) are able to extract better features than shallow models and hence, extra layers help in learning the features effectively.\nDeep learning architectures can be constructed with a greedy layer-by-layer method. Deep learning helps to disentangle these abstractions and pick out which features improve performance.\nDeep learning algorithms can be applied to unsupervised learning tasks. This is an important benefit because unlabeled data is more abundant than the labeled data. Examples of deep structures that can be trained in an unsupervised manner are deep belief networks.\nThe term deep learning was introduced to the machine learning community by Rina Dechter in 1986, and to artificial neural networks by Igor Aizenberg and colleagues in 2000, in the context of Boolean threshold neurons. Although the history of its appearance is apparently more complicated.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4856, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "66331e57-f85d-468e-97a3-6f878fba0a9e": {"__data__": {"id_": "66331e57-f85d-468e-97a3-6f878fba0a9e", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32472154", "node_type": "4", "metadata": {}, "hash": "2c6d7e6f84c4a9e5e945746e1ba39555343099af69cd64331fed1375c56fdd56", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5f2d015d-6bc6-4eac-9c23-a8127cb27636", "node_type": "1", "metadata": {}, "hash": "68b78867f4ddc16758da14a8addd951d37f8c3004c4c7efade3a39f1dc593eaa", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5477aace-7847-4390-b5f8-466bbdf1a9ba", "node_type": "1", "metadata": {}, "hash": "537c5796da87ae540ba2e03b32e396286003b297e24d963aeae2a7f7d41299a9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Interpretations ==\nDeep neural networks are generally interpreted in terms of the universal approximation theorem or probabilistic inference.\nThe classic universal approximation theorem concerns the capacity of feedforward neural networks with a single hidden layer of finite size to approximate continuous functions. In 1989, the first proof was published by George Cybenko for sigmoid activation functions and was generalised to feed-forward multi-layer architectures in 1991 by Kurt Hornik. Recent work also showed that universal approximation also holds for non-bounded activation functions such as Kunihiko Fukushima's rectified linear unit.\nThe universal approximation theorem for deep neural networks concerns the capacity of networks with bounded width but the depth is allowed to grow. Lu et al. proved that if the width of a deep neural network with ReLU activation is strictly larger than the input dimension, then the network can approximate any Lebesgue integrable function; if the width is smaller or equal to the input dimension, then a deep neural network is not a universal approximator.\nThe probabilistic interpretation derives from the field of machine learning. It features inference, as well as the optimization concepts of training and testing, related to fitting and generalization, respectively. More specifically, the probabilistic interpretation considers the activation nonlinearity as a cumulative distribution function. The probabilistic interpretation led to the introduction of dropout as regularizer in neural networks. The probabilistic interpretation was introduced by researchers including Hopfield, Widrow and Narendra and popularized in surveys such as the one by Bishop.\n\n\n== History ==", "mimetype": "text/plain", "start_char_idx": 4859, "end_char_idx": 6586, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5477aace-7847-4390-b5f8-466bbdf1a9ba": {"__data__": {"id_": "5477aace-7847-4390-b5f8-466bbdf1a9ba", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32472154", "node_type": "4", "metadata": {}, "hash": "2c6d7e6f84c4a9e5e945746e1ba39555343099af69cd64331fed1375c56fdd56", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "66331e57-f85d-468e-97a3-6f878fba0a9e", "node_type": "1", "metadata": {}, "hash": "4bf9dfccd7057f5a02f776719451af5627382c4cb7f7b1e54f6c5e8bd3c992fe", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fb6f1d2c-da47-4d18-b44f-f977de3f3d9a", "node_type": "1", "metadata": {}, "hash": "1a876a6433a4ceb4f227ed73d3d0df2be988f475dbf7efa05d522c50b592319f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== History ==\n\n\n=== Before 1980 ===\nThere are two types of artificial neural network (ANN): feedforward neural network (FNN) or multilayer perceptron (MLP) and recurrent neural networks (RNN). RNNs have cycles in their connectivity structure, FNNs don't. In the 1920s, Wilhelm Lenz and Ernst Ising created the Ising model which is essentially a non-learning RNN architecture consisting of neuron-like threshold elements. In 1972, Shun'ichi Amari made this architecture adaptive. His learning RNN was republished by John Hopfield in 1982. Other early recurrent neural networks were published by Kaoru Nakano in 1971. Already in 1948, Alan Turing produced work on \"Intelligent Machinery\"  that was not published in his lifetime, containing \"ideas related to artificial evolution and learning RNNs\".\nFrank Rosenblatt (1958) proposed the perceptron, an MLP with 3 layers: an input layer, a hidden layer with randomized weights that did not learn, and an output layer. He later published a 1962 book that also introduced variants and computer experiments, including a version with four-layer perceptrons \"with adaptive preterminal networks\" where the last two layers have learned weights (here he credits H. D. Block and B. W. Knight).:\u200asection 16\u200a The book cites an earlier network by R. D. Joseph (1960) \"functionally equivalent to a variation of\" this four-layer system (the book mentions Joseph over 30 times). Should Joseph therefore be considered the originator of proper adaptive multilayer perceptrons with learning hidden units? Unfortunately, the learning algorithm was not a functional one, and fell into oblivion.\nThe first working deep learning algorithm was the Group method of data handling, a method to train arbitrarily deep neural networks, published by Alexey Ivakhnenko and Lapa in 1965. They regarded it as a form of polynomial regression, or a generalization of Rosenblatt's perceptron. A 1971 paper described a deep network with eight layers trained by this method, which is based on layer by layer training through regression analysis. Superfluous hidden units are pruned using a separate validation set. Since the activation functions of the nodes are Kolmogorov-Gabor polynomials, these were also the first deep networks with multiplicative units or \"gates\".\nThe first deep learning multilayer perceptron trained by stochastic gradient descent was published in 1967 by Shun'ichi Amari. In computer experiments conducted by Amari's student Saito, a five layer MLP with two modifiable layers learned  internal representations to classify non-linearily separable pattern classes. Subsequent developments in hardware and hyperparameter tunings have made end-to-end stochastic gradient descent the currently dominant training technique.\nIn 1969, Kunihiko Fukushima introduced the ReLU (rectified linear unit) activation function. The rectifier has become the most popular activation function for deep learning.\nDeep learning architectures for convolutional neural networks (CNNs) with convolutional layers and downsampling layers began with the Neocognitron introduced by Kunihiko Fukushima in 1979, though not trained by backpropagation. \nBackpropagation is an efficient application of the chain rule derived by Gottfried Wilhelm Leibniz in 1673 to networks of differentiable nodes. The terminology \"back-propagating errors\" was actually introduced in 1962 by Rosenblatt, but he did not know how to implement this, although Henry J. Kelley had a continuous precursor of backpropagation in 1960 in the context of control theory. The modern form of backpropagation was first published in Seppo Linnainmaa's master thesis (1970). G.M. Ostrovski et al. republished it in 1971. Paul Werbos applied backpropagation to neural networks in 1982 (his 1974 PhD thesis, reprinted in a 1994 book, did not yet describe the algorithm). In 1986, David E. Rumelhart et al. popularised backpropagation but did not cite the original work.\n\n\n=== 1980s-2000s ===\nThe time delay neural network (TDNN) was introduced in 1987 by Alex Waibel to apply CNN to phoneme recognition. It used convolutions, weight sharing, and backpropagation.  In 1988, Wei Zhang applied a backpropagation-trained CNN to alphabet recognition. \nIn 1989, Yann LeCun et al. created a CNN called LeNet for recognizing handwritten ZIP codes on mail. Training required 3 days. In 1990, Wei Zhang implemented a CNN on optical computing hardware. In 1991, a CNN was applied to medical image object segmentation and breast cancer detection in mammograms.", "mimetype": "text/plain", "start_char_idx": 6573, "end_char_idx": 11088, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fb6f1d2c-da47-4d18-b44f-f977de3f3d9a": {"__data__": {"id_": "fb6f1d2c-da47-4d18-b44f-f977de3f3d9a", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32472154", "node_type": "4", "metadata": {}, "hash": "2c6d7e6f84c4a9e5e945746e1ba39555343099af69cd64331fed1375c56fdd56", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5477aace-7847-4390-b5f8-466bbdf1a9ba", "node_type": "1", "metadata": {}, "hash": "537c5796da87ae540ba2e03b32e396286003b297e24d963aeae2a7f7d41299a9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "60be2bba-4bc5-431b-b48f-e8b47131c06e", "node_type": "1", "metadata": {}, "hash": "ccfe96d9636bb7759877586291f84de38e3b57ec75e3cc93acb7fcec4b2e7956", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== 1980s-2000s ===\nThe time delay neural network (TDNN) was introduced in 1987 by Alex Waibel to apply CNN to phoneme recognition. It used convolutions, weight sharing, and backpropagation.  In 1988, Wei Zhang applied a backpropagation-trained CNN to alphabet recognition. \nIn 1989, Yann LeCun et al. created a CNN called LeNet for recognizing handwritten ZIP codes on mail. Training required 3 days. In 1990, Wei Zhang implemented a CNN on optical computing hardware. In 1991, a CNN was applied to medical image object segmentation and breast cancer detection in mammograms. LeNet-5 (1998), a 7-level CNN by Yann LeCun et al., that classifies digits, was applied by several banks to recognize hand-written numbers on checks  digitized in 32x32 pixel images.\nRecurrent neural networks (RNN) were further developed in the 1980s. Recurrence is used for sequence processing, and when a recurrent network is unrolled, it mathematically resembles a deep feedforward layer. Consequently, they have similar properties and issues, and their developments had mutual influences. In RNN, two early influential works were the Jordan network (1986) and the Elman network (1990), which applied RNN to study problems in cognitive psychology.\nIn the 1980s, backpropagation did not work well for deep learning with long credit assignment paths. To overcome this problem, in 1991, J\u00fcrgen Schmidhuber proposed a hierarchy of RNNs pre-trained one level at a time by self-supervised learning where each RNN tries to predict its own next input, which is the next unexpected input of the RNN below. This \"neural history compressor\" uses predictive coding  to learn internal representations at multiple self-organizing time scales. This can substantially facilitate downstream deep learning. The RNN hierarchy can be collapsed into a single RNN, by  distilling a higher level chunker network into a lower level automatizer network. In 1993, a neural history compressor solved a \"Very Deep Learning\" task that required more than 1000 subsequent layers in an RNN unfolded in time. The \"P\" in ChatGPT refers to such pre-training.\nSepp Hochreiter's diploma thesis (1991) implemented the neural history compressor, and identified and analyzed the vanishing gradient problem.  Hochreiter proposed recurrent residual connections to solve the vanishing gradient problem. This led to the long short-term memory (LSTM), published in 1995. LSTM can learn \"very deep learning\" tasks with long credit assignment paths that require memories of events that happened thousands of discrete time steps before. That LSTM was not yet the modern architecture, which required a \"forget gate\", introduced in 1999, which became the standard RNN architecture.\nIn 1991, J\u00fcrgen Schmidhuber also published adversarial neural networks that contest with each other in the form of a zero-sum game, where one network's gain is the other network's loss. The first network is a generative model that models a probability distribution over output patterns. The second network learns by gradient descent to predict the reactions of the environment to these patterns. This was called \"artificial curiosity\". In 2014, this principle was used in generative adversarial networks (GANs).\nDuring 1985\u20131995, inspired by statistical mechanics, several architectures and methods were developed by Terry Sejnowski, Peter Dayan, Geoffrey Hinton, etc., including the Boltzmann machine, restricted Boltzmann machine, Helmholtz machine, and the wake-sleep algorithm. These were designed for unsupervised learning of deep generative models. However, those were more computationally expensive compared to backpropagation. Boltzmann machine learning algorithm, published in 1985, was briefly popular before being eclipsed by the backpropagation algorithm in 1986. (p. 112 ). A 1988 network became state of the art in protein structure prediction, an early application of deep learning to bioinformatics.\nBoth shallow and deep learning (e.g., recurrent nets) of ANNs for speech recognition have been explored for many years. These methods never outperformed non-uniform internal-handcrafting Gaussian mixture model/Hidden Markov model (GMM-HMM) technology based on generative models of speech trained discriminatively. Key difficulties have been analyzed, including gradient diminishing and weak temporal correlation structure in neural predictive models. Additional difficulties were the lack of training data and limited computing power.\nMost speech recognition researchers moved away from neural nets to pursue generative modeling.", "mimetype": "text/plain", "start_char_idx": 10512, "end_char_idx": 15069, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "60be2bba-4bc5-431b-b48f-e8b47131c06e": {"__data__": {"id_": "60be2bba-4bc5-431b-b48f-e8b47131c06e", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32472154", "node_type": "4", "metadata": {}, "hash": "2c6d7e6f84c4a9e5e945746e1ba39555343099af69cd64331fed1375c56fdd56", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fb6f1d2c-da47-4d18-b44f-f977de3f3d9a", "node_type": "1", "metadata": {}, "hash": "1a876a6433a4ceb4f227ed73d3d0df2be988f475dbf7efa05d522c50b592319f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2be6c3c9-24d6-4339-8c8c-98b4b2bb7160", "node_type": "1", "metadata": {}, "hash": "294e5445d58454abb293add53c64d260d9f8a1deeac58188ed5a28225bcd85b8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "However, those were more computationally expensive compared to backpropagation. Boltzmann machine learning algorithm, published in 1985, was briefly popular before being eclipsed by the backpropagation algorithm in 1986. (p. 112 ). A 1988 network became state of the art in protein structure prediction, an early application of deep learning to bioinformatics.\nBoth shallow and deep learning (e.g., recurrent nets) of ANNs for speech recognition have been explored for many years. These methods never outperformed non-uniform internal-handcrafting Gaussian mixture model/Hidden Markov model (GMM-HMM) technology based on generative models of speech trained discriminatively. Key difficulties have been analyzed, including gradient diminishing and weak temporal correlation structure in neural predictive models. Additional difficulties were the lack of training data and limited computing power.\nMost speech recognition researchers moved away from neural nets to pursue generative modeling. An exception was at SRI International in the late 1990s. Funded by the US government's NSA and DARPA, SRI researched in speech and speaker recognition. The speaker recognition team led by Larry Heck reported significant success with deep neural networks in speech processing in the 1998 NIST Speaker Recognition benchmark. It was deployed in the Nuance Verifier, representing the first major industrial application of deep learning.\nThe principle of elevating \"raw\" features over hand-crafted optimization was first explored successfully in the architecture of deep autoencoder on the \"raw\" spectrogram or linear filter-bank features in the late 1990s, showing its superiority over the Mel-Cepstral features that contain stages of fixed transformation from spectrograms. The raw features of speech, waveforms, later produced excellent larger-scale results.\n\n\n=== 2000s ===\nNeural networks entered a lull, and simpler models that use task-specific handcrafted features such as Gabor filters and support vector machines (SVMs) became the preferred choices in the 1990s and 2000s, because of artificial neural networks' computational cost and a lack of understanding of how the brain wires its biological networks.\nIn 2003, LSTM became competitive with traditional speech recognizers on certain tasks. In 2006, Alex Graves, Santiago Fern\u00e1ndez, Faustino Gomez, and Schmidhuber combined it with connectionist temporal classification (CTC) in stacks of LSTMs. In 2009, it became the first RNN to win a pattern recognition contest, in connected handwriting recognition.\nIn 2006, publications by Geoff Hinton, Ruslan Salakhutdinov, Osindero and Teh deep belief networks were developed for generative modeling. They are trained by training one restricted Boltzmann machine, then freezing it and training another one on top of the first one, and so on, then optionally fine-tuned using supervised backpropagation. They could model high-dimensional probability distributions, such as the distribution of MNIST images, but convergence was slow.\nThe impact of deep learning in industry began in the early 2000s, when CNNs already processed an estimated 10% to 20% of all the checks written in the US, according to Yann LeCun. Industrial applications of deep learning to large-scale speech recognition started around 2010.\nThe 2009 NIPS Workshop on Deep Learning for Speech Recognition was motivated by the limitations of deep generative models of speech, and the possibility that given more capable hardware and large-scale data sets that deep neural nets might become practical. It was believed that pre-training DNNs using generative models of deep belief nets (DBN) would overcome the main difficulties of neural nets. However, it was discovered that replacing pre-training with large amounts of training data for straightforward backpropagation when using DNNs with large, context-dependent output layers produced error rates dramatically lower than then-state-of-the-art Gaussian mixture model (GMM)/Hidden Markov Model (HMM) and also than more-advanced generative model-based systems. The nature of the recognition errors produced by the two types of systems was characteristically different, offering technical insights into how to integrate deep learning into the existing highly efficient, run-time speech decoding system deployed by all major speech recognition systems. Analysis around 2009\u20132010, contrasting the GMM (and other generative speech models) vs. DNN models, stimulated early industrial investment in deep learning for speech recognition.  That analysis was done with comparable performance (less than 1.5% in error rate) between discriminative DNNs and generative models.\nIn 2010, researchers extended deep learning from TIMIT to large vocabulary speech recognition, by adopting large output layers of the DNN based on context-dependent HMM states constructed by decision trees.", "mimetype": "text/plain", "start_char_idx": 14079, "end_char_idx": 18958, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2be6c3c9-24d6-4339-8c8c-98b4b2bb7160": {"__data__": {"id_": "2be6c3c9-24d6-4339-8c8c-98b4b2bb7160", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32472154", "node_type": "4", "metadata": {}, "hash": "2c6d7e6f84c4a9e5e945746e1ba39555343099af69cd64331fed1375c56fdd56", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "60be2bba-4bc5-431b-b48f-e8b47131c06e", "node_type": "1", "metadata": {}, "hash": "ccfe96d9636bb7759877586291f84de38e3b57ec75e3cc93acb7fcec4b2e7956", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d15b1341-804e-426b-97e0-a1d73328bd5e", "node_type": "1", "metadata": {}, "hash": "09dcfab3f907be974a5ba060117d52df97863955c6c3ffc67f168027ea1caddf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Deep learning revolution ===\n\nThe deep learning revolution started around CNN- and GPU-based computer vision.\nAlthough CNNs trained by backpropagation had been around for decades and GPU implementations of NNs for years, including CNNs, faster implementations of CNNs on GPUs were needed to progress on computer vision. Later, as deep learning becomes widespread, specialized hardware and algorithm optimizations were developed specifically for deep learning.\nA key advance for the deep learning revolution was hardware advances, especially GPU. Some early work dated back to 2004. In 2009, Raina, Madhavan, and Andrew Ng reported a 100M deep belief network trained on 30 Nvidia GeForce GTX 280 GPUs, an early demonstration of GPU-based deep learning. They reported up to 70 times faster training.\nIn 2011, a CNN named DanNet by Dan Ciresan, Ueli Meier, Jonathan Masci, Luca Maria Gambardella, and J\u00fcrgen Schmidhuber achieved for the first time superhuman performance in a visual pattern recognition contest, outperforming traditional methods by a factor of 3. It then won more contests. They also showed how max-pooling CNNs on GPU improved performance significantly.\nIn 2012, Andrew Ng and Jeff Dean created an FNN that learned to recognize higher-level concepts, such as cats, only from watching unlabeled images taken from YouTube videos.\nIn October 2012, AlexNet by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton won the large-scale ImageNet competition by a significant margin over shallow machine learning methods. Further incremental improvements included the VGG-16 network by Karen Simonyan and Andrew Zisserman and Google's Inceptionv3.\nThe success in image classification was then extended to the more challenging task of generating descriptions (captions) for images, often as a combination of CNNs and LSTMs.\nIn 2014, the state of the art was training \u201cvery deep neural network\u201d with 20 to 30 layers. Stacking too many layers led to a steep reduction in training accuracy, known as the \"degradation\" problem. In 2015, two techniques were developed to train very deep networks: the Highway Network was published in May 2015, and the residual neural network (ResNet) in Dec 2015. ResNet behaves like an open-gated Highway Net.\nAround the same time, deep learning started impacting the field of art. Early examples included Google DeepDream (2015), and neural style transfer (2015), both of which were based on pretrained image classification neural networks, such as VGG-19.\nGenerative adversarial network (GAN) by (Ian Goodfellow et al., 2014) (based on  J\u00fcrgen Schmidhuber's principle of artificial curiosity)\nbecame state of the art in generative modeling during 2014-2018 period. Excellent image quality is achieved by Nvidia's StyleGAN (2018) based on the Progressive GAN by Tero Karras et al. Here the GAN generator is grown from small to large scale in a pyramidal fashion. Image generation by GAN reached popular success, and provoked discussions concerning deepfakes.  Diffusion models (2015) eclipsed GANs in generative modeling since then, with systems such as DALL\u00b7E 2 (2022) and Stable Diffusion (2022).\nIn 2015, Google's speech recognition improved by 49% by an LSTM-based model, which they made available through Google Voice Search on smartphone.\nDeep learning is part of state-of-the-art systems in various disciplines, particularly computer vision and automatic speech recognition (ASR). Results on commonly used evaluation sets such as TIMIT (ASR) and MNIST (image classification), as well as a range of large-vocabulary speech recognition tasks have steadily improved. Convolutional neural networks were superseded for ASR by LSTM. but are more successful in computer vision.\nYoshua Bengio, Geoffrey Hinton and Yann LeCun were awarded the 2018 Turing Award for \"conceptual and engineering breakthroughs that have made deep neural networks a critical component of computing\".", "mimetype": "text/plain", "start_char_idx": 18961, "end_char_idx": 22877, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d15b1341-804e-426b-97e0-a1d73328bd5e": {"__data__": {"id_": "d15b1341-804e-426b-97e0-a1d73328bd5e", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32472154", "node_type": "4", "metadata": {}, "hash": "2c6d7e6f84c4a9e5e945746e1ba39555343099af69cd64331fed1375c56fdd56", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2be6c3c9-24d6-4339-8c8c-98b4b2bb7160", "node_type": "1", "metadata": {}, "hash": "294e5445d58454abb293add53c64d260d9f8a1deeac58188ed5a28225bcd85b8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "55807351-f087-4663-813f-0399077c90fe", "node_type": "1", "metadata": {}, "hash": "7630e998aa14d81f893183b1559984cece1a66bf939352ed23985b2bd24bb01f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Neural networks ==\n\nArtificial neural networks (ANNs) or connectionist systems are computing systems inspired by the biological neural networks that constitute animal brains. Such systems learn (progressively improve their ability) to do tasks by considering examples, generally without task-specific programming. For example, in image recognition, they might learn to identify images that contain cats by analyzing example images that have been manually labeled as \"cat\" or \"no cat\" and using the analytic results to identify cats in other images. They have found most use in applications difficult to express with a traditional computer algorithm using rule-based programming.\nAn ANN is based on a collection of connected units called artificial neurons, (analogous to biological neurons in a biological brain). Each connection (synapse) between neurons can transmit a signal to another neuron. The receiving (postsynaptic) neuron can process the signal(s) and then signal downstream neurons connected to it. Neurons may have state, generally represented by real numbers, typically between 0 and 1. Neurons and synapses may also have a weight that varies as learning proceeds, which can increase or decrease the strength of the signal that it sends downstream.\nTypically, neurons are organized in layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first (input), to the last (output) layer, possibly after traversing the layers multiple times.\nThe original goal of the neural network approach was to solve problems in the same way that a human brain would. Over time, attention focused on matching specific mental abilities, leading to deviations from biology such as backpropagation, or passing information in the reverse direction and adjusting the network to reflect that information.\nNeural networks have been used on a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games and medical diagnosis.\nAs of 2017, neural networks typically have a few thousand to a few million units and millions of connections. Despite this number being several order of magnitude less than the number of neurons on a human brain, these networks can perform many tasks at a level beyond that of humans (e.g., recognizing faces, or playing \"Go\").\n\n\n=== Deep neural networks ===\nA deep neural network (DNN) is an artificial neural network with multiple layers between the input and output layers. There are different types of neural networks but they always consist of the same components: neurons, synapses, weights, biases, and functions. These components as a whole function in a way that mimics functions of the human brain, and can be trained like any other ML algorithm.\nFor example, a DNN that is trained to recognize dog breeds will go over the given image and calculate the probability that the dog in the image is a certain breed. The user can review the results and select which probabilities the network should display (above a certain threshold, etc.) and return the proposed label. Each mathematical manipulation as such is considered a layer,  and complex DNN have many layers, hence the name \"deep\" networks. \nDNNs can model complex non-linear relationships. DNN architectures generate compositional models where the object is expressed as a layered composition of primitives. The extra layers enable composition of features from lower layers, potentially modeling complex data with fewer units than a similarly performing shallow network. For instance, it was proved that sparse multivariate polynomials are exponentially easier to approximate with DNNs than with shallow networks.\nDeep architectures include many variants of a few basic approaches. Each architecture has found success in specific domains. It is not always possible to compare the performance of multiple architectures, unless they have been evaluated on the same data sets.\nDNNs are typically feedforward networks in which data flows from the input layer to the output layer without looping back. At first, the DNN creates a map of virtual neurons and assigns random numerical values, or \"weights\", to connections between them. The weights and inputs are multiplied and return an output between 0 and 1. If the network did not accurately recognize a particular pattern, an algorithm would adjust the weights. That way the algorithm can make certain parameters more influential, until it determines the correct mathematical manipulation to fully process the data.\nRecurrent neural networks, in which data can flow in any direction, are used for applications such as language modeling. Long short-term memory is particularly effective for this use.\nConvolutional neural networks (CNNs) are used in computer vision. CNNs also have been applied to acoustic modeling for automatic speech recognition (ASR).", "mimetype": "text/plain", "start_char_idx": 22880, "end_char_idx": 27802, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "55807351-f087-4663-813f-0399077c90fe": {"__data__": {"id_": "55807351-f087-4663-813f-0399077c90fe", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32472154", "node_type": "4", "metadata": {}, "hash": "2c6d7e6f84c4a9e5e945746e1ba39555343099af69cd64331fed1375c56fdd56", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d15b1341-804e-426b-97e0-a1d73328bd5e", "node_type": "1", "metadata": {}, "hash": "09dcfab3f907be974a5ba060117d52df97863955c6c3ffc67f168027ea1caddf", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "682470e6-b604-496c-bc21-bc958d9caf62", "node_type": "1", "metadata": {}, "hash": "bbcd61324f8329f2301b6b48fa9da21d0856791ddcf50b5b017e00c844c5a7ad", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Challenges ====\nAs with ANNs, many issues can arise with naively trained DNNs. Two common issues are overfitting and computation time.\nDNNs are prone to overfitting because of the added layers of abstraction, which allow them to model rare dependencies in the training data. Regularization methods such as Ivakhnenko's unit pruning or weight decay (\n  \n    \n      \n        \n          \u2113\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\ell _{2}}\n  \n-regularization) or sparsity (\n  \n    \n      \n        \n          \u2113\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\ell _{1}}\n  \n-regularization) can be applied during training to combat overfitting. Alternatively dropout regularization randomly omits units from the hidden layers during training. This helps to exclude rare dependencies. Another interesting recent development is research into models of just enough complexity through an estimation of the intrinsic complexity of the task being modelled. This approach has been successfully applied for multivariate time series prediction tasks such as traffic prediction. Finally, data can be augmented via methods such as cropping and rotating such that smaller training sets can be increased in size to reduce the chances of overfitting.\nDNNs must consider many training parameters, such as the size (number of layers and number of units per layer), the learning rate, and initial weights. Sweeping through the parameter space for optimal parameters may not be feasible due to the cost in time and computational resources. Various tricks, such as batching (computing the gradient on several training examples at once rather than individual examples) speed up computation. Large processing capabilities of many-core architectures (such as GPUs or the Intel Xeon Phi) have produced significant speedups in training, because of the suitability of such processing architectures for the matrix and vector computations.\nAlternatively, engineers may look for other types of neural networks with more straightforward and convergent training algorithms. CMAC (cerebellar model articulation controller) is one such kind of neural network. It doesn't require learning rates or randomized initial weights. The training process can be guaranteed to converge in one step with a new batch of data, and the computational complexity of the training algorithm is linear with respect to the number of neurons involved.\n\n\n== Hardware ==\nSince the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks that contain many layers of non-linear hidden units and a very large output layer. By 2019, graphics processing units (GPUs), often with AI-specific enhancements, had displaced CPUs as the dominant method for training large-scale commercial cloud AI . OpenAI estimated the hardware computation used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017) and found a 300,000-fold increase in the amount of computation required, with a doubling-time trendline of 3.4 months.\nSpecial electronic circuits called deep learning processors were designed to speed up deep learning algorithms. Deep learning processors include neural processing units (NPUs) in Huawei cellphones and cloud computing servers such as tensor processing units (TPU) in the Google Cloud Platform. Cerebras Systems has also built a dedicated system to handle large deep learning models, the CS-2, based on the largest processor in the industry, the second-generation Wafer Scale Engine (WSE-2).\nAtomically thin semiconductors are considered promising for energy-efficient deep learning hardware where the same basic device structure is used for both logic operations and data storage.\nIn 2020, Marega et al. published experiments with a large-area active channel material for developing logic-in-memory devices and circuits based on floating-gate field-effect transistors (FGFETs).\nIn 2021, J. Feldmann et al. proposed an integrated photonic hardware accelerator for parallel convolutional processing. The authors identify two key advantages of integrated photonics over its electronic counterparts: (1) massively parallel data transfer through wavelength division multiplexing in conjunction with frequency combs, and (2) extremely high data modulation speeds. Their system can execute trillions of multiply-accumulate operations per second, indicating the potential of integrated photonics in data-heavy AI applications.\n\n\n== Applications ==", "mimetype": "text/plain", "start_char_idx": 27805, "end_char_idx": 32372, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "682470e6-b604-496c-bc21-bc958d9caf62": {"__data__": {"id_": "682470e6-b604-496c-bc21-bc958d9caf62", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32472154", "node_type": "4", "metadata": {}, "hash": "2c6d7e6f84c4a9e5e945746e1ba39555343099af69cd64331fed1375c56fdd56", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "55807351-f087-4663-813f-0399077c90fe", "node_type": "1", "metadata": {}, "hash": "7630e998aa14d81f893183b1559984cece1a66bf939352ed23985b2bd24bb01f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f8b1ffb6-17c7-4339-af7b-899c4528a21e", "node_type": "1", "metadata": {}, "hash": "70b739311b55a76ac5f691bec58deeb1d0bae2a055cf32cba449473d9df71c81", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Applications ==\n\n\n=== Automatic speech recognition ===\n\nLarge-scale automatic speech recognition is the first and most convincing successful case of deep learning. LSTM RNNs can learn \"Very Deep Learning\" tasks that involve multi-second intervals containing speech events separated by thousands of discrete time steps, where one time step corresponds to about 10 ms. LSTM with forget gates is competitive with traditional speech recognizers on certain tasks.\nThe initial success in speech recognition was based on small-scale recognition tasks based on TIMIT. The data set contains 630 speakers from eight major dialects of American English, where each speaker reads 10 sentences. Its small size lets many configurations be tried. More importantly, the TIMIT task concerns phone-sequence recognition, which, unlike word-sequence recognition, allows weak phone bigram language models. This lets the strength of the acoustic modeling aspects of speech recognition be more easily analyzed. The error rates listed below, including these early results and measured as percent phone error rates (PER), have been summarized since 1991.\n\nThe debut of DNNs for speaker recognition in the late 1990s and speech recognition around 2009-2011 and of LSTM around 2003\u20132007, accelerated progress in eight major areas:\n\nScale-up/out and accelerated DNN training and decoding\nSequence discriminative training\nFeature processing by deep models with solid understanding of the underlying mechanisms\nAdaptation of DNNs and related deep models\nMulti-task and transfer learning by DNNs and related deep models\nCNNs and how to design them to best exploit domain knowledge of speech\nRNN and its rich LSTM variants\nOther types of deep models including tensor-based models and integrated deep generative/discriminative models.\nAll major commercial speech recognition systems (e.g., Microsoft Cortana, Xbox, Skype Translator, Amazon Alexa, Google Now, Apple Siri, Baidu and iFlyTek voice search, and a range of Nuance speech products, etc.) are based on deep learning.\n\n\n=== Image recognition ===\n\nA common evaluation set for image classification is the MNIST database data set. MNIST is composed of handwritten digits and includes 60,000 training examples and 10,000 test examples. As with TIMIT, its small size lets users test multiple configurations. A comprehensive list of results on this set is available.\nDeep learning-based image recognition has become \"superhuman\", producing more accurate results than human contestants. This first occurred in 2011 in recognition of traffic signs, and in 2014, with recognition of human faces.\nDeep learning-trained vehicles now interpret 360\u00b0 camera views. Another example is Facial Dysmorphology Novel Analysis (FDNA) used to analyze cases of human malformation connected to a large database of genetic syndromes.\n\n\n=== Visual art processing ===\n\nClosely related to the progress that has been made in image recognition is the increasing application of deep learning techniques to various visual art tasks. DNNs have proven themselves capable, for example, of\n\nidentifying the style period of a given painting\nNeural Style Transfer \u2013  capturing the style of a given artwork and applying it in a visually pleasing manner to an arbitrary photograph or video\ngenerating striking imagery based on random visual input fields.\n\n\n=== Natural language processing ===\n\nNeural networks have been used for implementing language models since the early 2000s. LSTM helped to improve machine translation and language modeling.\nOther key techniques in this field are negative sampling and word embedding. Word embedding, such as word2vec, can be thought of as a representational layer in a deep learning architecture that transforms an atomic word into a positional representation of the word relative to other words in the dataset; the position is represented as a point in a vector space. Using word embedding as an RNN input layer allows the network to parse sentences and phrases using an effective compositional vector grammar. A compositional vector grammar can be thought of as probabilistic context free grammar (PCFG) implemented by an RNN. Recursive auto-encoders built atop word embeddings can assess sentence similarity and detect paraphrasing. Deep neural architectures provide the best results for constituency parsing, sentiment analysis, information retrieval, spoken language understanding, machine translation, contextual entity linking, writing style recognition, named-entity recognition (token classification), text classification, and others.\nRecent developments generalize word embedding to sentence embedding.\nGoogle Translate (GT) uses a large end-to-end long short-term memory (LSTM) network. Google Neural Machine Translation (GNMT) uses an example-based machine translation method in which the system \"learns from millions of examples\". It translates \"whole sentences at a time, rather than pieces\". Google Translate supports over one hundred languages. The network encodes the \"semantics of the sentence rather than simply memorizing phrase-to-phrase translations\". GT uses English as an intermediate between most language pairs.", "mimetype": "text/plain", "start_char_idx": 32354, "end_char_idx": 37518, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f8b1ffb6-17c7-4339-af7b-899c4528a21e": {"__data__": {"id_": "f8b1ffb6-17c7-4339-af7b-899c4528a21e", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32472154", "node_type": "4", "metadata": {}, "hash": "2c6d7e6f84c4a9e5e945746e1ba39555343099af69cd64331fed1375c56fdd56", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "682470e6-b604-496c-bc21-bc958d9caf62", "node_type": "1", "metadata": {}, "hash": "bbcd61324f8329f2301b6b48fa9da21d0856791ddcf50b5b017e00c844c5a7ad", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "48cbff38-cf1e-4c6f-a74b-b271ac130d9a", "node_type": "1", "metadata": {}, "hash": "203d799683eb9588c44580e498fcc0da5ec133394c65f1fdf1570d9e78483c8a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Drug discovery and toxicology ===\n\nA large percentage of candidate drugs fail to win regulatory approval. These failures are caused by insufficient efficacy (on-target effect), undesired interactions (off-target effects), or unanticipated toxic effects. Research has explored use of deep learning to predict the biomolecular targets, off-targets, and toxic effects of environmental chemicals in nutrients, household products and drugs.\nAtomNet is a deep learning system for structure-based rational drug design. AtomNet was used to predict novel candidate biomolecules for disease targets such as the Ebola virus and multiple sclerosis.\nIn 2017 graph neural networks were used for the first time to predict various properties of molecules in a large toxicology data set. In 2019, generative neural networks were used to produce molecules that were validated experimentally all the way into mice.\n\n\n=== Customer relationship management ===\n\nDeep reinforcement learning has been used to approximate the value of possible direct marketing actions, defined in terms of RFM variables. The estimated value function was shown to have a natural interpretation as customer lifetime value.\n\n\n=== Recommendation systems ===\n\nRecommendation systems have used deep learning to extract meaningful features for a latent factor model for content-based music and journal recommendations. Multi-view deep learning has been applied for learning user preferences from multiple domains. The model uses a hybrid collaborative and content-based approach and enhances recommendations in multiple tasks.\n\n\n=== Bioinformatics ===\n\nAn autoencoder ANN was used in bioinformatics, to predict gene ontology annotations and gene-function relationships.\nIn medical informatics, deep learning was used to predict sleep quality based on data from wearables and predictions of health complications from electronic health record data.\nDeep neural networks have shown unparalleled performance in predicting protein structure, according to the sequence of the amino acids that make it up. In 2020, AlphaFold, a deep-learning based system, achieved a level of accuracy significantly higher than all previous computational methods.\n\n\n=== Deep Neural Network Estimations ===\nDeep neural networks can be used to estimate the entropy of a stochastic process and called Neural Joint Entropy Estimator (NJEE). Such an estimation provides insights on the effects of input random variables on an independent random variable. Practically, the DNN is trained as a classifier that maps an input vector or matrix X to an output probability distribution over the possible classes of random variable Y, given input X. For example, in image classification tasks, the NJEE maps a vector of pixels' color values to probabilities over possible image classes. In practice, the probability distribution of Y is obtained by a Softmax layer with number of nodes that is equal to the alphabet size of Y. NJEE uses continuously differentiable activation functions, such that the conditions for the universal approximation theorem holds. It is shown that this method provides a strongly consistent estimator and outperforms other methods in case of large alphabet sizes.\n\n\n=== Medical image analysis ===\nDeep learning has been shown to produce competitive results in medical application such as cancer cell classification, lesion detection, organ segmentation and image enhancement. Modern deep learning tools demonstrate the high accuracy of detecting various diseases and the helpfulness of their use by specialists to improve the diagnosis efficiency.\n\n\n=== Mobile advertising ===\nFinding the appropriate mobile audience for mobile advertising is always challenging, since many data points must be considered and analyzed before a target segment can be created and used in ad serving by any ad server. Deep learning has been used to interpret large, many-dimensioned advertising datasets. Many data points are collected during the request/serve/click internet advertising cycle. This information can form the basis of machine learning to improve ad selection.\n\n\n=== Image restoration ===\nDeep learning has been successfully applied to inverse problems such as denoising, super-resolution, inpainting, and film colorization. These applications include learning methods such as \"Shrinkage Fields for Effective Image Restoration\" which trains on an image dataset, and Deep Image Prior, which trains on the image that needs restoration.\n\n\n=== Financial fraud detection ===\nDeep learning is being successfully applied to financial fraud detection, tax evasion detection, and anti-money laundering.\n\n\n=== Materials science ===\nIn November 2023, researchers at Google DeepMind and Lawrence Berkeley National Laboratory announced that they had developed an AI system known as GNoME. This system has contributed to materials science by discovering over 2 million new materials within a relatively short timeframe. GNoME employs deep learning techniques to efficiently explore potential material structures, achieving a significant increase in the identification of stable inorganic crystal structures. The system's predictions were validated through autonomous robotic experiments, demonstrating a noteworthy success rate of 71%. The data of newly discovered materials is publicly available through the Materials Project database, offering researchers the opportunity to identify materials with desired properties for various applications. This development has implications for the future of scientific discovery and the integration of AI in material science research, potentially expediting material innovation and reducing costs in product development. The use of AI and deep learning suggests the possibility of minimizing or eliminating manual lab experiments and allowing scientists to focus more on the design and analysis of unique compounds.", "mimetype": "text/plain", "start_char_idx": 37521, "end_char_idx": 43404, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "48cbff38-cf1e-4c6f-a74b-b271ac130d9a": {"__data__": {"id_": "48cbff38-cf1e-4c6f-a74b-b271ac130d9a", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32472154", "node_type": "4", "metadata": {}, "hash": "2c6d7e6f84c4a9e5e945746e1ba39555343099af69cd64331fed1375c56fdd56", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f8b1ffb6-17c7-4339-af7b-899c4528a21e", "node_type": "1", "metadata": {}, "hash": "70b739311b55a76ac5f691bec58deeb1d0bae2a055cf32cba449473d9df71c81", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "da74462b-7f92-4b30-a154-291d49d9b3a1", "node_type": "1", "metadata": {}, "hash": "a86d7c31655b78cd073763d5410367f0fe709ed56783e29415eb14c577f1bff7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Materials science ===\nIn November 2023, researchers at Google DeepMind and Lawrence Berkeley National Laboratory announced that they had developed an AI system known as GNoME. This system has contributed to materials science by discovering over 2 million new materials within a relatively short timeframe. GNoME employs deep learning techniques to efficiently explore potential material structures, achieving a significant increase in the identification of stable inorganic crystal structures. The system's predictions were validated through autonomous robotic experiments, demonstrating a noteworthy success rate of 71%. The data of newly discovered materials is publicly available through the Materials Project database, offering researchers the opportunity to identify materials with desired properties for various applications. This development has implications for the future of scientific discovery and the integration of AI in material science research, potentially expediting material innovation and reducing costs in product development. The use of AI and deep learning suggests the possibility of minimizing or eliminating manual lab experiments and allowing scientists to focus more on the design and analysis of unique compounds.\n\n\n=== Military ===\nThe United States Department of Defense applied deep learning to train robots in new tasks through observation.\n\n\n=== Partial differential equations ===\nPhysics informed neural networks have been used to solve partial differential equations in both forward and inverse problems in a data driven manner. One example is the reconstructing fluid flow governed by the Navier-Stokes equations. Using physics informed neural networks does not require the often expensive mesh generation that conventional CFD methods rely on.\n\n\n=== Deep backward stochastic differential equation method ===\nDeep backward stochastic differential equation method is a numerical method that combines deep learning with Backward stochastic differential equation (BSDE). This method is particularly useful for solving high-dimensional problems in financial mathematics. By leveraging the powerful function approximation capabilities of deep neural networks, deep BSDE addresses the computational challenges faced by traditional numerical methods in high-dimensional settings. Specifically, traditional methods like finite difference methods or Monte Carlo simulations often struggle with the curse of dimensionality, where computational cost increases exponentially with the number of dimensions. Deep BSDE methods, however, employ deep neural networks to approximate solutions of high-dimensional partial differential equations (PDEs), effectively reducing the computational burden.\nIn addition, the integration of Physics-informed neural networks (PINNs) into the deep BSDE framework enhances its capability by embedding the underlying physical laws directly into the neural network architecture. This ensures that the solutions not only fit the data but also adhere to the governing stochastic differential equations. PINNs leverage the power of deep learning while respecting the constraints imposed by the physical models, resulting in more accurate and reliable solutions for financial mathematics problems.\n\n\n=== Image reconstruction ===\nImage reconstruction is the reconstruction of the underlying images from the image-related measurements. Several works showed the better and superior performance of the deep learning methods compared to analytical methods for various applications, e.g., spectral imaging  and ultrasound imaging.\n\n\n=== Weather prediction ===\nTraditional weather prediction systems solve a very complex system of partial differential equations. GraphCast is a deep learning based model, trained on a long history of weather data to predict how weather patterns change over time. It is able to  predict weather conditions for up to 10 days globally, at a very detailed level, and in under a minute, with precision similar to state of the art systems.\n\n\n=== Epigenetic clock ===\n\nAn epigenetic clock is a biochemical test that can be used to measure age. Galkin et al. used deep neural networks to train an epigenetic aging clock of unprecedented accuracy using >6,000 blood samples. The clock uses information from 1000 CpG sites and predicts people with certain conditions older than healthy controls: IBD, frontotemporal dementia, ovarian cancer, obesity. The aging clock was planned to be released for public use in 2021 by an Insilico Medicine spinoff company Deep Longevity.", "mimetype": "text/plain", "start_char_idx": 42159, "end_char_idx": 46701, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "da74462b-7f92-4b30-a154-291d49d9b3a1": {"__data__": {"id_": "da74462b-7f92-4b30-a154-291d49d9b3a1", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32472154", "node_type": "4", "metadata": {}, "hash": "2c6d7e6f84c4a9e5e945746e1ba39555343099af69cd64331fed1375c56fdd56", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "48cbff38-cf1e-4c6f-a74b-b271ac130d9a", "node_type": "1", "metadata": {}, "hash": "203d799683eb9588c44580e498fcc0da5ec133394c65f1fdf1570d9e78483c8a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ca4ed15b-8a74-45ad-8851-193a04db4413", "node_type": "1", "metadata": {}, "hash": "6b8ada9065c62e30cf7cda3b948509978fa1085d0de585a7946fff38ff879bcd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Epigenetic clock ===\n\nAn epigenetic clock is a biochemical test that can be used to measure age. Galkin et al. used deep neural networks to train an epigenetic aging clock of unprecedented accuracy using >6,000 blood samples. The clock uses information from 1000 CpG sites and predicts people with certain conditions older than healthy controls: IBD, frontotemporal dementia, ovarian cancer, obesity. The aging clock was planned to be released for public use in 2021 by an Insilico Medicine spinoff company Deep Longevity.\n\n\n== Relation to human cognitive and brain development ==\nDeep learning is closely related to a class of theories of brain development (specifically, neocortical development) proposed by cognitive neuroscientists in the early 1990s. These developmental theories were instantiated in computational models, making them predecessors of deep learning systems. These developmental models share the property that various proposed learning dynamics in the brain (e.g., a wave of nerve growth factor) support the self-organization somewhat analogous to the neural networks utilized in deep learning models. Like the neocortex, neural networks employ a hierarchy of layered filters in which each layer considers information from a prior layer (or the operating environment), and then passes its output (and possibly the original input), to other layers. This process yields a self-organizing stack of transducers, well-tuned to their operating environment. A 1995 description stated, \"...the infant's brain seems to organize itself under the influence of waves of so-called trophic-factors ... different regions of the brain become connected sequentially, with one layer of tissue maturing before another and so on until the whole brain is mature\".\nA variety of approaches have been used to investigate the plausibility of deep learning models from a neurobiological perspective. On the one hand, several variants of the backpropagation algorithm have been proposed in order to increase its processing realism. Other researchers have argued that unsupervised forms of deep learning, such as those based on hierarchical generative models and deep belief networks, may be closer to biological reality. In this respect, generative neural network models have been related to neurobiological evidence about sampling-based processing in the cerebral cortex.\nAlthough a systematic comparison between the human brain organization and the neuronal encoding in deep networks has not yet been established, several analogies have been reported. For example, the computations performed by deep learning units could be similar to those of actual neurons and neural populations. Similarly, the representations developed by deep learning models are similar to those measured in the primate visual system both at the single-unit and at the population levels.\n\n\n== Commercial activity ==\nFacebook's AI lab performs tasks such as automatically tagging uploaded pictures with the names of the people in them.\nGoogle's DeepMind Technologies developed a system capable of learning how to play Atari video games using only pixels as data input. In 2015 they demonstrated their AlphaGo system, which learned the game of Go well enough to beat a professional Go player. Google Translate uses a neural network to translate between more than 100 languages.\nIn 2017, Covariant.ai was launched, which focuses on integrating deep learning into factories.\nAs of 2008, researchers at The University of Texas at Austin (UT) developed a machine learning framework called Training an Agent Manually via Evaluative Reinforcement, or TAMER, which proposed new methods for robots or computer programs to learn how to perform tasks by interacting with a human instructor. First developed as TAMER, a new algorithm called Deep TAMER was later introduced in 2018 during a collaboration between U.S. Army Research Laboratory (ARL) and UT researchers. Deep TAMER used deep learning to provide a robot with the ability to learn new tasks through observation. Using Deep TAMER, a robot learned a task with a human trainer, watching video streams or observing a human perform a task in-person. The robot later practiced the task with the help of some coaching from the trainer, who provided feedback such as \"good job\" and \"bad job\".\n\n\n== Criticism and comment ==\nDeep learning has attracted both criticism and comment, in some cases from outside the field of computer science.", "mimetype": "text/plain", "start_char_idx": 46175, "end_char_idx": 50624, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ca4ed15b-8a74-45ad-8851-193a04db4413": {"__data__": {"id_": "ca4ed15b-8a74-45ad-8851-193a04db4413", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32472154", "node_type": "4", "metadata": {}, "hash": "2c6d7e6f84c4a9e5e945746e1ba39555343099af69cd64331fed1375c56fdd56", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "da74462b-7f92-4b30-a154-291d49d9b3a1", "node_type": "1", "metadata": {}, "hash": "a86d7c31655b78cd073763d5410367f0fe709ed56783e29415eb14c577f1bff7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d8063aa9-302d-4bb7-a7cf-a3d3b2fdb83b", "node_type": "1", "metadata": {}, "hash": "14d92b98b7f874110c097c8552b19fb05f90896a2793dd7675f3ca88a9bb4946", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Criticism and comment ==\nDeep learning has attracted both criticism and comment, in some cases from outside the field of computer science.\n\n\n=== Theory ===\n\nA main criticism concerns the lack of theory surrounding some methods. Learning in the most common deep architectures is implemented using well-understood gradient descent. However, the theory surrounding other algorithms, such as contrastive divergence is less clear. (e.g., Does it converge? If so, how fast? What is it approximating?) Deep learning methods are often looked at as a black box, with most confirmations done empirically, rather than theoretically.\nIn further reference to the idea that artistic sensitivity might be inherent in relatively low levels of the cognitive hierarchy, a published series of graphic representations of the internal states of deep (20-30 layers) neural networks attempting to discern within essentially random data the images on which they were trained demonstrate a visual appeal: the original research notice received well over 1,000 comments, and was the subject of what was for a time the most frequently accessed article on The Guardian's website.\nFurthermore, some researchers have argued that standard loss functions and differentiable architectures in deep learning may limit the discovery of deeper causal or generative mechanisms. Building on Algorithmic information theory (AIT), Hern\u00e1ndez-Orozco et al. (2021) proposed an algorithmic loss function to measure the discrepancy between predicted and observed system behavior. Their approach integrates AIT with Machine learning to formulate a framework for learning generative rules in non-differentiable spaces, bridging discrete algorithmic theory with continuous optimization techniques. This framework provides a new perspective on generalization and model interpretability by grounding learning dynamics in algorithmic complexity.  \n\n\n=== Errors ===\nSome deep learning architectures display problematic behaviors, such as confidently classifying unrecognizable images as belonging to a familiar category of ordinary images (2014) and misclassifying minuscule perturbations of correctly classified images (2013). Goertzel hypothesized that these behaviors are due to limitations in their internal representations and that these limitations would inhibit integration into heterogeneous multi-component artificial general intelligence (AGI) architectures. These issues may possibly be addressed by deep learning architectures that internally form states homologous to image-grammar decompositions of observed entities and events. Learning a grammar (visual or linguistic) from training data would be equivalent to restricting the system to commonsense reasoning that operates on concepts in terms of grammatical production rules and is a basic goal of both human language acquisition and artificial intelligence (AI).\n\n\n=== Cyber threat ===\nAs deep learning moves from the lab into the world, research and experience show that artificial neural networks are vulnerable to hacks and deception. By identifying patterns that these systems use to function, attackers can modify inputs to ANNs in such a way that the ANN finds a match that human observers would not recognize. For example, an attacker can make subtle changes to an image such that the ANN finds a match even though the image looks to a human nothing like the search target. Such manipulation is termed an \"adversarial attack\".\nIn 2016 researchers used one ANN to doctor images in trial and error fashion, identify another's focal points, and thereby generate images that deceived it. The modified images looked no different to human eyes. Another group showed that printouts of doctored images then photographed successfully tricked an image classification system. One defense is reverse image search, in which a possible fake image is submitted to a site such as TinEye that can then find other instances of it. A refinement is to search using only parts of the image, to identify images from which that piece may have been taken.\nAnother group showed that certain psychedelic spectacles could fool a facial recognition system into thinking ordinary people were celebrities, potentially allowing one person to impersonate another. In 2017 researchers added stickers to stop signs and caused an ANN to misclassify them.\nANNs can however be further trained to detect attempts at deception, potentially leading attackers and defenders into an arms race similar to the kind that already defines the malware defense industry. ANNs have been trained to defeat ANN-based anti-malware software by repeatedly attacking a defense with malware that was continually altered by a genetic algorithm until it tricked the anti-malware while retaining its ability to damage the target.\nIn 2016, another group demonstrated that certain sounds could make the Google Now voice command system open a particular web address, and hypothesized that this could \"serve as a stepping stone for further attacks (e.g., opening a web page hosting drive-by malware)\".\nIn \"data poisoning\", false data is continually smuggled into a machine learning system's training set to prevent it from achieving mastery.", "mimetype": "text/plain", "start_char_idx": 50483, "end_char_idx": 55684, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d8063aa9-302d-4bb7-a7cf-a3d3b2fdb83b": {"__data__": {"id_": "d8063aa9-302d-4bb7-a7cf-a3d3b2fdb83b", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32472154", "node_type": "4", "metadata": {}, "hash": "2c6d7e6f84c4a9e5e945746e1ba39555343099af69cd64331fed1375c56fdd56", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ca4ed15b-8a74-45ad-8851-193a04db4413", "node_type": "1", "metadata": {}, "hash": "6b8ada9065c62e30cf7cda3b948509978fa1085d0de585a7946fff38ff879bcd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Data collection ethics ===\nThe deep learning systems that are trained using supervised learning often rely on data that is created or annotated by humans, or both. It has been argued that not only low-paid clickwork (such as on Amazon Mechanical Turk) is regularly deployed for this purpose, but also implicit forms of human microwork that are often not recognized as such. The philosopher Rainer M\u00fchlhoff distinguishes five types of \"machinic capture\" of human microwork to generate training data: (1) gamification (the embedding of annotation or computation tasks in the flow of a game), (2) \"trapping and tracking\" (e.g. CAPTCHAs for image recognition or click-tracking on Google search results pages), (3) exploitation of social motivations (e.g. tagging faces on Facebook to obtain labeled facial images), (4) information mining (e.g. by leveraging quantified-self devices such as activity trackers) and (5) clickwork.\n\n\n== See also ==\nApplications of artificial intelligence\nComparison of deep learning software\nCompressed sensing\nDifferentiable programming\nEcho state network\nList of artificial intelligence projects\nLiquid state machine\nList of datasets for machine-learning research\nReservoir computing\nScale space and deep learning\nSparse coding\nStochastic parrot\nTopological deep learning\n\n\n== References ==\n\n\n== Further reading ==", "mimetype": "text/plain", "start_char_idx": 55687, "end_char_idx": 57033, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "121b47e8-914a-432b-abf7-54c888e3dcaa": {"__data__": {"id_": "121b47e8-914a-432b-abf7-54c888e3dcaa", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "981bb578-8268-41a2-b1ae-1b3cd02958f5", "node_type": "1", "metadata": {}, "hash": "ec25a31db27e14def7d2876f2be3b484fc90731068663d84ebc1819cc9e8425f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "A convolutional neural network (CNN) is a type of feedforward neural network that learns features via filter (or kernel) optimization. This type of deep learning network has been applied to process and make predictions from many different types of data including text, images and audio. Convolution-based networks are the de-facto standard in deep learning-based approaches to computer vision and image processing, and have only recently been replaced\u2014in some cases\u2014by newer deep learning architectures such as the transformer.\nVanishing gradients and exploding gradients, seen during backpropagation in earlier neural networks, are prevented by the regularization that comes from using shared weights over fewer connections. For example, for each neuron in the fully-connected layer, 10,000 weights would be required for processing an image sized 100 \u00d7 100 pixels. However, applying cascaded convolution (or cross-correlation) kernels, only 25 weights for each convolutional layer are required to process 5x5-sized tiles. Higher-layer features are extracted from wider context windows, compared to lower-layer features.\nSome applications of CNNs include: \n\nimage and video recognition,\nrecommender systems,\nimage classification,\nimage segmentation,\nmedical image analysis,\nnatural language processing,\nbrain\u2013computer interfaces, and\nfinancial time series.\nCNNs are also known as shift invariant or space invariant artificial neural networks, based on the shared-weight architecture of the convolution kernels or filters that slide along input features and provide translation-equivariant responses known as feature maps. Counter-intuitively, most convolutional neural networks are not invariant to translation, due to the downsampling operation they apply to the input.\nFeedforward neural networks are usually fully connected networks, that is, each neuron in one layer is connected to all neurons in the next layer. The \"full connectivity\" of these networks makes them prone to overfitting data. Typical ways of regularization, or preventing overfitting, include: penalizing parameters during training (such as weight decay) or trimming connectivity (skipped connections, dropout, etc.) Robust datasets also increase the probability that CNNs will learn the generalized principles that characterize a given dataset rather than the biases of a poorly-populated set.\nConvolutional networks were inspired by biological processes in that the connectivity pattern between neurons resembles the organization of the animal visual cortex. Individual cortical neurons respond to stimuli only in a restricted region of the visual field known as the receptive field. The receptive fields of different neurons partially overlap such that they cover the entire visual field.\nCNNs use relatively little pre-processing compared to other image classification algorithms. This means that the network learns to optimize the filters (or kernels) through automated learning, whereas in traditional algorithms these filters are hand-engineered. This simplifies and automates the process, enhancing efficiency and scalability overcoming human-intervention bottlenecks.\n\n\n== Architecture ==\n\nA convolutional neural network consists of an input layer, hidden layers and an output layer. In a convolutional neural network, the hidden layers include one or more layers that perform convolutions. Typically this includes a layer that performs a dot product of the convolution kernel with the layer's input matrix. This product is usually the Frobenius inner product, and its activation function is commonly ReLU. As the convolution kernel slides along the input matrix for the layer, the convolution operation generates a feature map, which in turn contributes to the input of the next layer. This is followed by other layers such as pooling layers, fully connected layers, and normalization layers.\nHere it should be noted how close a convolutional neural network is to a matched filter.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3963, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "981bb578-8268-41a2-b1ae-1b3cd02958f5": {"__data__": {"id_": "981bb578-8268-41a2-b1ae-1b3cd02958f5", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "121b47e8-914a-432b-abf7-54c888e3dcaa", "node_type": "1", "metadata": {}, "hash": "bff1ffc7829a4df7a9f0a99b2f40bab260abe2c38a7698cb8ce9c77184b12417", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "af19dddc-cce4-4e87-a7fe-87d7a1cb1be2", "node_type": "1", "metadata": {}, "hash": "bda2ebb583c9a8b676b2ed17a0659b8ce0f799f84dc1716f9625a1c6cfa61bf1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Architecture ==\n\nA convolutional neural network consists of an input layer, hidden layers and an output layer. In a convolutional neural network, the hidden layers include one or more layers that perform convolutions. Typically this includes a layer that performs a dot product of the convolution kernel with the layer's input matrix. This product is usually the Frobenius inner product, and its activation function is commonly ReLU. As the convolution kernel slides along the input matrix for the layer, the convolution operation generates a feature map, which in turn contributes to the input of the next layer. This is followed by other layers such as pooling layers, fully connected layers, and normalization layers.\nHere it should be noted how close a convolutional neural network is to a matched filter.\n\n\n=== Convolutional layers ===\nIn a CNN, the input is a tensor with shape:\n(number of inputs) \u00d7 (input height) \u00d7 (input width) \u00d7 (input channels)\nAfter passing through a convolutional layer, the image becomes abstracted to a feature map, also called an activation map, with shape:\n(number of inputs) \u00d7 (feature map height) \u00d7 (feature map width) \u00d7 (feature map channels).\nConvolutional layers convolve the input and pass its result to the next layer. This is similar to the response of a neuron in the visual cortex to a specific stimulus. Each convolutional neuron processes data only for its receptive field. \n\nAlthough fully connected feedforward neural networks can be used to learn features and classify data, this architecture is generally impractical for larger inputs (e.g., high-resolution images), which would require massive numbers of neurons because each pixel is a relevant input feature. A fully connected layer for an image of size 100 \u00d7 100 has 10,000 weights for each neuron in the second layer. Convolution reduces the number of free parameters, allowing the network to be deeper. For example, using a 5 \u00d7 5 tiling region, each with the same shared weights, requires only 25 neurons. Using shared weights means there are many fewer parameters, which helps avoid the vanishing gradients and exploding gradients problems seen during backpropagation in earlier neural networks.\nTo speed processing, standard convolutional layers can be replaced by depthwise separable convolutional layers, which are based on a depthwise convolution followed by a pointwise convolution. The depthwise convolution is a spatial convolution applied independently over each channel of the input tensor, while the pointwise convolution is a standard convolution restricted to the use of \n  \n    \n      \n        1\n        \u00d7\n        1\n      \n    \n    {\\displaystyle 1\\times 1}\n  \n kernels.\n\n\n=== Pooling layers ===\nConvolutional networks may include local and/or global pooling layers along with traditional convolutional layers. Pooling layers reduce the dimensions of data by combining the outputs of neuron clusters at one layer into a single neuron in the next layer. Local pooling combines small clusters, tiling sizes such as 2 \u00d7 2 are commonly used. Global pooling acts on all the neurons of the feature map. There are two common types of pooling in popular use: max and average. Max pooling uses the maximum value of each local cluster of neurons in the feature map, while average pooling takes the average value.\n\n\n=== Fully connected layers ===\nFully connected layers connect every neuron in one layer to every neuron in another layer. It is the same as a traditional multilayer perceptron neural network (MLP). The flattened matrix goes through a fully connected layer to classify the images.\n\n\n=== Receptive field ===\nIn neural networks, each neuron receives input from some number of locations in the previous layer. In a convolutional layer, each neuron receives input from only a restricted area of the previous layer called the neuron's receptive field. Typically the area is a square (e.g. 5 by 5 neurons). Whereas, in a fully connected layer, the receptive field is the entire previous layer. Thus, in each convolutional layer, each neuron takes input from a larger area in the input than previous layers. This is due to applying the convolution over and over, which takes the value of a pixel into account, as well as its surrounding pixels. When using dilated layers, the number of pixels in the receptive field remains constant, but the field is more sparsely populated as its dimensions grow when combining the effect of several layers.\nTo manipulate the receptive field size as desired, there are some alternatives to the standard convolutional layer. For example, atrous or dilated convolution expands the receptive field size without increasing the number of parameters by interleaving visible and blind regions. Moreover, a single dilated convolutional layer can comprise filters with multiple dilation ratios, thus having a variable receptive field size.", "mimetype": "text/plain", "start_char_idx": 3151, "end_char_idx": 8036, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "af19dddc-cce4-4e87-a7fe-87d7a1cb1be2": {"__data__": {"id_": "af19dddc-cce4-4e87-a7fe-87d7a1cb1be2", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "981bb578-8268-41a2-b1ae-1b3cd02958f5", "node_type": "1", "metadata": {}, "hash": "ec25a31db27e14def7d2876f2be3b484fc90731068663d84ebc1819cc9e8425f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1c071c84-da1c-4646-904b-02c49ed0f7eb", "node_type": "1", "metadata": {}, "hash": "2f251fa8d7d1e0c52028303717f9715af1e44bb4769fe1d5722d9947c7d65a16", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Weights ===\nEach neuron in a neural network computes an output value by applying a specific function to the input values received from the receptive field in the previous layer. The function that is applied to the input values is determined by a vector of weights and a bias (typically real numbers). Learning consists of iteratively adjusting these biases and weights.\nThe vectors of weights and biases are called filters and represent particular features of the input (e.g., a particular shape). A distinguishing feature of CNNs is that many neurons can share the same filter. This reduces the memory footprint because a single bias and a single vector of weights are used across all receptive fields that share that filter, as opposed to each receptive field having its own bias and vector weighting.\n\n\n=== Deconvolutional ===\n\nA deconvolutional neural network is essentially the reverse of a CNN. It consists of deconvolutional layers and unpooling layers. \nA deconvolutional layer is the transpose of a convolutional layer. Specifically, a convolutional layer can be written as a multiplication with a matrix, and a deconvolutional layer is multiplication with the transpose of that matrix.\nAn unpooling layer expands the layer. The max-unpooling layer is the simplest, as it simply copies each entry multiple times. For example, a 2-by-2 max-unpooling layer is \n  \n    \n      \n        [\n        x\n        ]\n        \u21a6\n        \n          \n            [\n            \n              \n                \n                  x\n                \n                \n                  x\n                \n              \n              \n                \n                  x\n                \n                \n                  x\n                \n              \n            \n            ]\n          \n        \n      \n    \n    {\\displaystyle [x]\\mapsto {\\begin{bmatrix}x&x\\\\x&x\\end{bmatrix}}}\n  \n.\nDeconvolution layers are used in image generators. By default, it creates periodic checkerboard artifact, which can be fixed by upscale-then-convolve.\n\n\n== History ==\nCNN are often compared to the way the brain achieves vision processing in living organisms.\n\n\n=== Receptive fields in the visual cortex ===\nWork by Hubel and Wiesel in the 1950s and 1960s showed that cat visual cortices contain neurons that individually respond to small regions of the visual field. Provided the eyes are not moving, the region of visual space within which visual stimuli affect the firing of a single neuron is known as its receptive field. Neighboring cells have similar and overlapping receptive fields. Receptive field size and location varies systematically across the cortex to form a complete map of visual space. The cortex in each hemisphere represents the contralateral visual field.\nTheir 1968 paper identified two basic visual cell types in the brain:\n\nsimple cells, whose output is maximized by straight edges having particular orientations within their receptive field\ncomplex cells, which have larger receptive fields, whose output is insensitive to the exact position of the edges in the field.\nHubel and Wiesel also proposed a cascading model of these two types of cells for use in pattern recognition tasks.\n\n\n=== Fukushima's analog threshold elements in a vision model ===\nIn 1969, Kunihiko Fukushima introduced a multilayer visual feature detection network, inspired by the above-mentioned work of Hubel and Wiesel, in which \"All the elements in one layer have the same set of interconnecting coefficients; the arrangement of the elements and their interconnections are all homogeneous over a given layer.\"  This is the essential core of a convolutional network, but the weights were not trained.  In the same paper, Fukushima also introduced the ReLU (rectified linear unit) activation function.", "mimetype": "text/plain", "start_char_idx": 8039, "end_char_idx": 11823, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1c071c84-da1c-4646-904b-02c49ed0f7eb": {"__data__": {"id_": "1c071c84-da1c-4646-904b-02c49ed0f7eb", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "af19dddc-cce4-4e87-a7fe-87d7a1cb1be2", "node_type": "1", "metadata": {}, "hash": "bda2ebb583c9a8b676b2ed17a0659b8ce0f799f84dc1716f9625a1c6cfa61bf1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cee819b4-b95e-4f1a-99d9-6f7a657c53b7", "node_type": "1", "metadata": {}, "hash": "007afd1be5de0db82730cee4e08eac3223697ed7d8cc657a2c6d95ec54e373d9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Fukushima's analog threshold elements in a vision model ===\nIn 1969, Kunihiko Fukushima introduced a multilayer visual feature detection network, inspired by the above-mentioned work of Hubel and Wiesel, in which \"All the elements in one layer have the same set of interconnecting coefficients; the arrangement of the elements and their interconnections are all homogeneous over a given layer.\"  This is the essential core of a convolutional network, but the weights were not trained.  In the same paper, Fukushima also introduced the ReLU (rectified linear unit) activation function. \n\n\n=== Neocognitron, origin of the trainable CNN architecture ===\nThe \"neocognitron\" was introduced by Fukushima in 1980.  The neocognitron introduced the two basic types of layers:\n\n\"S-layer\": a shared-weights receptive-field layer, later known as a convolutional layer, which contains units whose receptive fields cover a patch of the previous layer. A shared-weights receptive-field group (a \"plane\" in neocognitron terminology) is often called a filter, and a layer typically has several such filters.\n\"C-layer\": a downsampling layer that contain units whose receptive fields cover patches of previous convolutional layers. Such a unit typically computes a weighted average of the activations of the units in its patch, and applies inhibition (divisive normalization) pooled from a somewhat larger patch and across different filters in a layer, and applies a saturating activation function. The patch weights are nonnegative and are not trainable in the original neocognitron. The downsampling and competitive inhibition help to classify features and objects in visual scenes even when the objects are shifted.\nSeveral supervised and unsupervised learning algorithms have been proposed over the decades to train the weights of a neocognitron. Today, however, the CNN architecture is usually trained through backpropagation.\nFukushima's ReLU activation function was not used in his neocognitron since all the weights were nonnegative; lateral inhibition was used instead. The rectifier has become a very popular activation function for CNNs and deep neural networks in general.\n\n\n=== Convolution in time ===\nThe term \"convolution\" first appears in neural networks in a paper by Toshiteru Homma, Les Atlas, and Robert Marks II at the first Conference on Neural Information Processing Systems in 1987. Their paper replaced multiplication with convolution in time, inherently providing shift invariance, motivated by and connecting more directly to the signal-processing concept of a filter, and demonstrated it on a speech recognition task. They also pointed out that as a data-trainable system, convolution is essentially equivalent to correlation since reversal of the weights does not affect the final learned function (\"For convenience, we denote * as correlation instead of convolution. Note that convolving a(t) with b(t) is equivalent to correlating a(-t) with b(t).\"). Modern CNN implementations typically do correlation and call it convolution, for convenience, as they did here.\n\n\n=== Time delay neural networks ===\nThe time delay neural network (TDNN) was introduced in 1987 by Alex Waibel et al. for phoneme recognition and was an early convolutional network exhibiting shift-invariance. A TDNN is a 1-D convolutional neural net where the convolution is performed along the time axis of the data. It is the first CNN utilizing weight sharing in combination with a training by gradient descent, using backpropagation. Thus, while also using a pyramidal structure as in the neocognitron, it performed a global optimization of the weights instead of a local one.\nTDNNs are convolutional networks that share weights along the temporal dimension. They allow speech signals to be processed time-invariantly. In 1990 Hampshire and Waibel introduced a variant that performs a two-dimensional convolution. Since these TDNNs operated on spectrograms, the resulting phoneme recognition system was invariant to both time and frequency shifts, as with images processed by a neocognitron.\nTDNNs improved the performance of far-distance speech recognition.", "mimetype": "text/plain", "start_char_idx": 11235, "end_char_idx": 15378, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cee819b4-b95e-4f1a-99d9-6f7a657c53b7": {"__data__": {"id_": "cee819b4-b95e-4f1a-99d9-6f7a657c53b7", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1c071c84-da1c-4646-904b-02c49ed0f7eb", "node_type": "1", "metadata": {}, "hash": "2f251fa8d7d1e0c52028303717f9715af1e44bb4769fe1d5722d9947c7d65a16", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "013e5c8a-180a-4426-ab64-ed043a254d99", "node_type": "1", "metadata": {}, "hash": "d7f3665ce0568050df9042dc14d2b20f266f9ef4d639df8277fe5fe3db1dbed7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Image recognition with CNNs trained by gradient descent ===\nDenker et al. (1989) designed a 2-D CNN system to recognize hand-written ZIP Code numbers. However, the lack of an efficient training method to determine the kernel coefficients of the involved convolutions meant that all the coefficients had to be laboriously hand-designed.\nFollowing the advances in the training of 1-D CNNs by Waibel et al. (1987), Yann LeCun et al. (1989) used back-propagation to learn the convolution kernel coefficients directly from images of hand-written numbers. Learning was thus fully automatic, performed better than manual coefficient design, and was suited to a broader range of image recognition problems and image types. \nWei Zhang et al. (1988) used back-propagation to train the convolution kernels of a CNN for alphabets recognition. The model was called shift-invariant pattern recognition neural network before the name CNN was coined later in the early 1990s. Wei Zhang et al. also applied the same CNN without the last fully connected layer for medical image object segmentation (1991) and breast cancer detection in mammograms (1994).\nThis approach became a foundation of modern computer vision.\n\n\n==== Max pooling ====\nIn 1990 Yamaguchi et al. introduced the concept of max pooling, a fixed filtering operation that calculates and propagates the maximum value of a given region. They did so by combining TDNNs with max pooling to realize a speaker-independent isolated word recognition system. In their system they used several TDNNs per word, one for each syllable. The results of each TDNN over the input signal were combined using max pooling and the outputs of the pooling layers were then passed on to networks performing the actual word classification.\nIn a variant of the neocognitron called the cresceptron, instead of using Fukushima's spatial averaging with inhibition and saturation, J. Weng et al. in 1993 used max pooling, where a downsampling unit computes the maximum of the activations of the units in its patch, introducing this method into the vision field. \nMax pooling is often used in modern CNNs.\n\n\n==== LeNet-5 ====\n\nLeNet-5, a pioneering 7-level convolutional network by LeCun et al. in 1995, classifies hand-written numbers on checks (British English: cheques) digitized in 32x32 pixel images. The ability to process higher-resolution images requires larger and more layers of convolutional neural networks, so this technique is constrained by the availability of computing resources.\nIt was superior than other commercial courtesy amount reading systems (as of 1995). The system was integrated in NCR's check reading systems, and fielded in several American banks since June 1996, reading millions of checks per day.\n\n\n=== Shift-invariant neural network ===\nA shift-invariant neural network was proposed by Wei Zhang et al. for image character recognition in 1988. It is a modified Neocognitron by keeping only the convolutional interconnections between the image feature layers and the last fully connected layer. The model was trained with back-propagation. The training algorithm was further improved in 1991 to improve its generalization ability. The model architecture was modified by removing the last fully connected layer and applied for medical image segmentation (1991) and automatic detection of breast cancer in mammograms (1994).\nA different convolution-based design was proposed in 1988 for application to decomposition of one-dimensional electromyography convolved signals via de-convolution. This design was modified in 1989 to other de-convolution-based designs.", "mimetype": "text/plain", "start_char_idx": 15381, "end_char_idx": 18993, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "013e5c8a-180a-4426-ab64-ed043a254d99": {"__data__": {"id_": "013e5c8a-180a-4426-ab64-ed043a254d99", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cee819b4-b95e-4f1a-99d9-6f7a657c53b7", "node_type": "1", "metadata": {}, "hash": "007afd1be5de0db82730cee4e08eac3223697ed7d8cc657a2c6d95ec54e373d9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0f03deee-09fb-4d92-b6a6-678a329bb62d", "node_type": "1", "metadata": {}, "hash": "d669ab12718c1502c2854ed11cc11c14f95f65bf81edfce7bd40333927f7f4f4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Shift-invariant neural network ===\nA shift-invariant neural network was proposed by Wei Zhang et al. for image character recognition in 1988. It is a modified Neocognitron by keeping only the convolutional interconnections between the image feature layers and the last fully connected layer. The model was trained with back-propagation. The training algorithm was further improved in 1991 to improve its generalization ability. The model architecture was modified by removing the last fully connected layer and applied for medical image segmentation (1991) and automatic detection of breast cancer in mammograms (1994).\nA different convolution-based design was proposed in 1988 for application to decomposition of one-dimensional electromyography convolved signals via de-convolution. This design was modified in 1989 to other de-convolution-based designs.\n\n\n=== GPU implementations ===\nAlthough CNNs were invented in the 1980s, their breakthrough in the 2000s required fast implementations on graphics processing units (GPUs).\nIn 2004, it was shown by K. S. Oh and K. Jung that standard neural networks can be greatly accelerated on GPUs. Their implementation was 20 times faster than an equivalent implementation on CPU. In 2005, another paper also emphasised the value of GPGPU for machine learning.\nThe first GPU-implementation of a CNN was described in 2006 by K. Chellapilla et al. Their implementation was 4 times faster than an equivalent implementation on CPU. In the same period, GPUs were also used for unsupervised training of deep belief networks.\nIn 2010, Dan Ciresan et al. at IDSIA trained deep feedforward networks on GPUs. In 2011, they extended this to CNNs, accelerating by 60 compared to training CPU. In 2011, the network won an image recognition contest where they achieved superhuman performance for the first time. Then they won more competitions and achieved state of the art on several benchmarks.\nSubsequently, AlexNet, a similar GPU-based CNN by Alex Krizhevsky et al. won the ImageNet Large Scale Visual Recognition Challenge 2012. It was an early catalytic event for the AI boom.\nCompared to the training of CNNs using GPUs, not much attention was given to CPU. (Viebke et al 2019) parallelizes CNN by thread- and SIMD-level parallelism that is available on the Intel Xeon Phi.", "mimetype": "text/plain", "start_char_idx": 18133, "end_char_idx": 20445, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0f03deee-09fb-4d92-b6a6-678a329bb62d": {"__data__": {"id_": "0f03deee-09fb-4d92-b6a6-678a329bb62d", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "013e5c8a-180a-4426-ab64-ed043a254d99", "node_type": "1", "metadata": {}, "hash": "d7f3665ce0568050df9042dc14d2b20f266f9ef4d639df8277fe5fe3db1dbed7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "46f103c5-2e21-4651-a84a-0b458a4079ba", "node_type": "1", "metadata": {}, "hash": "702551c10d7f7170d374907a743e0776b4cac616b46e25a4ecdbd88ed8f4d3b0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Distinguishing features ==\nIn the past, traditional multilayer perceptron (MLP) models were used for image recognition. However, the full connectivity between nodes caused the curse of dimensionality, and was computationally intractable with higher-resolution images. A 1000\u00d71000-pixel image with RGB color channels has 3 million weights per fully-connected neuron, which is too high to feasibly process efficiently at scale.\n\nFor example, in CIFAR-10, images are only of size 32\u00d732\u00d73 (32 wide, 32 high, 3 color channels), so a single fully connected neuron in the first hidden layer of a regular neural network would have 32*32*3 = 3,072 weights. A 200\u00d7200 image, however, would lead to neurons that have 200*200*3 = 120,000 weights.\nAlso, such network architecture does not take into account the spatial structure of data, treating input pixels which are far apart in the same way as pixels that are close together. This ignores locality of reference in data with a grid-topology (such as images), both computationally and semantically. Thus, full connectivity of neurons is wasteful for purposes such as image recognition that are dominated by spatially local input patterns.\nConvolutional neural networks are variants of multilayer perceptrons, designed to emulate the behavior of a visual cortex. These models mitigate the challenges posed by the MLP architecture by exploiting the strong spatially local correlation present in natural images. As opposed to MLPs, CNNs have the following distinguishing features:\n\n3D volumes of neurons. The layers of a CNN have neurons arranged in 3 dimensions: width, height and depth. Where each neuron inside a convolutional layer is connected to only a small region of the layer before it, called a receptive field. Distinct types of layers, both locally and completely connected, are stacked to form a CNN architecture.\nLocal connectivity: following the concept of receptive fields, CNNs exploit spatial locality by enforcing a local connectivity pattern between neurons of adjacent layers. The architecture thus ensures that the learned \"filters\" produce the strongest response to a spatially local input pattern. Stacking many such layers leads to nonlinear filters that become increasingly global (i.e. responsive to a larger region of pixel space) so that the network first creates representations of small parts of the input, then from them assembles representations of larger areas.\nShared weights: In CNNs, each filter is replicated across the entire visual field. These replicated units share the same parameterization (weight vector and bias) and form a feature map. This means that all the neurons in a given convolutional layer respond to the same feature within their specific response field. Replicating units in this way allows for the resulting activation map to be equivariant under shifts of the locations of input features in the visual field, i.e. they grant translational equivariance\u2014given that the layer has a stride of one.\nPooling: In a CNN's pooling layers, feature maps are divided into rectangular sub-regions, and the features in each rectangle are independently down-sampled to a single value, commonly by taking their average or maximum value. In addition to reducing the sizes of feature maps, the pooling operation grants a degree of local translational invariance to the features contained therein, allowing the CNN to be more robust to variations in their positions.\nTogether, these properties allow CNNs to achieve better generalization on vision problems. Weight sharing dramatically reduces the number of free parameters learned, thus lowering the memory requirements for running the network and allowing the training of larger, more powerful networks.\n\n\n== Building blocks ==\nA CNN architecture is formed by a stack of distinct layers that transform the input volume into an output volume (e.g. holding the class scores) through a differentiable function. A few distinct types of layers are commonly used. These are further discussed below.\n\n\n=== Convolutional layer ===\n\nThe convolutional layer is the core building block of a CNN. The layer's parameters consist of a set of learnable filters (or kernels), which have a small receptive field, but extend through the full depth of the input volume. During the forward pass, each filter is convolved across the width and height of the input volume, computing the dot product between the filter entries and the input, producing a 2-dimensional activation map of that filter. As a result, the network learns filters that activate when it detects some specific type of feature at some spatial position in the input.\nStacking the activation maps for all filters along the depth dimension forms the full output volume of the convolution layer. Every entry in the output volume can thus also be interpreted as an output of a neuron that looks at a small region in the input. Each entry in an activation map use the same set of parameters that define the filter.\nSelf-supervised learning has been adapted for use in convolutional layers by using sparse patches with a high-mask ratio and a global response normalization layer.", "mimetype": "text/plain", "start_char_idx": 20448, "end_char_idx": 25601, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "46f103c5-2e21-4651-a84a-0b458a4079ba": {"__data__": {"id_": "46f103c5-2e21-4651-a84a-0b458a4079ba", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0f03deee-09fb-4d92-b6a6-678a329bb62d", "node_type": "1", "metadata": {}, "hash": "d669ab12718c1502c2854ed11cc11c14f95f65bf81edfce7bd40333927f7f4f4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8774cd75-2e0e-42df-b4d4-79367dc8e15d", "node_type": "1", "metadata": {}, "hash": "caa1afbf2cacc6b06ab77bf006b420a4edd36df99d7ef35f3a3512cb05ba4052", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Local connectivity ====\n\nWhen dealing with high-dimensional inputs such as images, it is impractical to connect neurons to all neurons in the previous volume because such a network architecture does not take the spatial structure of the data into account. Convolutional networks exploit spatially local correlation by enforcing a sparse local connectivity pattern between neurons of adjacent layers: each neuron is connected to only a small region of the input volume.\nThe extent of this connectivity is a hyperparameter called the receptive field of the neuron. The connections are local in space (along width and height), but always extend along the entire depth of the input volume. Such an architecture ensures that the learned filters produce the strongest response to a spatially local input pattern.\n\n\n==== Spatial arrangement ====\nThree hyperparameters control the size of the output volume of the convolutional layer: the depth, stride, and padding size:\n\nThe depth of the output volume controls the number of neurons in a layer that connect to the same region of the input volume. These neurons learn to activate for different features in the input. For example, if the first convolutional layer takes the raw image as input, then different neurons along the depth dimension may activate in the presence of various oriented edges, or blobs of color.\nStride controls how depth columns around the width and height are allocated. If the stride is 1, then we move the filters one pixel at a time. This leads to heavily overlapping receptive fields between the columns, and to large output volumes. For any integer \n  \n    \n      \n        S\n        >\n        0\n        ,\n      \n    \n    {\\textstyle S>0,}\n  \n a stride S means that the filter is translated S units at a time per output. In practice, \n  \n    \n      \n        S\n        \u2265\n        3\n      \n    \n    {\\textstyle S\\geq 3}\n  \n is rare. A greater stride means smaller overlap of receptive fields and smaller spatial dimensions of the output volume.\nSometimes, it is convenient to pad the input with zeros (or other values, such as the average of the region) on the border of the input volume. The size of this padding is a third hyperparameter. Padding provides control of the output volume's spatial size. In particular, sometimes it is desirable to exactly preserve the spatial size of the input volume, this is commonly referred to as \"same\" padding.\n\nThe spatial size of the output volume is a function of the input volume size \n  \n    \n      \n        W\n      \n    \n    {\\displaystyle W}\n  \n, the kernel field size \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n of the convolutional layer neurons, the stride \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n, and the amount of zero padding \n  \n    \n      \n        P\n      \n    \n    {\\displaystyle P}\n  \n on the border. The number of neurons that \"fit\" in a given volume is then:\n\n  \n    \n      \n        \n          \n            \n              W\n              \u2212\n              K\n              +\n              2\n              P\n            \n            S\n          \n        \n        +\n        1.\n      \n    \n    {\\displaystyle {\\frac {W-K+2P}{S}}+1.}\n  \n\nIf this number is not an integer, then the strides are incorrect and the neurons cannot be tiled to fit across the input volume in a symmetric way. In general, setting zero padding to be \n  \n    \n      \n        P\n        =\n        (\n        K\n        \u2212\n        1\n        )\n        \n          /\n        \n        2\n      \n    \n    {\\textstyle P=(K-1)/2}\n  \n when the stride is \n  \n    \n      \n        S\n        =\n        1\n      \n    \n    {\\displaystyle S=1}\n  \n ensures that the input volume and output volume will have the same size spatially. However, it is not always completely necessary to use all of the neurons of the previous layer. For example, a neural network designer may decide to use just a portion of padding.", "mimetype": "text/plain", "start_char_idx": 25604, "end_char_idx": 29532, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8774cd75-2e0e-42df-b4d4-79367dc8e15d": {"__data__": {"id_": "8774cd75-2e0e-42df-b4d4-79367dc8e15d", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "46f103c5-2e21-4651-a84a-0b458a4079ba", "node_type": "1", "metadata": {}, "hash": "702551c10d7f7170d374907a743e0776b4cac616b46e25a4ecdbd88ed8f4d3b0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "af625bcb-0af1-4f09-bfb0-b77e8b49f68b", "node_type": "1", "metadata": {}, "hash": "d90c2cbdf4d09b492ee2ea267befbd3b36de85f40b3864c323fbca0c255ecfaf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Parameter sharing ====\nA parameter sharing scheme is used in convolutional layers to control the number of free parameters. It relies on the assumption that if a patch feature is useful to compute at some spatial position, then it should also be useful to compute at other positions. Denoting a single 2-dimensional slice of depth as a depth slice, the neurons in each depth slice are constrained to use the same weights and bias.\nSince all neurons in a single depth slice share the same parameters, the forward pass in each depth slice of the convolutional layer can be computed as a convolution of the neuron's weights with the input volume. Therefore, it is common to refer to the sets of weights as a filter (or a kernel), which is convolved with the input. The result of this convolution is an activation map, and the set of activation maps for each different filter are stacked together along the depth dimension to produce the output volume. Parameter sharing contributes to the translation invariance of the CNN architecture.\nSometimes, the parameter sharing assumption may not make sense. This is especially the case when the input images to a CNN have some specific centered structure; for which we expect completely different features to be learned on different spatial locations. One practical example is when the inputs are faces that have been centered in the image: we might expect different eye-specific or hair-specific features to be learned in different parts of the image. In that case it is common to relax the parameter sharing scheme, and instead simply call the layer a \"locally connected layer\".\n\n\n=== Pooling layer ===\n\nAnother important concept of CNNs is pooling, which is used as a form of non-linear down-sampling. Pooling provides downsampling because it reduces the spatial dimensions (height and width) of the input feature maps while retaining the most important information. There are several non-linear functions to implement pooling, where max pooling and average pooling are the most common. Pooling aggregates information from small regions of the input creating partitions of the input feature map, typically using a fixed-size window (like 2x2) and applying a stride (often 2) to move the window across the input. Note that without using a stride greater than 1, pooling would not perform downsampling, as it would simply move the pooling window across the input one step at a time, without reducing the size of the feature map. In other words, the stride is what actually causes the downsampling by determining how much the pooling window moves over the input.\nIntuitively, the exact location of a feature is less important than its rough location relative to other features. This is the idea behind the use of pooling in convolutional neural networks. The pooling layer serves to progressively reduce the spatial size of the representation, to reduce the number of parameters, memory footprint and amount of computation in the network, and hence to also control overfitting. This is known as down-sampling. It is common to periodically insert a pooling layer between successive convolutional layers (each one typically followed by an activation function, such as a ReLU layer) in a CNN architecture.:\u200a460\u2013461\u200a While pooling layers contribute to local translation invariance, they do not provide global translation invariance in a CNN, unless a form of global pooling is used. The pooling layer commonly operates independently on every depth, or slice, of the input and resizes it spatially. A very common form of max pooling is a layer with filters of size 2\u00d72, applied with a stride of 2, which subsamples every depth slice in the input by 2 along both width and height, discarding 75% of the activations:\n  \n    \n      \n        \n          f\n          \n            X\n            ,\n            Y\n          \n        \n        (\n        S\n        )\n        =\n        \n          max\n          \n            a\n            ,\n            b\n            =\n            0\n          \n          \n            1\n          \n        \n        \n          S\n          \n            2\n            X\n            +\n            a\n            ,\n            2\n            Y\n            +\n            b\n          \n        \n        .\n      \n    \n    {\\displaystyle f_{X,Y}(S)=\\max _{a,b=0}^{1}S_{2X+a,2Y+b}.}\n  \n\nIn this case, every max operation is over 4 numbers. The depth dimension remains unchanged (this is true for other forms of pooling as well).\nIn addition to max pooling, pooling units can use other functions, such as average pooling or \u21132-norm pooling. Average pooling was often used historically but has recently fallen out of favor compared to max pooling, which generally performs better in practice.\nDue to the effects of fast spatial reduction of the size of the representation, there is a recent trend towards using smaller filters or discarding pooling layers altogether.", "mimetype": "text/plain", "start_char_idx": 29535, "end_char_idx": 34444, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "af625bcb-0af1-4f09-bfb0-b77e8b49f68b": {"__data__": {"id_": "af625bcb-0af1-4f09-bfb0-b77e8b49f68b", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8774cd75-2e0e-42df-b4d4-79367dc8e15d", "node_type": "1", "metadata": {}, "hash": "caa1afbf2cacc6b06ab77bf006b420a4edd36df99d7ef35f3a3512cb05ba4052", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9de57a1a-7b2c-4662-9cdb-5e91ce43397d", "node_type": "1", "metadata": {}, "hash": "252de977c7e4754b3005c9a4608b805345e90dc118908f8e879ee2798f2693e2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Channel max pooling ====\nA channel max pooling (CMP) operation layer conducts the MP operation along the channel side among the corresponding positions of the consecutive feature maps for the purpose of redundant information elimination. The CMP makes the significant features gather together within fewer channels, which is important for fine-grained image classification that needs more discriminating features. Meanwhile, another advantage of the CMP operation is to make the channel number of feature maps smaller before it connects to the first fully connected (FC) layer. Similar to the MP operation, we denote the input feature maps and output feature maps of a CMP layer as F \u2208 R(C\u00d7M\u00d7N) and C \u2208 R(c\u00d7M\u00d7N), respectively, where C and c are the channel numbers of the input and output feature maps, M and N are the widths and the height of the feature maps, respectively. Note that the CMP operation only changes the channel number of the feature maps. The width and the height of the feature maps are not changed, which is different from the MP operation.\nSee  for reviews for pooling methods.\n\n\n=== ReLU layer ===\nReLU is the abbreviation of rectified linear unit. It was proposed by Alston Householder in 1941, and used in CNN by Kunihiko Fukushima in 1969. ReLU applies the non-saturating activation function \n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        max\n        (\n        0\n        ,\n        x\n        )\n      \n    \n    {\\textstyle f(x)=\\max(0,x)}\n  \n. It effectively removes negative values from an activation map by setting them to zero. It introduces nonlinearity to the decision function and in the overall network without affecting the receptive fields of the convolution layers.\nIn 2011, Xavier Glorot, Antoine Bordes and Yoshua Bengio found that ReLU enables better training of deeper networks, compared to widely used activation functions prior to 2011.\nOther functions can also be used to increase nonlinearity, for example the saturating hyperbolic tangent \n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        tanh\n        \u2061\n        (\n        x\n        )\n      \n    \n    {\\displaystyle f(x)=\\tanh(x)}\n  \n, \n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        \n          |\n        \n        tanh\n        \u2061\n        (\n        x\n        )\n        \n          |\n        \n      \n    \n    {\\displaystyle f(x)=|\\tanh(x)|}\n  \n, and the sigmoid function \n  \n    \n      \n        \u03c3\n        (\n        x\n        )\n        =\n        (\n        1\n        +\n        \n          e\n          \n            \u2212\n            x\n          \n        \n        \n          )\n          \n            \u2212\n            1\n          \n        \n      \n    \n    {\\textstyle \\sigma (x)=(1+e^{-x})^{-1}}\n  \n. ReLU is often preferred to other functions because it trains the neural network several times faster without a significant penalty to generalization accuracy.\n\n\n=== Fully connected layer ===\nAfter several convolutional and max pooling layers, the final classification is done via fully connected layers. Neurons in a fully connected layer have connections to all activations in the previous layer, as seen in regular (non-convolutional) artificial neural networks. Their activations can thus be computed as an affine transformation, with matrix multiplication followed by a bias offset (vector addition of a learned or fixed bias term).\n\n\n=== Loss layer ===\n\nThe \"loss layer\", or \"loss function\", exemplifies how training penalizes the deviation between the predicted output of the network, and the true data labels (during supervised learning). Various loss functions can be used, depending on the specific task.\nThe Softmax loss function is used for predicting a single class of K mutually exclusive classes. Sigmoid cross-entropy loss is used for predicting K independent probability values in \n  \n    \n      \n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle [0,1]}\n  \n. Euclidean loss is used for regressing to real-valued labels \n  \n    \n      \n        (\n        \u2212\n        \u221e\n        ,\n        \u221e\n        )\n      \n    \n    {\\displaystyle (-\\infty ,\\infty )}\n  \n.\n\n\n== Hyperparameters ==\n\nHyperparameters are various settings that are used to control the learning process. CNNs use more hyperparameters than a standard multilayer perceptron (MLP).\n\n\n=== Padding ===\nPadding is the addition of (typically) 0-valued pixels on the borders of an image. This is done so that the border pixels are not undervalued (lost) from the output because they would ordinarily participate in only a single receptive field instance. The padding applied is typically one less than the corresponding kernel dimension. For example, a convolutional layer using 3x3 kernels would receive a 2-pixel pad, that is 1 pixel on each side of the image.", "mimetype": "text/plain", "start_char_idx": 34447, "end_char_idx": 39261, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9de57a1a-7b2c-4662-9cdb-5e91ce43397d": {"__data__": {"id_": "9de57a1a-7b2c-4662-9cdb-5e91ce43397d", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "af625bcb-0af1-4f09-bfb0-b77e8b49f68b", "node_type": "1", "metadata": {}, "hash": "d90c2cbdf4d09b492ee2ea267befbd3b36de85f40b3864c323fbca0c255ecfaf", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c74943a4-e7f6-4e6b-b251-f93e0db189e9", "node_type": "1", "metadata": {}, "hash": "aaad958f2a02f0aa6beb7bced4a98b5ef621274e5424304d2c7647d42313945c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Hyperparameters ==\n\nHyperparameters are various settings that are used to control the learning process. CNNs use more hyperparameters than a standard multilayer perceptron (MLP).\n\n\n=== Padding ===\nPadding is the addition of (typically) 0-valued pixels on the borders of an image. This is done so that the border pixels are not undervalued (lost) from the output because they would ordinarily participate in only a single receptive field instance. The padding applied is typically one less than the corresponding kernel dimension. For example, a convolutional layer using 3x3 kernels would receive a 2-pixel pad, that is 1 pixel on each side of the image.\n\n\n=== Stride ===\nThe stride is the number of pixels that the analysis window moves on each iteration. A stride of 2 means that each kernel is offset by 2 pixels from its predecessor.\n\n\n=== Number of filters ===\nSince feature map size decreases with depth, layers near the input layer tend to have fewer filters while higher layers can have more. To equalize computation at each layer, the product of feature values va with pixel position is kept roughly constant across layers. Preserving more information about the input would require keeping the total number of activations (number of feature maps times number of pixel positions) non-decreasing from one layer to the next.\nThe number of feature maps directly controls the capacity and depends on the number of available examples and task complexity.\n\n\n=== Filter (or Kernel) size ===\nCommon filter sizes found in the literature vary greatly, and are usually chosen based on the data set. Typical filter sizes range from 1x1 to 7x7. As two famous examples, AlexNet used 3x3, 5x5, and 11x11. Inceptionv3 used 1x1, 3x3, and 5x5.\nThe challenge is to find the right level of granularity so as to create abstractions at the proper scale, given a particular data set, and without overfitting.\n\n\n=== Pooling type and size ===\nMax pooling is typically used, often with a 2x2 dimension. This implies that the input is drastically downsampled, reducing processing cost.\nGreater pooling reduces the dimension of the signal, and may result in unacceptable information loss. Often, non-overlapping pooling windows perform best.\n\n\n=== Dilation ===\nDilation involves ignoring pixels within a kernel. This reduces processing memory potentially without significant signal loss. A dilation of 2 on a 3x3 kernel expands the kernel to 5x5, while still processing 9 (evenly spaced) pixels. Specifically, the processed pixels after the dilation are the cells (1,1), (1,3), (1,5), (3,1), (3,3), (3,5), (5,1), (5,3), (5,5), where (i,j) denotes the cell of the i-th row and j-th column in the expanded 5x5 kernel. Accordingly, dilation of 4 expands the kernel to 7x7.\n\n\n== Translation equivariance and aliasing ==\nIt is commonly assumed that CNNs are invariant to shifts of the input. Convolution or pooling layers within a CNN that do not have a stride greater than one are indeed equivariant to translations of the input. However, layers with a stride greater than one ignore the Nyquist\u2013Shannon sampling theorem and might lead to aliasing of the input signal While, in principle, CNNs are capable of implementing anti-aliasing filters, it has been observed that this does not happen in practice, and therefore yield models that are not equivariant to translations.\nFurthermore, if a CNN makes use of fully connected layers, translation equivariance does not imply translation invariance, as the fully connected layers are not invariant to shifts of the input. One solution for complete translation invariance is avoiding any down-sampling throughout the network and applying global average pooling at the last layer. Additionally, several other partial solutions have been proposed, such as anti-aliasing before downsampling operations, spatial transformer networks, data augmentation, subsampling combined with pooling, and capsule neural networks.\n\n\n== Evaluation ==\nThe accuracy of the final model is typically estimated on a sub-part of the dataset set apart at the start, often called a test set. Alternatively, methods such as k-fold cross-validation are applied. Other strategies include using conformal prediction.\n\n\n== Regularization methods ==\n\nRegularization is a process of introducing additional information to solve an ill-posed problem or to prevent overfitting. CNNs use various types of regularization.\n\n\n=== Empirical ===", "mimetype": "text/plain", "start_char_idx": 38604, "end_char_idx": 43031, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c74943a4-e7f6-4e6b-b251-f93e0db189e9": {"__data__": {"id_": "c74943a4-e7f6-4e6b-b251-f93e0db189e9", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9de57a1a-7b2c-4662-9cdb-5e91ce43397d", "node_type": "1", "metadata": {}, "hash": "252de977c7e4754b3005c9a4608b805345e90dc118908f8e879ee2798f2693e2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7bdf5309-49ff-43e7-991c-33c2a0b8f862", "node_type": "1", "metadata": {}, "hash": "f914196a2f4d0f4742ac2d2ddd83556efd8581746726cf79c286bd968cd8fb19", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Evaluation ==\nThe accuracy of the final model is typically estimated on a sub-part of the dataset set apart at the start, often called a test set. Alternatively, methods such as k-fold cross-validation are applied. Other strategies include using conformal prediction.\n\n\n== Regularization methods ==\n\nRegularization is a process of introducing additional information to solve an ill-posed problem or to prevent overfitting. CNNs use various types of regularization.\n\n\n=== Empirical ===\n\n\n==== Dropout ====\nBecause networks have so many parameters, they are prone to overfitting. One method to reduce overfitting is dropout, introduced in 2014. At each training stage, individual nodes are either \"dropped out\" of the net (ignored) with probability \n  \n    \n      \n        1\n        \u2212\n        p\n      \n    \n    {\\displaystyle 1-p}\n  \n or kept with probability \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n, so that a reduced network is left; incoming and outgoing edges to a dropped-out node are also removed. Only the reduced network is trained on the data in that stage. The removed nodes are then reinserted into the network with their original weights.\nIn the training stages, \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n is usually 0.5; for input nodes, it is typically much higher because information is directly lost when input nodes are ignored.\nAt testing time after training has finished, we would ideally like to find a sample average of all possible \n  \n    \n      \n        \n          2\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle 2^{n}}\n  \n dropped-out networks; unfortunately this is unfeasible for large values of \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n. However, we can find an approximation by using the full network with each node's output weighted by a factor of \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n, so the expected value of the output of any node is the same as in the training stages. This is the biggest contribution of the dropout method: although it effectively generates \n  \n    \n      \n        \n          2\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle 2^{n}}\n  \n neural nets, and as such allows for model combination, at test time only a single network needs to be tested.\nBy avoiding training all nodes on all training data, dropout decreases overfitting. The method also significantly improves training speed. This makes the model combination practical, even for deep neural networks. The technique seems to reduce node interactions, leading them to learn more robust features that better generalize to new data.\n\n\n==== DropConnect ====\nDropConnect is the generalization of dropout in which each connection, rather than each output unit, can be dropped with probability \n  \n    \n      \n        1\n        \u2212\n        p\n      \n    \n    {\\displaystyle 1-p}\n  \n. Each unit thus receives input from a random subset of units in the previous layer.\nDropConnect is similar to dropout as it introduces dynamic sparsity within the model, but differs in that the sparsity is on the weights, rather than the output vectors of a layer. In other words, the fully connected layer with DropConnect becomes a sparsely connected layer in which the connections are chosen at random during the training stage.\n\n\n==== Stochastic pooling ====\nA major drawback to dropout is that it does not have the same benefits for convolutional layers, where the neurons are not fully connected.\nEven before dropout, in 2013 a technique called stochastic pooling, the conventional deterministic pooling operations were replaced with a stochastic procedure, where the activation within each pooling region is picked randomly according to a multinomial distribution, given by the activities within the pooling region. This approach is free of hyperparameters and can be combined with other regularization approaches, such as dropout and data augmentation.\nAn alternate view of stochastic pooling is that it is equivalent to standard max pooling but with many copies of an input image, each having small local deformations. This is similar to explicit elastic deformations of the input images, which delivers excellent performance on the MNIST data set. Using stochastic pooling in a multilayer model gives an exponential number of deformations since the selections in higher layers are independent of those below.\n\n\n==== Artificial data ====\n\nBecause the degree of model overfitting is determined by both its power and the amount of training it receives, providing a convolutional network with more training examples can reduce overfitting. Because there is often not enough available data to train, especially considering that some part should be spared for later testing, two approaches are to either generate new data from scratch (if possible) or perturb existing data to create new ones. The latter one is used since mid-1990s. For example, input images can be cropped, rotated, or rescaled to create new examples with the same labels as the original training set.\n\n\n=== Explicit ===", "mimetype": "text/plain", "start_char_idx": 42544, "end_char_idx": 47674, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7bdf5309-49ff-43e7-991c-33c2a0b8f862": {"__data__": {"id_": "7bdf5309-49ff-43e7-991c-33c2a0b8f862", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c74943a4-e7f6-4e6b-b251-f93e0db189e9", "node_type": "1", "metadata": {}, "hash": "aaad958f2a02f0aa6beb7bced4a98b5ef621274e5424304d2c7647d42313945c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "78698999-8539-4538-be6f-8bb7f9daa430", "node_type": "1", "metadata": {}, "hash": "703a30f66fb0b7dd4496e96fa97e0b800bd3ea1454d47c3e5508816479c50854", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Artificial data ====\n\nBecause the degree of model overfitting is determined by both its power and the amount of training it receives, providing a convolutional network with more training examples can reduce overfitting. Because there is often not enough available data to train, especially considering that some part should be spared for later testing, two approaches are to either generate new data from scratch (if possible) or perturb existing data to create new ones. The latter one is used since mid-1990s. For example, input images can be cropped, rotated, or rescaled to create new examples with the same labels as the original training set.\n\n\n=== Explicit ===\n\n\n==== Early stopping ====\n\nOne of the simplest methods to prevent overfitting of a network is to simply stop the training before overfitting has had a chance to occur. It comes with the disadvantage that the learning process is halted.\n\n\n==== Number of parameters ====\nAnother simple way to prevent overfitting is to limit the number of parameters, typically by limiting the number of hidden units in each layer or limiting network depth. For convolutional networks, the filter size also affects the number of parameters. Limiting the number of parameters restricts the predictive power of the network directly, reducing the complexity of the function that it can perform on the data, and thus limits the amount of overfitting. This is equivalent to a \"zero norm\".\n\n\n==== Weight decay ====\nA simple form of added regularizer is weight decay, which simply adds an additional error, proportional to the sum of weights (L1 norm) or squared magnitude (L2 norm) of the weight vector, to the error at each node. The level of acceptable model complexity can be reduced by increasing the proportionality constant('alpha' hyperparameter), thus increasing the penalty for large weight vectors.\nL2 regularization is the most common form of regularization. It can be implemented by penalizing the squared magnitude of all parameters directly in the objective. The L2 regularization has the intuitive interpretation of heavily penalizing peaky weight vectors and preferring diffuse weight vectors. Due to multiplicative interactions between weights and inputs this has the useful property of encouraging the network to use all of its inputs a little rather than some of its inputs a lot.\nL1 regularization is also common. It makes the weight vectors sparse during optimization. In other words, neurons with L1 regularization end up using only a sparse subset of their most important inputs and become nearly invariant to the noisy inputs. L1 with L2 regularization can be combined; this is called elastic net regularization.\n\n\n==== Max norm constraints ====\nAnother form of regularization is to enforce an absolute upper bound on the magnitude of the weight vector for every neuron and use projected gradient descent to enforce the constraint. In practice, this corresponds to performing the parameter update as normal, and then enforcing the constraint by clamping the weight vector \n  \n    \n      \n        \n          \n            \n              w\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {w}}}\n  \n of every neuron to satisfy \n  \n    \n      \n        \u2016\n        \n          \n            \n              w\n              \u2192\n            \n          \n        \n        \n          \u2016\n          \n            2\n          \n        \n        <\n        c\n      \n    \n    {\\displaystyle \\|{\\vec {w}}\\|_{2}<c}\n  \n. Typical values of \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  \n are order of 3\u20134. Some papers report improvements when using this form of regularization.", "mimetype": "text/plain", "start_char_idx": 47002, "end_char_idx": 50674, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "78698999-8539-4538-be6f-8bb7f9daa430": {"__data__": {"id_": "78698999-8539-4538-be6f-8bb7f9daa430", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7bdf5309-49ff-43e7-991c-33c2a0b8f862", "node_type": "1", "metadata": {}, "hash": "f914196a2f4d0f4742ac2d2ddd83556efd8581746726cf79c286bd968cd8fb19", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4849d0ff-f29c-4600-8258-c409d146c621", "node_type": "1", "metadata": {}, "hash": "b163152590e9ffbcb338e2d964e03e99ff4c9fddb445dfaf4b7c100ea6f0af1f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Max norm constraints ====\nAnother form of regularization is to enforce an absolute upper bound on the magnitude of the weight vector for every neuron and use projected gradient descent to enforce the constraint. In practice, this corresponds to performing the parameter update as normal, and then enforcing the constraint by clamping the weight vector \n  \n    \n      \n        \n          \n            \n              w\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {w}}}\n  \n of every neuron to satisfy \n  \n    \n      \n        \u2016\n        \n          \n            \n              w\n              \u2192\n            \n          \n        \n        \n          \u2016\n          \n            2\n          \n        \n        <\n        c\n      \n    \n    {\\displaystyle \\|{\\vec {w}}\\|_{2}<c}\n  \n. Typical values of \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  \n are order of 3\u20134. Some papers report improvements when using this form of regularization.\n\n\n== Hierarchical coordinate frames ==\nPooling loses the precise spatial relationships between high-level parts (such as nose and mouth in a face image). These relationships are needed for identity recognition. Overlapping the pools so that each feature occurs in multiple pools, helps retain the information. Translation alone cannot extrapolate the understanding of geometric relationships to a radically new viewpoint, such as a different orientation or scale. On the other hand, people are very good at extrapolating; after seeing a new shape once they can recognize it from a different viewpoint.\nAn earlier common way to deal with this problem is to train the network on transformed data in different orientations, scales, lighting, etc. so that the network can cope with these variations. This is computationally intensive for large data-sets. The alternative is to use a hierarchy of coordinate frames and use a group of neurons to represent a conjunction of the shape of the feature and its pose relative to the retina. The pose relative to the retina is the relationship between the coordinate frame of the retina and the intrinsic features' coordinate frame.\nThus, one way to represent something is to embed the coordinate frame within it. This allows large features to be recognized by using the consistency of the poses of their parts (e.g. nose and mouth poses make a consistent prediction of the pose of the whole face). This approach ensures that the higher-level entity (e.g. face) is present when the lower-level (e.g. nose and mouth) agree on its prediction of the pose. The vectors of neuronal activity that represent pose (\"pose vectors\") allow spatial transformations modeled as linear operations that make it easier for the network to learn the hierarchy of visual entities and generalize across viewpoints. This is similar to the way the human visual system imposes coordinate frames in order to represent shapes.\n\n\n== Applications ==", "mimetype": "text/plain", "start_char_idx": 49690, "end_char_idx": 52633, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4849d0ff-f29c-4600-8258-c409d146c621": {"__data__": {"id_": "4849d0ff-f29c-4600-8258-c409d146c621", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "78698999-8539-4538-be6f-8bb7f9daa430", "node_type": "1", "metadata": {}, "hash": "703a30f66fb0b7dd4496e96fa97e0b800bd3ea1454d47c3e5508816479c50854", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c765a06d-ca46-4e77-b968-4483510cfde3", "node_type": "1", "metadata": {}, "hash": "0cfa6b15c6a0b00307622d53db5d7d8dc3caca30abfd65393dbc14d76215e434", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Applications ==\n\n\n=== Image recognition ===\nCNNs are often used in image recognition systems. In 2012, an error rate of 0.23% on the MNIST database was reported. Another paper on using CNN for image classification reported that the learning process was \"surprisingly fast\"; in the same paper, the best published results as of 2011 were achieved in the MNIST database and the NORB database. Subsequently, a similar CNN called AlexNet won the ImageNet Large Scale Visual Recognition Challenge 2012.\nWhen applied to facial recognition, CNNs achieved a large decrease in error rate. Another paper reported a 97.6% recognition rate on \"5,600 still images of more than 10 subjects\". CNNs were used to assess video quality in an objective way after manual training; the resulting system had a very low root mean square error.\nThe ImageNet Large Scale Visual Recognition Challenge is a benchmark in object classification and detection, with millions of images and hundreds of object classes. In the ILSVRC 2014, a large-scale visual recognition challenge, almost every highly ranked team used CNN as their basic framework. The winner GoogLeNet (the foundation of DeepDream) increased the mean average precision of object detection to 0.439329, and reduced classification error to 0.06656, the best result to date. Its network applied more than 30 layers. That performance of convolutional neural networks on the ImageNet tests was close to that of humans. The best algorithms still struggle with objects that are small or thin, such as a small ant on a stem of a flower or a person holding a quill in their hand. They also have trouble with images that have been distorted with filters, an increasingly common phenomenon with modern digital cameras. By contrast, those kinds of images rarely trouble humans. Humans, however, tend to have trouble with other issues. For example, they are not good at classifying objects into fine-grained categories such as the particular breed of dog or species of bird, whereas convolutional neural networks handle this.\nIn 2015, a many-layered CNN demonstrated the ability to spot faces from a wide range of angles, including upside down, even when partially occluded, with competitive performance. The network was trained on a database of 200,000 images that included faces at various angles and orientations and a further 20 million images without faces. They used batches of 128 images over 50,000 iterations.\n\n\n=== Video analysis ===\nCompared to image data domains, there is relatively little work on applying CNNs to video classification. Video is more complex than images since it has another (temporal) dimension. However, some extensions of CNNs into the video domain have been explored. One approach is to treat space and time as equivalent dimensions of the input and perform convolutions in both time and space. Another way is to fuse the features of two convolutional neural networks, one for the spatial and one for the temporal stream. Long short-term memory (LSTM) recurrent units are typically incorporated after the CNN to account for inter-frame or inter-clip dependencies. Unsupervised learning schemes for training spatio-temporal features have been introduced, based on Convolutional Gated Restricted Boltzmann Machines and Independent Subspace Analysis. Its application can be seen in text-to-video model.\n\n\n=== Natural language processing ===\nCNNs have also been explored for natural language processing. CNN models are effective for various NLP problems and achieved excellent results in semantic parsing, search query retrieval, sentence modeling, classification, prediction and other traditional NLP tasks.\nCompared to traditional language processing methods such as recurrent neural networks, CNNs can represent different contextual realities of language that do not rely on a series-sequence assumption, while RNNs are better suitable when classical time series modeling is required.\n\n\n=== Anomaly detection ===\nA CNN with 1-D convolutions was used on time series in the frequency domain (spectral residual) by an unsupervised model to detect anomalies in the time domain.\n\n\n=== Drug discovery ===\nCNNs have been used in drug discovery. Predicting the interaction between molecules and biological proteins can identify potential treatments. In 2015, Atomwise introduced AtomNet, the first deep learning neural network for structure-based drug design. The system trains directly on 3-dimensional representations of chemical interactions. Similar to how image recognition networks learn to compose smaller, spatially proximate features into larger, complex structures, AtomNet discovers chemical features, such as aromaticity, sp3 carbons, and hydrogen bonding. Subsequently, AtomNet was used to predict novel candidate biomolecules for multiple disease targets, most notably treatments for the Ebola virus and multiple sclerosis.", "mimetype": "text/plain", "start_char_idx": 52615, "end_char_idx": 57501, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c765a06d-ca46-4e77-b968-4483510cfde3": {"__data__": {"id_": "c765a06d-ca46-4e77-b968-4483510cfde3", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4849d0ff-f29c-4600-8258-c409d146c621", "node_type": "1", "metadata": {}, "hash": "b163152590e9ffbcb338e2d964e03e99ff4c9fddb445dfaf4b7c100ea6f0af1f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e6a296fc-77b4-427b-b8c3-8e0f34b82846", "node_type": "1", "metadata": {}, "hash": "52c992e9cb923aaf5cee0aca8819eed9c8a036ffacd4aecc5ead7dd923f53bf3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Anomaly detection ===\nA CNN with 1-D convolutions was used on time series in the frequency domain (spectral residual) by an unsupervised model to detect anomalies in the time domain.\n\n\n=== Drug discovery ===\nCNNs have been used in drug discovery. Predicting the interaction between molecules and biological proteins can identify potential treatments. In 2015, Atomwise introduced AtomNet, the first deep learning neural network for structure-based drug design. The system trains directly on 3-dimensional representations of chemical interactions. Similar to how image recognition networks learn to compose smaller, spatially proximate features into larger, complex structures, AtomNet discovers chemical features, such as aromaticity, sp3 carbons, and hydrogen bonding. Subsequently, AtomNet was used to predict novel candidate biomolecules for multiple disease targets, most notably treatments for the Ebola virus and multiple sclerosis.\n\n\n=== Checkers game ===\nCNNs have been used in the game of checkers. From 1999 to 2001, Fogel and Chellapilla published papers showing how a convolutional neural network could learn to play checkers using co-evolution. The learning process did not use prior human professional games, but rather focused on a minimal set of information contained in the checkerboard: the location and type of pieces, and the difference in number of pieces between the two sides. Ultimately, the program (Blondie24) was tested on 165 games against players and ranked in the highest 0.4%. It also earned a win against the program Chinook at its \"expert\" level of play.\n\n\n=== Go ===\nCNNs have been used in computer Go. In December 2014, Clark and Storkey published a paper showing that a CNN trained by supervised learning from a database of human professional games could outperform GNU Go and win some games against Monte Carlo tree search Fuego 1.1 in a fraction of the time it took Fuego to play. Later it was announced that a large 12-layer convolutional neural network had correctly predicted the professional move in 55% of positions, equalling the accuracy of a 6 dan human player. When the trained convolutional network was used directly to play games of Go, without any search, it beat the traditional search program GNU Go in 97% of games, and matched the performance of the Monte Carlo tree search program Fuego simulating ten thousand playouts (about a million positions) per move.\nA couple of CNNs for choosing moves to try (\"policy network\") and evaluating positions (\"value network\") driving MCTS were used by AlphaGo, the first to beat the best human player at the time.\n\n\n=== Time series forecasting ===\nRecurrent neural networks are generally considered the best neural network architectures for time series forecasting (and sequence modeling in general), but recent studies show that convolutional networks can perform comparably or even better. Dilated convolutions might enable one-dimensional convolutional neural networks to effectively learn time series dependences. Convolutions can be implemented more efficiently than RNN-based solutions, and they do not suffer from vanishing (or exploding) gradients. Convolutional networks can provide an improved forecasting performance when there are multiple similar time series to learn from. CNNs can also be applied to further tasks in time series analysis (e.g., time series classification or quantile forecasting).\n\n\n=== Cultural heritage and 3D-datasets ===\nAs archaeological findings such as clay tablets with cuneiform writing are increasingly acquired using 3D scanners, benchmark datasets are becoming available, including HeiCuBeDa providing almost 2000 normalized 2-D and 3-D datasets prepared with the GigaMesh Software Framework. So curvature-based measures are used in conjunction with geometric neural networks (GNNs), e.g. for period classification of those clay tablets being among the oldest documents of human history.\n\n\n== Fine-tuning ==\nFor many applications, training data is not very available. Convolutional neural networks usually require a large amount of training data in order to avoid overfitting. A common technique is to train the network on a larger data set from a related domain. Once the network parameters have converged an additional training step is performed using the in-domain data to fine-tune the network weights, this is known as transfer learning. Furthermore, this technique allows convolutional network architectures to successfully be applied to problems with tiny training sets.\n\n\n== Human interpretable explanations ==\nEnd-to-end training and prediction are common practice in computer vision. However, human interpretable explanations are required for critical systems such as a self-driving cars. With recent advances in visual salience, spatial attention, and temporal attention, the most critical spatial regions/temporal instants could be visualized to justify the CNN predictions.\n\n\n== Related architectures ==", "mimetype": "text/plain", "start_char_idx": 56559, "end_char_idx": 61515, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e6a296fc-77b4-427b-b8c3-8e0f34b82846": {"__data__": {"id_": "e6a296fc-77b4-427b-b8c3-8e0f34b82846", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c765a06d-ca46-4e77-b968-4483510cfde3", "node_type": "1", "metadata": {}, "hash": "0cfa6b15c6a0b00307622d53db5d7d8dc3caca30abfd65393dbc14d76215e434", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Fine-tuning ==\nFor many applications, training data is not very available. Convolutional neural networks usually require a large amount of training data in order to avoid overfitting. A common technique is to train the network on a larger data set from a related domain. Once the network parameters have converged an additional training step is performed using the in-domain data to fine-tune the network weights, this is known as transfer learning. Furthermore, this technique allows convolutional network architectures to successfully be applied to problems with tiny training sets.\n\n\n== Human interpretable explanations ==\nEnd-to-end training and prediction are common practice in computer vision. However, human interpretable explanations are required for critical systems such as a self-driving cars. With recent advances in visual salience, spatial attention, and temporal attention, the most critical spatial regions/temporal instants could be visualized to justify the CNN predictions.\n\n\n== Related architectures ==\n\n\n=== Deep Q-networks ===\nA deep Q-network (DQN) is a type of deep learning model that combines a deep neural network with Q-learning, a form of reinforcement learning. Unlike earlier reinforcement learning agents, DQNs that utilize CNNs can learn directly from high-dimensional sensory inputs via reinforcement learning.\nPreliminary results were presented in 2014, with an accompanying paper in February 2015. The research described an application to Atari 2600 gaming. Other deep reinforcement learning models preceded it.\n\n\n=== Deep belief networks ===\n\nConvolutional deep belief networks (CDBN) have structure very similar to convolutional neural networks and are trained similarly to deep belief networks. Therefore, they exploit the 2D structure of images, like CNNs do, and make use of pre-training like deep belief networks. They provide a generic structure that can be used in many image and signal processing tasks. Benchmark results on standard image datasets like CIFAR have been obtained using CDBNs.\n\n\n=== Neural abstraction pyramid ===\nThe feed-forward architecture of convolutional neural networks was extended in the neural abstraction pyramid by lateral and feedback connections. The resulting recurrent convolutional network allows for the flexible incorporation of contextual information to iteratively resolve local ambiguities. In contrast to previous models, image-like outputs at the highest resolution were generated, e.g., for semantic segmentation, image reconstruction, and object localization tasks.\n\n\n== Notable libraries ==\nCaffe: A library for convolutional neural networks. Created by the Berkeley Vision and Learning Center (BVLC). It supports both CPU and GPU. Developed in C++, and has Python and MATLAB wrappers.\nDeeplearning4j: Deep learning in Java and Scala on multi-GPU-enabled Spark. A general-purpose deep learning library for the JVM production stack running on a C++ scientific computing engine. Allows the creation of custom layers. Integrates with Hadoop and Kafka.\nDlib: A toolkit for making real world machine learning and data analysis applications in C++.\nMicrosoft Cognitive Toolkit: A deep learning toolkit written by Microsoft with several unique features enhancing scalability over multiple nodes. It supports full-fledged interfaces for training in C++ and Python and with additional support for model inference in C# and Java.\nTensorFlow: Apache 2.0-licensed Theano-like library with support for CPU, GPU, Google's proprietary tensor processing unit (TPU), and mobile devices.\nTheano: The reference deep-learning library for Python with an API largely compatible with the popular NumPy library. Allows user to write symbolic mathematical expressions, then automatically generates their derivatives, saving the user from having to code gradients or backpropagation. These symbolic expressions are automatically compiled to CUDA code for a fast, on-the-GPU implementation.\nTorch: A scientific computing framework with wide support for machine learning algorithms, written in C and Lua.\n\n\n== See also ==\nAttention (machine learning)\nConvolution\nDeep learning\nNatural-language processing\nNeocognitron\nScale-invariant feature transform\nTime delay neural network\nVision processing unit\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\nCS231n: Convolutional Neural Networks for Visual Recognition \u2014 Andrej Karpathy's Stanford computer science course on CNNs in computer vision\nvdumoulin/conv_arithmetic: A technical report on convolution arithmetic in the context of deep learning. Animations of convolutions.", "mimetype": "text/plain", "start_char_idx": 60489, "end_char_idx": 65082, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f9a50d00-f27b-4bd6-bc7d-d95bc4de8338": {"__data__": {"id_": "f9a50d00-f27b-4bd6-bc7d-d95bc4de8338", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61603971", "node_type": "4", "metadata": {}, "hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0b86388c-beea-4223-9a0d-8c6d393bcd6b", "node_type": "1", "metadata": {}, "hash": "ce259c09c9f4728238b74c3104867eb8cd74144350143de3df5d839f2cc30a0f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In deep learning, transformer is an architecture based on the multi-head attention mechanism, in which text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished. \nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM). Later variations have been widely adopted for training large language models (LLMs) on large (language) datasets.\n\nThe modern version of the transformer was proposed in the 2017 paper \"Attention Is All You Need\" by researchers at Google. Transformers were first developed as an improvement over previous architectures for machine translation, but have found many applications since. They are used in large-scale natural language processing, computer vision (vision transformers), reinforcement learning, audio, multimodal learning, robotics, and even playing chess. It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs) and BERT (bidirectional encoder representations from transformers).\n\n\n== History ==\n\n\n=== Predecessors ===\nFor many years, sequence modelling and generation was done by using plain recurrent neural networks (RNNs). A well-cited early example was the Elman network (1990). In theory, the information from one token can propagate arbitrarily far down the sequence, but in practice the vanishing-gradient problem leaves the model's state at the end of a long sentence without precise, extractable information about preceding tokens.\nA key breakthrough was LSTM (1995), a RNN which used various innovations to overcome the vanishing gradient problem, allowing efficient learning of long-sequence modelling. One key innovation was the use of an attention mechanism which used neurons that multiply the outputs of other neurons, so-called multiplicative units. Neural networks using multiplicative units were later called sigma-pi networks or higher-order networks. LSTM became the standard architecture for long sequence modelling until the 2017 publication of Transformers.\nHowever, LSTM still used sequential processing, like most other RNNs. Specifically, RNNs operate one token at a time from first to last; they cannot operate in parallel over all tokens in a sequence.\nModern Transformers overcome this problem, but unlike RNNs, they require computation time that is quadratic in the size of the context window. The linearly scaling fast weight controller (1992) learns to compute a weight matrix for further processing depending on the input. One of its two networks has \"fast weights\" or \"dynamic links\" (1981). A slow neural network learns by gradient descent to generate keys and values for computing the weight changes of the fast neural network which computes answers to queries. This was later shown to be equivalent to the unnormalized linear Transformer.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3238, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0b86388c-beea-4223-9a0d-8c6d393bcd6b": {"__data__": {"id_": "0b86388c-beea-4223-9a0d-8c6d393bcd6b", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61603971", "node_type": "4", "metadata": {}, "hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f9a50d00-f27b-4bd6-bc7d-d95bc4de8338", "node_type": "1", "metadata": {}, "hash": "bf25a37d927f4daa8b7ef2f2e34df49aa0e44ba0eab54b545b2bd4f867e91d9f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "41a1debd-b938-4d7d-af6c-ca99cc5bcf15", "node_type": "1", "metadata": {}, "hash": "01965bed3651d81a8b2c915dfa47f2b795df15bae2d3f596463bccf820f37c62", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Attention with seq2seq ===\n\nThe idea of encoder-decoder sequence transduction had been developed in the early 2010s; commonly cited as the originators that produced seq2seq are two concurrently published papers from 2014.\nA 380M-parameter model for machine translation uses two long short-term memories (LSTM). Its architecture consists of two parts. The encoder is an LSTM that takes in a sequence of tokens and turns it into a vector. The decoder is another LSTM that converts the vector into a sequence of tokens. Similarly, another 130M-parameter model used gated recurrent units (GRU) instead of LSTM. Later research showed that GRUs are neither better nor worse than LSTMs for seq2seq.\nThese early seq2seq models had no attention mechanism, and the state vector is accessible only after the last word of the source text was processed. Although in theory such a vector retains the information about the whole original sentence, in practice the information is poorly preserved. This is because the input is processed sequentially by one recurrent network into a fixed-size output vector, which is then processed by another recurrent network into an output. If the input is long, then the output vector would not be able to contain all relevant information, degrading the output. As evidence, reversing the input sentence improved seq2seq translation.\nThe RNNsearch model introduced an attention mechanism to seq2seq for machine translation to solve the bottleneck problem (of the fixed-size output vector), allowing the model to process long-distance dependencies more easily. The name is because it \"emulates searching through a source sentence during decoding a translation\".\nThe relative performances were compared between global (that of RNNsearch) and local (sliding window) attention model architectures for machine translation, finding that mixed attention had higher quality than global attention, while local attention reduced translation time.\nIn 2016, Google Translate was revamped to Google Neural Machine Translation, which replaced the previous model based on statistical machine translation. The new model was a seq2seq model where the encoder and the decoder were both 8 layers of bidirectional LSTM. It took nine months to develop, and it outperformed the statistical approach, which took ten years to develop.\n\n\n=== Parallelizing attention ===\n\nSeq2seq models with attention (including self-attention) still suffered from the same issue with recurrent networks, which is that they are hard to parallelize, which prevented them from being accelerated on GPUs. In 2016, decomposable attention applied a self-attention mechanism to feedforward networks, which are easy to parallelize, and achieved SOTA result in textual entailment with an order of magnitude fewer parameters than LSTMs. One of its authors, Jakob Uszkoreit, suspected that attention without recurrence would be sufficient for language translation, thus the title \"attention is all you need\". That hypothesis was against conventional wisdom at the time, and even his father Hans Uszkoreit, a well-known computational linguist, was skeptical. In the same year, self-attention (called intra-attention or intra-sentence attention) was proposed for LSTMs.\nIn 2017, the original (100M-sized) encoder-decoder transformer model was proposed in the \"Attention is all you need\" paper. At the time, the focus of the research was on improving seq2seq for machine translation, by removing its recurrence to process all tokens in parallel, but preserving its dot-product attention mechanism to keep its text processing performance. This led to the introduction of a multi-head attention model that was easier to parallelize due to the use of independent heads and the lack of recurrence. Its parallelizability was an important factor to its widespread use in large neural networks.", "mimetype": "text/plain", "start_char_idx": 3241, "end_char_idx": 7098, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "41a1debd-b938-4d7d-af6c-ca99cc5bcf15": {"__data__": {"id_": "41a1debd-b938-4d7d-af6c-ca99cc5bcf15", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61603971", "node_type": "4", "metadata": {}, "hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0b86388c-beea-4223-9a0d-8c6d393bcd6b", "node_type": "1", "metadata": {}, "hash": "ce259c09c9f4728238b74c3104867eb8cd74144350143de3df5d839f2cc30a0f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ef739916-d2e2-4fa3-bbd9-616865383e62", "node_type": "1", "metadata": {}, "hash": "525e6b50001cd4458ad3047e60cb9cede1ba1211d86baa13b07daab8697d383c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== AI boom era ===\nAlready in spring 2017, even before the \"Attention is all you need\" preprint was published, one of the co-authors applied the \"decoder-only\" variation of the architecture to generate fictitious Wikipedia articles. Transformer architecture is now used alongside many generative models that contribute to the ongoing AI boom.\nIn language modelling, ELMo (2018) was a bi-directional LSTM that produces contextualized word embeddings, improving upon the line of research from bag of words and word2vec. It was followed by BERT (2018), an encoder-only Transformer model. In 2019 October, Google started using BERT to process search queries. In 2020, Google Translate replaced the previous RNN-encoder\u2013RNN-decoder model by a Transformer-encoder\u2013RNN-decoder model.\nStarting in 2018, the OpenAI GPT series of decoder-only Transformers became state of the art in natural language generation. In 2022, a chatbot based on GPT-3, ChatGPT, became unexpectedly popular, triggering a boom around large language models.\nSince 2020, Transformers have been applied in modalities beyond text, including the vision transformer, speech recognition, robotics, and multimodal. The vision transformer, in turn, stimulated new developments in convolutional neural networks. Image and video generators like DALL-E (2021), Stable Diffusion 3 (2024), and Sora (2024), use Transformers to analyse input data (like text prompts) by breaking it down into \"tokens\" and then calculating the relevance between each token using self-attention, which helps the model understand the context and relationships within the data.\n\n\n== Training ==\n\n\n=== Methods for stabilizing training ===\nThe plain transformer architecture had difficulty converging. In the original paper the authors recommended using learning rate warmup. That is, the learning rate should linearly scale up from 0 to maximal value for the first part of the training (usually recommended to be 2% of the total number of training steps), before decaying again.\nA 2020 paper found that using layer normalization before (instead of after) multiheaded attention and feedforward layers stabilizes training, not requiring learning rate warmup.\n\n\n=== Pretrain-finetune ===\nTransformers typically are first pretrained by self-supervised learning on a large generic dataset, followed by supervised fine-tuning on a small task-specific dataset. The pretrain dataset is typically an unlabeled large corpus, such as The Pile. Tasks for pretraining and fine-tuning commonly include:\n\nlanguage modeling\nnext-sentence prediction\nquestion answering\nreading comprehension\nsentiment analysis\nparaphrasing\nThe T5 transformer report documents a large number of natural language pretraining tasks. Some examples are:\n\nrestoring or repairing incomplete or corrupted text. For example, the input, \"Thank you\u202f~~\u202fme to your party\u202f~~\u202fweek\", might generate the output, \"Thank you for inviting me to your party last week\".\ntranslation between natural languages (machine translation)\njudging the pragmatic acceptability of natural language. For example, the following sentence might be judged \"not acceptable\", because even though it is syntactically well-formed, it is improbable in ordinary human usage: The course is jumping well.\nNote that while each of these tasks is trivial or obvious for human native speakers of the language (or languages), they have typically proved challenging for previous generations of machine learning architecture.", "mimetype": "text/plain", "start_char_idx": 7101, "end_char_idx": 10568, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ef739916-d2e2-4fa3-bbd9-616865383e62": {"__data__": {"id_": "ef739916-d2e2-4fa3-bbd9-616865383e62", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61603971", "node_type": "4", "metadata": {}, "hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "41a1debd-b938-4d7d-af6c-ca99cc5bcf15", "node_type": "1", "metadata": {}, "hash": "01965bed3651d81a8b2c915dfa47f2b795df15bae2d3f596463bccf820f37c62", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ed38813f-0eac-452b-9117-cf0f44bbfff1", "node_type": "1", "metadata": {}, "hash": "b61103699dd264f54f30c682a84cb9356150849d7baad608f26e9b6e6f8d4921", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Tasks ===\n\nIn general, there are 3 classes of language modelling tasks: \"masked\", \"autoregressive\", and \"prefixLM\". These classes are independent of a specific modeling architecture such as Transformer, but they are often discussed in the context of Transformer.\nIn a masked task, one or more of the tokens is masked out, and the model would produce a probability distribution predicting what the masked-out tokens are based on the context. The loss function for the task is typically sum of log-perplexities for the masked-out tokens: \n  \n    \n      \n        \n          Loss\n        \n        =\n        \u2212\n        \n          \u2211\n          \n            t\n            \u2208\n            \n              masked tokens\n            \n          \n        \n        ln\n        \u2061\n        (\n        \n          probability of \n        \n        t\n        \n           conditional on its context\n        \n        )\n      \n    \n    {\\displaystyle {\\text{Loss}}=-\\sum _{t\\in {\\text{masked tokens}}}\\ln({\\text{probability of }}t{\\text{ conditional on its context}})}\n  \nand the model is trained to minimize this loss function. The BERT series of models are trained for masked token prediction and another task.\nIn an autoregressive task, the entire sequence is masked at first, and the model produces a probability distribution for the first token. Then the first token is revealed and the model predicts the second token, and so on. The loss function for the task is still typically the same. The GPT series of models are trained by autoregressive tasks.\nIn a prefixLM task, the sequence is divided into two parts. The first part is presented as context, and the model predicts the first token of the second part. Then that would be revealed, and the model predicts the second token, and so on. The loss function for the task is still typically the same. The T5 series of models are trained by prefixLM tasks.\nNote that \"masked\" as in \"masked language modelling\" is not \"masked\" as in \"masked attention\", and \"prefixLM\" (prefix language modeling) is not \"prefixLM\" (prefix language model).\n\n\n== Architecture ==\nAll transformers have the same primary components:\n\nTokenizers, which convert text into tokens.\nEmbedding layer, which converts tokens and positions of the tokens into vector representations.\nTransformer layers, which carry out repeated transformations on the vector representations, extracting more and more linguistic information. These consist of alternating attention and feedforward layers. There are two major types of transformer layers: encoder layers and decoder layers, with further variants.\nUn-embedding layer, which converts the final vector representations back to a probability distribution over the tokens.\nThe following description follows exactly the Transformer as described in the original paper. There are variants, described in the following section.\nBy convention, we write all vectors as row vectors. This, for example, means that pushing a vector through a linear layer means multiplying it by a weight matrix on the right, as \n  \n    \n      \n        x\n        W\n      \n    \n    {\\displaystyle xW}\n  \n.\n\n\n=== Tokenization ===\n\nAs the Transformer architecture natively processes numerical data, not text, there must be a translation between text and tokens. A token is an integer that represents a character, or a short segment of characters. On the input side, the input text is parsed into a token sequence. Similarly, on the output side, the output tokens are parsed back to text. The module doing the conversion between texts and token sequences is a tokenizer.\nThe set of all tokens is the vocabulary of the tokenizer, and its size is the vocabulary size \n  \n    \n      \n        \n          n\n          \n            vocabulary\n          \n        \n      \n    \n    {\\displaystyle n_{\\text{vocabulary}}}\n  \n. When faced with tokens outside the vocabulary, typically a special token is used, written as \"[UNK]\" for \"unknown\".\nSome commonly used tokenizers are byte pair encoding, WordPiece, and SentencePiece.", "mimetype": "text/plain", "start_char_idx": 10571, "end_char_idx": 14592, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ed38813f-0eac-452b-9117-cf0f44bbfff1": {"__data__": {"id_": "ed38813f-0eac-452b-9117-cf0f44bbfff1", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61603971", "node_type": "4", "metadata": {}, "hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ef739916-d2e2-4fa3-bbd9-616865383e62", "node_type": "1", "metadata": {}, "hash": "525e6b50001cd4458ad3047e60cb9cede1ba1211d86baa13b07daab8697d383c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a2aa3ec3-8598-4e55-a098-cec317d0cab9", "node_type": "1", "metadata": {}, "hash": "7982d510654bd18c01e65884679d852dc8c324d46819ab89ed70016443333ce9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Tokenization ===\n\nAs the Transformer architecture natively processes numerical data, not text, there must be a translation between text and tokens. A token is an integer that represents a character, or a short segment of characters. On the input side, the input text is parsed into a token sequence. Similarly, on the output side, the output tokens are parsed back to text. The module doing the conversion between texts and token sequences is a tokenizer.\nThe set of all tokens is the vocabulary of the tokenizer, and its size is the vocabulary size \n  \n    \n      \n        \n          n\n          \n            vocabulary\n          \n        \n      \n    \n    {\\displaystyle n_{\\text{vocabulary}}}\n  \n. When faced with tokens outside the vocabulary, typically a special token is used, written as \"[UNK]\" for \"unknown\".\nSome commonly used tokenizers are byte pair encoding, WordPiece, and SentencePiece.\n\n\n=== Embedding ===\n\nEach token is converted into an embedding vector via a lookup table. Equivalently stated, it multiplies a one-hot representation of the token by an embedding matrix \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  \n. For example, if the input token is \n  \n    \n      \n        3\n      \n    \n    {\\displaystyle 3}\n  \n, then the one-hot representation is \n  \n    \n      \n        [\n        0\n        ,\n        0\n        ,\n        0\n        ,\n        1\n        ,\n        0\n        ,\n        0\n        ,\n        \u2026\n        ]\n      \n    \n    {\\displaystyle [0,0,0,1,0,0,\\dots ]}\n  \n, and its embedding vector is\n  \n    \n      \n        \n          E\n          m\n          b\n          e\n          d\n        \n        (\n        3\n        )\n        =\n        [\n        0\n        ,\n        0\n        ,\n        0\n        ,\n        1\n        ,\n        0\n        ,\n        0\n        ,\n        \u2026\n        ]\n        M\n      \n    \n    {\\displaystyle \\mathrm {Embed} (3)=[0,0,0,1,0,0,\\dots ]M}\n  \nThe token embedding vectors are added to their respective positional encoding vectors (see below), producing the sequence of input vectors.\nThe number of dimensions in an embedding vector is called hidden size or embedding size and written as \n  \n    \n      \n        \n          d\n          \n            emb\n          \n        \n      \n    \n    {\\displaystyle d_{\\text{emb}}}\n  \n. This size is written as \n  \n    \n      \n        \n          d\n          \n            model\n          \n        \n      \n    \n    {\\displaystyle d_{\\text{model}}}\n  \n in the original Transformer paper.\n\n\n=== Un-embedding ===\nAn un-embedding layer is almost the reverse of an embedding layer. Whereas an embedding layer converts a token into a vector, an un-embedding layer converts a vector into a probability distribution over tokens.\nThe un-embedding layer is a linear-softmax layer:\n  \n    \n      \n        \n          U\n          n\n          E\n          m\n          b\n          e\n          d\n        \n        (\n        x\n        )\n        =\n        \n          s\n          o\n          f\n          t\n          m\n          a\n          x\n        \n        (\n        x\n        W\n        +\n        b\n        )\n      \n    \n    {\\displaystyle \\mathrm {UnEmbed} (x)=\\mathrm {softmax} (xW+b)}\n  \nThe matrix has shape \n  \n    \n      \n        (\n        \n          d\n          \n            emb\n          \n        \n        ,\n        \n          n\n          \n            vocabulary\n          \n        \n        )\n      \n    \n    {\\displaystyle (d_{\\text{emb}},n_{\\text{vocabulary}})}\n  \n. The embedding matrix \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  \n and the un-embedding matrix \n  \n    \n      \n        W\n      \n    \n    {\\displaystyle W}\n  \n are sometimes required to be transposes of each other, a practice called weight tying.\n\n\n=== Positional encoding ===\n\nA positional encoding is a fixed-size vector representation of the relative positions of tokens within a sequence: it provides the transformer model with information about where the words are in the input sequence. This induces a bias towards the order of the input sequence, so that, for example, the input sequence \"man bites dog\" is processed differently from \"dog bites man\".\nThe positional encoding is defined as a function of type \n  \n    \n      \n        f\n        :\n        \n          R\n        \n        \u2192\n        \n          \n            R\n          \n          \n            d\n          \n        \n        ;\n        d\n        \u2208\n        \n          Z\n        \n        ,\n        d\n        >\n        0\n      \n    \n    {\\displaystyle f:\\mathbb {R} \\to \\mathbb {R} ^{d};d\\in \\mathbb {Z} ,d>0}\n  \n, where \n  \n    \n      \n        d\n      \n    \n    {\\displaystyle d}\n  \n is a positive even integer.", "mimetype": "text/plain", "start_char_idx": 13689, "end_char_idx": 18338, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a2aa3ec3-8598-4e55-a098-cec317d0cab9": {"__data__": {"id_": "a2aa3ec3-8598-4e55-a098-cec317d0cab9", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61603971", "node_type": "4", "metadata": {}, "hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ed38813f-0eac-452b-9117-cf0f44bbfff1", "node_type": "1", "metadata": {}, "hash": "b61103699dd264f54f30c682a84cb9356150849d7baad608f26e9b6e6f8d4921", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9409186e-9f01-4fb0-86bd-f865ae3e6168", "node_type": "1", "metadata": {}, "hash": "4ef7814f0baba97156ca7983a7cc2f579ea7b30c34f4f42eac21b8850ef986ed", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This induces a bias towards the order of the input sequence, so that, for example, the input sequence \"man bites dog\" is processed differently from \"dog bites man\".\nThe positional encoding is defined as a function of type \n  \n    \n      \n        f\n        :\n        \n          R\n        \n        \u2192\n        \n          \n            R\n          \n          \n            d\n          \n        \n        ;\n        d\n        \u2208\n        \n          Z\n        \n        ,\n        d\n        >\n        0\n      \n    \n    {\\displaystyle f:\\mathbb {R} \\to \\mathbb {R} ^{d};d\\in \\mathbb {Z} ,d>0}\n  \n, where \n  \n    \n      \n        d\n      \n    \n    {\\displaystyle d}\n  \n is a positive even integer. The full positional encoding defined in the original paper is:\n  \n    \n      \n        (\n        f\n        (\n        t\n        \n          )\n          \n            2\n            k\n          \n        \n        ,\n        f\n        (\n        t\n        \n          )\n          \n            2\n            k\n            +\n            1\n          \n        \n        )\n        =\n        (\n        sin\n        \u2061\n        (\n        \u03b8\n        )\n        ,\n        cos\n        \u2061\n        (\n        \u03b8\n        )\n        )\n        \n        \u2200\n        k\n        \u2208\n        {\n        0\n        ,\n        1\n        ,\n        \u2026\n        ,\n        d\n        \n          /\n        \n        2\n        \u2212\n        1\n        }\n      \n    \n    {\\displaystyle (f(t)_{2k},f(t)_{2k+1})=(\\sin(\\theta ),\\cos(\\theta ))\\quad \\forall k\\in \\{0,1,\\ldots ,d/2-1\\}}\n  \nwhere \n  \n    \n      \n        \u03b8\n        =\n        \n          \n            t\n            \n              r\n              \n                k\n              \n            \n          \n        \n        ,\n        r\n        =\n        \n          N\n          \n            2\n            \n              /\n            \n            d\n          \n        \n      \n    \n    {\\displaystyle \\theta ={\\frac {t}{r^{k}}},r=N^{2/d}}\n  \n.\nHere, \n  \n    \n      \n        N\n      \n    \n    {\\displaystyle N}\n  \n is a free parameter that should be significantly larger than the biggest \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n that would be input into the positional encoding function. The original paper uses \n  \n    \n      \n        N\n        =\n        10000\n      \n    \n    {\\displaystyle N=10000}\n  \n.\nThe function is in a simpler form when written as a complex function of type \n  \n    \n      \n        f\n        :\n        \n          R\n        \n        \u2192\n        \n          \n            C\n          \n          \n            d\n            \n              /\n            \n            2\n          \n        \n      \n    \n    {\\displaystyle f:\\mathbb {R} \\to \\mathbb {C} ^{d/2}}\n  \n\n  \n    \n      \n        f\n        (\n        t\n        )\n        =\n        \n          \n            (\n            \n              e\n              \n                i\n                t\n                \n                  /\n                \n                \n                  r\n                  \n                    k\n                  \n                \n              \n            \n            )\n          \n          \n            k\n            =\n            0\n            ,\n            1\n            ,\n            \u2026\n            ,\n            \n              \n                d\n                2\n              \n            \n            \u2212\n            1\n          \n        \n      \n    \n    {\\displaystyle f(t)=\\left(e^{it/r^{k}}\\right)_{k=0,1,\\ldots ,{\\frac {d}{2}}-1}}\n  \nwhere \n  \n    \n      \n        r\n        =\n        \n          N\n          \n            2\n            \n              /\n            \n            d\n          \n        \n      \n    \n    {\\displaystyle r=N^{2/d}}\n  \n.\nThe main reason for using this positional encoding function is that using it, shifts are linear transformations:\n  \n    \n      \n        f\n        (\n        t\n        +\n        \u0394\n        t\n        )\n        =\n        \n          d\n          i\n          a\n          g\n        \n        (\n        f\n        (\n        \u0394\n        t\n        )\n        )\n        f\n        (\n        t\n        )\n      \n    \n    {\\displaystyle f(t+\\Delta t)=\\mathrm {diag} (f(\\Delta t))f(t)}\n  \nwhere \n  \n    \n      \n        \u0394\n        t\n        \u2208\n        \n          R\n        \n      \n    \n    {\\displaystyle \\Delta t\\in \\mathbb {R} }\n  \n is the distance one wishes to shift. This allows the transformer to take any encoded position, and find the encoding of the position n-steps-ahead or n-steps-behind, by a matrix multiplication.", "mimetype": "text/plain", "start_char_idx": 17659, "end_char_idx": 22101, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9409186e-9f01-4fb0-86bd-f865ae3e6168": {"__data__": {"id_": "9409186e-9f01-4fb0-86bd-f865ae3e6168", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61603971", "node_type": "4", "metadata": {}, "hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a2aa3ec3-8598-4e55-a098-cec317d0cab9", "node_type": "1", "metadata": {}, "hash": "7982d510654bd18c01e65884679d852dc8c324d46819ab89ed70016443333ce9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b54c2232-05ed-4379-b9dc-cb492fb32cfe", "node_type": "1", "metadata": {}, "hash": "1c1b99b96875750af1f05494433df0ab5fd70d2491d9e0411c96945e87bb4793", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The main reason for using this positional encoding function is that using it, shifts are linear transformations:\n  \n    \n      \n        f\n        (\n        t\n        +\n        \u0394\n        t\n        )\n        =\n        \n          d\n          i\n          a\n          g\n        \n        (\n        f\n        (\n        \u0394\n        t\n        )\n        )\n        f\n        (\n        t\n        )\n      \n    \n    {\\displaystyle f(t+\\Delta t)=\\mathrm {diag} (f(\\Delta t))f(t)}\n  \nwhere \n  \n    \n      \n        \u0394\n        t\n        \u2208\n        \n          R\n        \n      \n    \n    {\\displaystyle \\Delta t\\in \\mathbb {R} }\n  \n is the distance one wishes to shift. This allows the transformer to take any encoded position, and find the encoding of the position n-steps-ahead or n-steps-behind, by a matrix multiplication.\nBy taking a linear sum, any convolution can also be implemented as linear transformations:\n  \n    \n      \n        \n          \u2211\n          \n            j\n          \n        \n        \n          c\n          \n            j\n          \n        \n        f\n        (\n        t\n        +\n        \u0394\n        \n          t\n          \n            j\n          \n        \n        )\n        =\n        \n          (\n          \n            \n              \u2211\n              \n                j\n              \n            \n            \n              c\n              \n                j\n              \n            \n            \n            \n              d\n              i\n              a\n              g\n            \n            (\n            f\n            (\n            \u0394\n            \n              t\n              \n                j\n              \n            \n            )\n            )\n          \n          )\n        \n        f\n        (\n        t\n        )\n      \n    \n    {\\displaystyle \\sum _{j}c_{j}f(t+\\Delta t_{j})=\\left(\\sum _{j}c_{j}\\,\\mathrm {diag} (f(\\Delta t_{j}))\\right)f(t)}\n  \nfor any constants \n  \n    \n      \n        \n          c\n          \n            j\n          \n        \n      \n    \n    {\\displaystyle c_{j}}\n  \n. This allows the transformer to take any encoded position and find a linear sum of the encoded locations of its neighbors. This sum of encoded positions, when fed into the attention mechanism, would create attention weights on its neighbors, much like what happens in a convolutional neural network language model. In the author's words, \"we hypothesized it would allow the model to easily learn to attend by relative position.\"\nIn typical implementations, all operations are done over the real numbers, not the complex numbers, but since complex multiplication can be implemented as real 2-by-2 matrix multiplication, this is a mere notational difference.\n\n\n=== Encoder-decoder (overview) ===\n\nLike earlier seq2seq models, the original transformer model used an encoder-decoder architecture. The encoder consists of encoding layers that process all the input tokens together one layer after another, while the decoder consists of decoding layers that iteratively process the encoder's output and the decoder's output tokens so far.\nThe purpose of each encoder layer is to create contextualized representations of the tokens, where each representation corresponds to a token that \"mixes\" information from other input tokens via self-attention mechanism. Each decoder layer contains two attention sublayers: (1) cross-attention for incorporating the output of encoder (contextualized input token representations), and (2) self-attention for \"mixing\" information among the input tokens to the decoder (i.e. the tokens generated so far during inference time).\nBoth the encoder and decoder layers have a feed-forward neural network for additional processing of their outputs and contain residual connections and layer normalization steps. These feed-forward layers contain most of the parameters in a Transformer model.", "mimetype": "text/plain", "start_char_idx": 21299, "end_char_idx": 25127, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b54c2232-05ed-4379-b9dc-cb492fb32cfe": {"__data__": {"id_": "b54c2232-05ed-4379-b9dc-cb492fb32cfe", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61603971", "node_type": "4", "metadata": {}, "hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9409186e-9f01-4fb0-86bd-f865ae3e6168", "node_type": "1", "metadata": {}, "hash": "4ef7814f0baba97156ca7983a7cc2f579ea7b30c34f4f42eac21b8850ef986ed", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "49dcb929-2a70-4cb0-b822-727c29f95ef0", "node_type": "1", "metadata": {}, "hash": "7c740b7230d55339076955fa0565633a953db4134ed27a45f325e61c4717411a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Feedforward network ===\n\nThe feedforward network (FFN) modules in a Transformer are 2-layered multilayer perceptrons:\n  \n    \n      \n        \n          F\n          F\n          N\n        \n        (\n        x\n        )\n        =\n        \u03d5\n        (\n        x\n        \n          W\n          \n            (\n            1\n            )\n          \n        \n        +\n        \n          b\n          \n            (\n            1\n            )\n          \n        \n        )\n        \n          W\n          \n            (\n            2\n            )\n          \n        \n        +\n        \n          b\n          \n            (\n            2\n            )\n          \n        \n      \n    \n    {\\displaystyle \\mathrm {FFN} (x)=\\phi (xW^{(1)}+b^{(1)})W^{(2)}+b^{(2)}}\n  \nwhere \n  \n    \n      \n        \n          W\n          \n            (\n            1\n            )\n          \n        \n      \n    \n    {\\displaystyle W^{(1)}}\n  \n and \n  \n    \n      \n        \n          W\n          \n            (\n            2\n            )\n          \n        \n      \n    \n    {\\displaystyle W^{(2)}}\n  \n are weight matrices and \n  \n    \n      \n        \n          b\n          \n            (\n            1\n            )\n          \n        \n      \n    \n    {\\displaystyle b^{(1)}}\n  \n and  \n  \n    \n      \n        \n          b\n          \n            (\n            2\n            )\n          \n        \n      \n    \n    {\\displaystyle b^{(2)}}\n  \n are bias vectors, and \n  \n    \n      \n        \u03d5\n      \n    \n    {\\displaystyle \\phi }\n  \n is its activation function. The original Transformer used ReLU activation.\nThe number of neurons in the middle layer is called intermediate size (GPT), filter size (BERT), or feedforward size (BERT). It is typically larger than the embedding size. For example, in both GPT-2 series and BERT series, the intermediate size of a model is 4 times its embedding size: \n  \n    \n      \n        \n          d\n          \n            ffn\n          \n        \n        =\n        4\n        \n          d\n          \n            emb\n          \n        \n      \n    \n    {\\displaystyle d_{\\text{ffn}}=4d_{\\text{emb}}}\n  \n.\n\n\n=== Scaled dot-product attention ===\n\n\n==== Attention head ====\n\nThe attention mechanism used in the Transformer architecture are scaled dot-product attention units. For each unit, the transformer model learns three weight matrices: the query weights \n  \n    \n      \n        \n          W\n          \n            Q\n          \n        \n      \n    \n    {\\displaystyle W^{Q}}\n  \n, the key weights \n  \n    \n      \n        \n          W\n          \n            K\n          \n        \n      \n    \n    {\\displaystyle W^{K}}\n  \n, and the value weights \n  \n    \n      \n        \n          W\n          \n            V\n          \n        \n      \n    \n    {\\displaystyle W^{V}}\n  \n.\nThe module takes three sequences, a query sequence, a key sequence, and a value sequence. The query sequence is a sequence of length \n  \n    \n      \n        \n          \u2113\n          \n            seq, query\n          \n        \n      \n    \n    {\\displaystyle \\ell _{\\text{seq, query}}}\n  \n, and each entry is a vector of dimension \n  \n    \n      \n        \n          d\n          \n            emb, query\n          \n        \n      \n    \n    {\\displaystyle d_{\\text{emb, query}}}\n  \n. Similarly for the key and value sequences.\nFor each vector \n  \n    \n      \n        \n          x\n          \n            i\n            ,\n            \n              query\n            \n          \n        \n      \n    \n    {\\displaystyle x_{i,{\\text{query}}}}\n  \n in the query sequence, it is multiplied by a matrix \n  \n    \n      \n        \n          W\n          \n            Q\n          \n        \n      \n    \n    {\\displaystyle W^{Q}}\n  \n to produce a query vector \n  \n    \n      \n        \n          q\n          \n            i\n          \n        \n        =\n        \n          x\n          \n            i\n            ,\n            \n              query\n            \n          \n        \n        \n          W\n          \n            Q\n          \n        \n      \n    \n    {\\displaystyle q_{i}=x_{i,{\\text{query}}}W^{Q}}\n  \n. The matrix of all query vectors is the query matrix:\n  \n    \n      \n        Q\n        =\n        \n          X\n          \n            query\n          \n        \n        \n          W\n          \n            Q\n          \n        \n      \n    \n    {\\displaystyle Q=X_{\\text{query}}W^{Q}}\n  \nSimilarly, we construct the key matrix \n  \n    \n      \n        K\n        =\n        \n          X\n          \n            key\n          \n        \n        \n          W\n          \n            K\n          \n        \n      \n    \n    {\\displaystyle K=X_{\\text{key}}W^{K}}\n  \n and the value matrix \n  \n    \n      \n        V\n        =\n        \n          X\n          \n            value\n          \n        \n        \n          W\n          \n            V\n          \n        \n      \n    \n    {\\displaystyle V=X_{\\text{value}}W^{V}}\n  \n.", "mimetype": "text/plain", "start_char_idx": 25130, "end_char_idx": 29996, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "49dcb929-2a70-4cb0-b822-727c29f95ef0": {"__data__": {"id_": "49dcb929-2a70-4cb0-b822-727c29f95ef0", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61603971", "node_type": "4", "metadata": {}, "hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b54c2232-05ed-4379-b9dc-cb492fb32cfe", "node_type": "1", "metadata": {}, "hash": "1c1b99b96875750af1f05494433df0ab5fd70d2491d9e0411c96945e87bb4793", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "724aa0bc-a5f6-455e-b58c-35e5096abcb8", "node_type": "1", "metadata": {}, "hash": "aa2fc1e8639d6c97e1dbcbadf09b4de7178351e63e7c7fba9a90169a8837a619", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The matrix of all query vectors is the query matrix:\n  \n    \n      \n        Q\n        =\n        \n          X\n          \n            query\n          \n        \n        \n          W\n          \n            Q\n          \n        \n      \n    \n    {\\displaystyle Q=X_{\\text{query}}W^{Q}}\n  \nSimilarly, we construct the key matrix \n  \n    \n      \n        K\n        =\n        \n          X\n          \n            key\n          \n        \n        \n          W\n          \n            K\n          \n        \n      \n    \n    {\\displaystyle K=X_{\\text{key}}W^{K}}\n  \n and the value matrix \n  \n    \n      \n        V\n        =\n        \n          X\n          \n            value\n          \n        \n        \n          W\n          \n            V\n          \n        \n      \n    \n    {\\displaystyle V=X_{\\text{value}}W^{V}}\n  \n.\nIt is usually the case that all \n  \n    \n      \n        \n          W\n          \n            Q\n          \n        \n        ,\n        \n          W\n          \n            K\n          \n        \n        ,\n        \n          W\n          \n            V\n          \n        \n      \n    \n    {\\displaystyle W^{Q},W^{K},W^{V}}\n  \n are square matrices, meaning \n  \n    \n      \n        \n          d\n          \n            emb, query\n          \n        \n        =\n        \n          d\n          \n            query\n          \n        \n      \n    \n    {\\displaystyle d_{\\text{emb, query}}=d_{\\text{query}}}\n  \n, etc.\nAttention weights are calculated using the query and key vectors: the attention weight \n  \n    \n      \n        \n          a\n          \n            i\n            j\n          \n        \n      \n    \n    {\\displaystyle a_{ij}}\n  \n from token \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n to token \n  \n    \n      \n        j\n      \n    \n    {\\displaystyle j}\n  \n is the dot product between \n  \n    \n      \n        \n          q\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle q_{i}}\n  \n and \n  \n    \n      \n        \n          k\n          \n            j\n          \n        \n      \n    \n    {\\displaystyle k_{j}}\n  \n. The attention weights are divided by the square root of the dimension of the key vectors, \n  \n    \n      \n        \n          \n            \n              d\n              \n                k\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\sqrt {d_{k}}}}\n  \n, which stabilizes gradients during training, and passed through a softmax which normalizes the weights. The fact that \n  \n    \n      \n        \n          W\n          \n            Q\n          \n        \n      \n    \n    {\\displaystyle W^{Q}}\n  \n and \n  \n    \n      \n        \n          W\n          \n            K\n          \n        \n      \n    \n    {\\displaystyle W^{K}}\n  \n are different matrices allows attention to be non-symmetric: if token \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n attends to token \n  \n    \n      \n        j\n      \n    \n    {\\displaystyle j}\n  \n (i.e. \n  \n    \n      \n        \n          q\n          \n            i\n          \n        \n        \u22c5\n        \n          k\n          \n            j\n          \n        \n      \n    \n    {\\displaystyle q_{i}\\cdot k_{j}}\n  \n is large), this does not necessarily mean that token \n  \n    \n      \n        j\n      \n    \n    {\\displaystyle j}\n  \n will attend to token \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n (i.e. \n  \n    \n      \n        \n          q\n          \n            j\n          \n        \n        \u22c5\n        \n          k\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle q_{j}\\cdot k_{i}}\n  \n could be small). The output of the attention unit for token \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n is the weighted sum of the value vectors of all tokens, weighted by \n  \n    \n      \n        \n          a\n          \n            i\n            j\n          \n        \n      \n    \n    {\\displaystyle a_{ij}}\n  \n, the attention from token \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n to each token.\nThe attention calculation for all tokens can be expressed as one large matrix calculation using the softmax function, which is useful for training due to computational matrix operation optimizations that quickly compute matrix operations. The matrices \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n  \n, \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n and \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n are defined as the matrices where the \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \nth rows are vectors \n  \n    \n      \n        \n          q\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle q_{i}}\n  \n, \n  \n    \n      \n        \n          k\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle k_{i}}\n  \n, and \n  \n    \n      \n        \n          v\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle v_{i}}\n  \n respectively.", "mimetype": "text/plain", "start_char_idx": 29193, "end_char_idx": 34158, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "724aa0bc-a5f6-455e-b58c-35e5096abcb8": {"__data__": {"id_": "724aa0bc-a5f6-455e-b58c-35e5096abcb8", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61603971", "node_type": "4", "metadata": {}, "hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "49dcb929-2a70-4cb0-b822-727c29f95ef0", "node_type": "1", "metadata": {}, "hash": "7c740b7230d55339076955fa0565633a953db4134ed27a45f325e61c4717411a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b5cc7826-8fdf-4f18-9690-6a0f6e9666d6", "node_type": "1", "metadata": {}, "hash": "d1f7fb4226a8c6de92dce7846f6ad576dcec02704cd41c1abb2c0ddd2ab3db51", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The attention calculation for all tokens can be expressed as one large matrix calculation using the softmax function, which is useful for training due to computational matrix operation optimizations that quickly compute matrix operations. The matrices \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n  \n, \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n and \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n are defined as the matrices where the \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \nth rows are vectors \n  \n    \n      \n        \n          q\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle q_{i}}\n  \n, \n  \n    \n      \n        \n          k\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle k_{i}}\n  \n, and \n  \n    \n      \n        \n          v\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle v_{i}}\n  \n respectively. Then we can represent the attention as\n  \n    \n      \n        \n          \n            \n              \n                \n                  Attention\n                \n                (\n                Q\n                ,\n                K\n                ,\n                V\n                )\n                =\n                \n                  softmax\n                \n                \n                  (\n                  \n                    \n                      \n                        Q\n                        \n                          K\n                          \n                            \n                              T\n                            \n                          \n                        \n                      \n                      \n                        \n                          d\n                          \n                            k\n                          \n                        \n                      \n                    \n                  \n                  )\n                \n                V\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}{\\text{Attention}}(Q,K,V)={\\text{softmax}}\\left({\\frac {QK^{\\mathrm {T} }}{\\sqrt {d_{k}}}}\\right)V\\end{aligned}}}\n  \n\nwhere the softmax is applied over each of the rows of the matrix.\nThe number of dimensions in a query vector is query size \n  \n    \n      \n        \n          d\n          \n            query\n          \n        \n      \n    \n    {\\displaystyle d_{\\text{query}}}\n  \n and similarly for the key size \n  \n    \n      \n        \n          d\n          \n            key\n          \n        \n      \n    \n    {\\displaystyle d_{\\text{key}}}\n  \n and value size \n  \n    \n      \n        \n          d\n          \n            value\n          \n        \n      \n    \n    {\\displaystyle d_{\\text{value}}}\n  \n. The output dimension of an attention head is its head dimension \n  \n    \n      \n        \n          d\n          \n            head\n          \n        \n      \n    \n    {\\displaystyle d_{\\text{head}}}\n  \n. The attention mechanism requires the following three equalities to hold:\n  \n    \n      \n        \n          \u2113\n          \n            seq, key\n          \n        \n        =\n        \n          \u2113\n          \n            seq, value\n          \n        \n        ,\n        \n        \n          d\n          \n            query\n          \n        \n        =\n        \n          d\n          \n            key\n          \n        \n        ,\n        \n        \n          d\n          \n            value\n          \n        \n        =\n        \n          d\n          \n            head\n          \n        \n      \n    \n    {\\displaystyle \\ell _{\\text{seq, key}}=\\ell _{\\text{seq, value}},\\;d_{\\text{query}}=d_{\\text{key}},\\;d_{\\text{value}}=d_{\\text{head}}}\n  \nbut is otherwise unconstrained.\nIf the attention head is used in a self-attention fashion, then \n  \n    \n      \n        \n          X\n          \n            query\n          \n        \n        =\n        \n          X\n          \n            key\n          \n        \n        =\n        \n          X\n          \n            value\n          \n        \n      \n    \n    {\\displaystyle X_{\\text{query}}=X_{\\text{key}}=X_{\\text{value}}}\n  \n. If the attention head is used in a cross-attention fashion, then usually \n  \n    \n      \n        \n          X\n          \n            query\n          \n        \n        \u2260\n        \n          X\n          \n            key\n          \n        \n        =\n        \n          X\n          \n            value\n          \n        \n      \n    \n    {\\displaystyle X_{\\text{query}}\\neq X_{\\text{key}}=X_{\\text{value}}}\n  \n. It is theoretically possible for all three to be different, but that is rarely the case in practice.\n\n\n==== Multiheaded attention ====\n\nOne set of \n  \n    \n      \n        \n          (\n          \n            \n              W\n              \n                Q\n              \n            \n            ,\n            \n              W\n              \n                K\n              \n            \n            ,\n            \n              W\n              \n                V\n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\left(W^{Q},W^{K},W^{V}\\right)}\n  \n matrices is called an attention head, and each layer in a transformer model has multiple attention heads. While each attention head attends to the tokens that are relevant to each token, multiple attention heads allow the model to do this for different definitions of \"relevance\".", "mimetype": "text/plain", "start_char_idx": 33197, "end_char_idx": 38639, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b5cc7826-8fdf-4f18-9690-6a0f6e9666d6": {"__data__": {"id_": "b5cc7826-8fdf-4f18-9690-6a0f6e9666d6", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61603971", "node_type": "4", "metadata": {}, "hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "724aa0bc-a5f6-455e-b58c-35e5096abcb8", "node_type": "1", "metadata": {}, "hash": "aa2fc1e8639d6c97e1dbcbadf09b4de7178351e63e7c7fba9a90169a8837a619", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "634dea5a-efc4-43ea-955b-2abd4315cc9d", "node_type": "1", "metadata": {}, "hash": "53d5fd77cd0a901cc92ccf571850ee2a8ca3762ee5949a02c4386df2c9e6c4ed", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "It is theoretically possible for all three to be different, but that is rarely the case in practice.\n\n\n==== Multiheaded attention ====\n\nOne set of \n  \n    \n      \n        \n          (\n          \n            \n              W\n              \n                Q\n              \n            \n            ,\n            \n              W\n              \n                K\n              \n            \n            ,\n            \n              W\n              \n                V\n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\left(W^{Q},W^{K},W^{V}\\right)}\n  \n matrices is called an attention head, and each layer in a transformer model has multiple attention heads. While each attention head attends to the tokens that are relevant to each token, multiple attention heads allow the model to do this for different definitions of \"relevance\". Specifically, the query and key projection matrices, \n  \n    \n      \n        \n          W\n          \n            Q\n          \n        \n      \n    \n    {\\displaystyle W^{Q}}\n  \n and \n  \n    \n      \n        \n          W\n          \n            K\n          \n        \n      \n    \n    {\\displaystyle W^{K}}\n  \n , which are involved in the attention score computation, defines the \"relevance\". Meanwhile, the value projection matrix \n  \n    \n      \n        \n          W\n          \n            V\n          \n        \n      \n    \n    {\\displaystyle W^{V}}\n  \n, in combination with the part of the output projection matrix \n  \n    \n      \n        \n          W\n          \n            O\n          \n        \n      \n    \n    {\\displaystyle W^{O}}\n  \n, determines how the attended tokens influence what information is passed to subsequent layers and ultimately the output logits. In addition, the scope of attention, or the range of token relationships captured by each attention head, can expand as tokens pass through successive layers. This allows the model to capture more complex and long-range dependencies in deeper layers. Many transformer attention heads encode relevance relations that are meaningful to humans. For example, some attention heads can attend mostly to the next word, while others mainly attend from verbs to their direct objects. The computations for each attention head can be performed in parallel, which allows for fast processing. The outputs for the attention layer are concatenated to pass into the feed-forward neural network layers.\nConcretely, let the multiple attention heads be indexed by \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n, then we have\n  \n    \n      \n        \n          MultiheadedAttention\n        \n        (\n        Q\n        ,\n        K\n        ,\n        V\n        )\n        =\n        \n          \n            Concat\n          \n          \n            i\n            \u2208\n            [\n            \n              n\n              \n                heads\n              \n            \n            ]\n          \n        \n        (\n        \n          Attention\n        \n        (\n        X\n        \n          W\n          \n            i\n          \n          \n            Q\n          \n        \n        ,\n        X\n        \n          W\n          \n            i\n          \n          \n            K\n          \n        \n        ,\n        X\n        \n          W\n          \n            i\n          \n          \n            V\n          \n        \n        )\n        )\n        \n          W\n          \n            O\n          \n        \n      \n    \n    {\\displaystyle {\\text{MultiheadedAttention}}(Q,K,V)={\\text{Concat}}_{i\\in [n_{\\text{heads}}]}({\\text{Attention}}(XW_{i}^{Q},XW_{i}^{K},XW_{i}^{V}))W^{O}}\n  \n where the matrix \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is the concatenation of word embeddings, and the matrices \n  \n    \n      \n        \n          W\n          \n            i\n          \n          \n            Q\n          \n        \n        ,\n        \n          W\n          \n            i\n          \n          \n            K\n          \n        \n        ,\n        \n          W\n          \n            i\n          \n          \n            V\n          \n        \n      \n    \n    {\\displaystyle W_{i}^{Q},W_{i}^{K},W_{i}^{V}}\n  \n are \"projection matrices\" owned by individual attention head \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n, and \n  \n    \n      \n        \n          W\n          \n            O\n          \n        \n      \n    \n    {\\displaystyle W^{O}}\n  \n is a final projection matrix owned by the whole multi-headed attention head.\nIt is theoretically possible for each attention head to have a different head dimension \n  \n    \n      \n        \n          d\n          \n            head\n          \n        \n      \n    \n    {\\displaystyle d_{\\text{head}}}\n  \n, but that is rarely the case in practice.\nAs an example, in the smallest GPT-2 model, there are only self-attention mechanisms.", "mimetype": "text/plain", "start_char_idx": 37767, "end_char_idx": 42606, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "634dea5a-efc4-43ea-955b-2abd4315cc9d": {"__data__": {"id_": "634dea5a-efc4-43ea-955b-2abd4315cc9d", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61603971", "node_type": "4", "metadata": {}, "hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b5cc7826-8fdf-4f18-9690-6a0f6e9666d6", "node_type": "1", "metadata": {}, "hash": "d1f7fb4226a8c6de92dce7846f6ad576dcec02704cd41c1abb2c0ddd2ab3db51", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f395caaf-43b5-49fd-a3f0-52adef4b24ed", "node_type": "1", "metadata": {}, "hash": "68ae2586e7c7881aee2af7a639890cbd3b95faebd00241febb69dc08b557099c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "It is theoretically possible for each attention head to have a different head dimension \n  \n    \n      \n        \n          d\n          \n            head\n          \n        \n      \n    \n    {\\displaystyle d_{\\text{head}}}\n  \n, but that is rarely the case in practice.\nAs an example, in the smallest GPT-2 model, there are only self-attention mechanisms. It has the following dimensions:\n  \n    \n      \n        \n          d\n          \n            emb\n          \n        \n        =\n        768\n        ,\n        \n          n\n          \n            head\n          \n        \n        =\n        12\n        ,\n        \n          d\n          \n            head\n          \n        \n        =\n        64\n      \n    \n    {\\displaystyle d_{\\text{emb}}=768,n_{\\text{head}}=12,d_{\\text{head}}=64}\n  \nSince \n  \n    \n      \n        12\n        \u00d7\n        64\n        =\n        768\n      \n    \n    {\\displaystyle 12\\times 64=768}\n  \n, its output projection matrix \n  \n    \n      \n        \n          W\n          \n            O\n          \n        \n        \u2208\n        \n          \n            R\n          \n          \n            (\n            12\n            \u00d7\n            64\n            )\n            \u00d7\n            768\n          \n        \n      \n    \n    {\\displaystyle W^{O}\\in \\mathbb {R} ^{(12\\times 64)\\times 768}}\n  \n is a square matrix.", "mimetype": "text/plain", "start_char_idx": 42254, "end_char_idx": 43568, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f395caaf-43b5-49fd-a3f0-52adef4b24ed": {"__data__": {"id_": "f395caaf-43b5-49fd-a3f0-52adef4b24ed", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61603971", "node_type": "4", "metadata": {}, "hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "634dea5a-efc4-43ea-955b-2abd4315cc9d", "node_type": "1", "metadata": {}, "hash": "53d5fd77cd0a901cc92ccf571850ee2a8ca3762ee5949a02c4386df2c9e6c4ed", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f066afd2-28bb-40db-970b-3396b82b1c81", "node_type": "1", "metadata": {}, "hash": "52baa33aadf139b97f43063d1fb947ee848fb09446f533cf46ac3544ea2801f5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Masked attention ====\nThe Transformer architecture is constructed to calculate output tokens iteratively. Assuming \n  \n    \n      \n        t\n        =\n        0\n      \n    \n    {\\displaystyle t=0}\n  \n refers to the calculation of the first output token \n  \n    \n      \n        i\n        =\n        0\n      \n    \n    {\\displaystyle i=0}\n  \n, for step \n  \n    \n      \n        t\n        >\n        0\n      \n    \n    {\\displaystyle t>0}\n  \n, the output token \n  \n    \n      \n        i\n        =\n        0\n      \n    \n    {\\displaystyle i=0}\n  \n shall remain constant. This ensures properties of the model similar to autoregressive models. Therefore, at every time step \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  \n, the calculation for all outputs \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n should not have access to tokens at position \n  \n    \n      \n        j\n      \n    \n    {\\displaystyle j}\n  \n for \n  \n    \n      \n        j\n        >=\n        i\n      \n    \n    {\\displaystyle j>=i}\n  \n (as it naturally is the case for time step \n  \n    \n      \n        t\n        =\n        i\n      \n    \n    {\\displaystyle t=i}\n  \n, when tokens \n  \n    \n      \n        j\n        >\n        t\n      \n    \n    {\\displaystyle j>t}\n  \n are not yet calculated). This behavior may be accomplished before the softmax stage by adding a mask matrix \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  \n that is \n  \n    \n      \n        \u2212\n        \u221e\n      \n    \n    {\\displaystyle -\\infty }\n  \n at entries where the attention link must be cut, and \n  \n    \n      \n        0\n      \n    \n    {\\displaystyle 0}\n  \n at other places:\n  \n    \n      \n        \n          \n            \n              \n                \n                  MaskedAttention\n                \n                (\n                Q\n                ,\n                K\n                ,\n                V\n                )\n                =\n                \n                  softmax\n                \n                \n                  (\n                  \n                    M\n                    +\n                    \n                      \n                        \n                          Q\n                          \n                            K\n                            \n                              \n                                T\n                              \n                            \n                          \n                        \n                        \n                          \n                            d\n                            \n                              k\n                            \n                          \n                        \n                      \n                    \n                  \n                  )\n                \n                V\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}{\\text{MaskedAttention}}(Q,K,V)={\\text{softmax}}\\left(M+{\\frac {QK^{\\mathrm {T} }}{\\sqrt {d_{k}}}}\\right)V\\end{aligned}}}\n  \n The following matrix is commonly used in decoder self-attention modules, called \"causal masking\":\n  \n    \n      \n        \n          M\n          \n            causal\n          \n        \n        =\n        \n          \n            [\n            \n              \n                \n                  0\n                \n                \n                  \u2212\n                  \u221e\n                \n                \n                  \u2212\n                  \u221e\n                \n                \n                  \u2026\n                \n                \n                  \u2212\n                  \u221e\n                \n              \n              \n                \n                  0\n                \n                \n                  0\n                \n                \n                  \u2212\n                  \u221e\n                \n                \n                  \u2026\n                \n                \n                  \u2212\n                  \u221e\n                \n              \n              \n                \n                  0\n                \n                \n                  0\n                \n                \n                  0\n                \n                \n                  \u2026\n                \n                \n                  \u2212\n                  \u221e\n                \n              \n              \n                \n                  \u22ee\n                \n                \n                  \u22ee\n                \n                \n                  \u22ee\n                \n                \n                  \u22f1\n                \n                \n                  \u22ee\n                \n              \n              \n                \n                  0\n                \n                \n                  0\n                \n                \n                  0\n                \n                \n                  \u2026\n                \n                \n                  0\n                \n              \n            \n            ]\n          \n        \n      \n    \n    {\\displaystyle M_{\\text{causal}}={\\begin{bmatrix}0&-\\infty &-\\infty &\\dots &-\\infty \\\\0&0&-\\infty &\\dots &-\\infty \\\\0&0&0&\\dots &-\\infty \\\\\\vdots &\\vdots &\\vdots &\\ddots &\\vdots \\\\0&0&0&\\dots &0\\end{bmatrix}}}\n  \n\nIn words, it means that each token can pay attention to itself, and every token before it, but not any after it. A non-masked attention module can be thought of as a masked attention module where the mask has all entries zero. As an example of an uncommon use of mask matrix, the XLNet considers all masks of the form \n  \n    \n      \n        P\n        \n          M\n          \n            causal\n          \n        \n        \n          P\n          \n            \u2212\n            1\n          \n        \n      \n    \n    {\\displaystyle PM_{\\text{causal}}P^{-1}}\n  \n, where \n  \n    \n      \n        P\n      \n    \n    {\\displaystyle P}\n  \n is a random permutation matrix.", "mimetype": "text/plain", "start_char_idx": 43571, "end_char_idx": 49378, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f066afd2-28bb-40db-970b-3396b82b1c81": {"__data__": {"id_": "f066afd2-28bb-40db-970b-3396b82b1c81", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61603971", "node_type": "4", "metadata": {}, "hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f395caaf-43b5-49fd-a3f0-52adef4b24ed", "node_type": "1", "metadata": {}, "hash": "68ae2586e7c7881aee2af7a639890cbd3b95faebd00241febb69dc08b557099c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f285ebfe-fe9f-4e85-91a7-d61981c83929", "node_type": "1", "metadata": {}, "hash": "0106f513bde97d96be03790d74919e5cd5942a5201ef40f3147fc744468997ac", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Encoder ===\n\nAn encoder consists of an embedding layer, followed by multiple encoder layers.\nEach encoder layer consists of two major components: a self-attention mechanism and a feed-forward layer. It takes an input as a sequence of input vectors, applies the self-attention mechanism, to produce an intermediate sequence of vectors, then applies the feed-forward layer for each vector individually. Schematically, we have:\n  \n    \n      \n        \n          \n            \n              \n                \n                  given input vectors \n                \n              \n              \n                \n                  h\n                  \n                    0\n                  \n                \n                ,\n                \n                  h\n                  \n                    1\n                  \n                \n                ,\n                \u2026\n              \n            \n            \n              \n                \n                  combine them into a matrix \n                \n                H\n              \n              \n                \n                =\n                \n                  \n                    [\n                    \n                      \n                        \n                          \n                            h\n                            \n                              0\n                            \n                          \n                        \n                      \n                      \n                        \n                          \n                            h\n                            \n                              1\n                            \n                          \n                        \n                      \n                      \n                        \n                          \u22ee\n                        \n                      \n                    \n                    ]\n                  \n                \n              \n            \n            \n              \n                \n                  EncoderLayer\n                \n                (\n                H\n                )\n              \n              \n                \n                =\n                \n                  \n                    [\n                    \n                      \n                        \n                          \n                            FFN\n                          \n                          (\n                          \n                            MultiheadedAttention\n                          \n                          (\n                          H\n                          ,\n                          H\n                          ,\n                          H\n                          \n                            )\n                            \n                              0\n                            \n                          \n                          )\n                        \n                      \n                      \n                        \n                          \n                            FFN\n                          \n                          (\n                          \n                            MultiheadedAttention\n                          \n                          (\n                          H\n                          ,\n                          H\n                          ,\n                          H\n                          \n                            )\n                            \n                              1\n                            \n                          \n                          )\n                        \n                      \n                      \n                        \n                          \u22ee\n                        \n                      \n                    \n                    ]\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}{\\text{given input vectors }}&h_{0},h_{1},\\dots \\\\{\\text{combine them into a matrix }}H&={\\begin{bmatrix}h_{0}\\\\h_{1}\\\\\\vdots \\end{bmatrix}}\\\\{\\text{EncoderLayer}}(H)&={\\begin{bmatrix}{\\text{FFN}}({\\text{MultiheadedAttention}}(H,H,H)_{0})\\\\{\\text{FFN}}({\\text{MultiheadedAttention}}(H,H,H)_{1})\\\\\\vdots \\end{bmatrix}}\\\\\\end{aligned}}}\n  \n\nwhere \n  \n    \n      \n        \n          FFN\n        \n      \n    \n    {\\displaystyle {\\text{FFN}}}\n  \n stands for \"feed-forward network\". We can more succinctly write it as\n  \n    \n      \n        \n          EncoderLayer\n        \n        (\n        H\n        )\n        =\n        \n          FFN\n        \n        (\n        \n          MultiheadedAttention\n        \n        (\n        H\n        ,\n        H\n        ,\n        H\n        )\n        )\n      \n    \n    {\\displaystyle {\\text{EncoderLayer}}(H)={\\text{FFN}}({\\text{MultiheadedAttention}}(H,H,H))}\n  \nwith the implicit convention that the \n  \n    \n      \n        \n          FFN\n        \n      \n    \n    {\\displaystyle {\\text{FFN}}}\n  \n is applied to each row of the matrix individually.\nThe encoder layers are stacked. The first encoder layer takes the sequence of input vectors from the embedding layer, producing a sequence of vectors. This sequence of vectors is processed by the second encoder, and so on. The output from the final encoder layer is then used by the decoder.\nAs the encoder processes the entire input all at once, every token can attend to every other token (all-to-all attention), so there is no need for causal masking.", "mimetype": "text/plain", "start_char_idx": 49381, "end_char_idx": 54812, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f285ebfe-fe9f-4e85-91a7-d61981c83929": {"__data__": {"id_": "f285ebfe-fe9f-4e85-91a7-d61981c83929", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61603971", "node_type": "4", "metadata": {}, "hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f066afd2-28bb-40db-970b-3396b82b1c81", "node_type": "1", "metadata": {}, "hash": "52baa33aadf139b97f43063d1fb947ee848fb09446f533cf46ac3544ea2801f5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "192fb953-5dfd-4cef-8bc9-d69e9c31cd7c", "node_type": "1", "metadata": {}, "hash": "3467b58d67e82ab5fca9954ca8a55814bdf304dc0b98c50bb3b4a3f0291dc061", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Decoder ===\n\nA decoder consists of an embedding layer, followed by multiple decoder layers, followed by an un-embedding layer.\nEach decoder consists of three major components: a causally masked self-attention mechanism, a cross-attention mechanism, and a feed-forward neural network. The decoder functions in a similar fashion to the encoder, but an additional attention mechanism is inserted which instead draws relevant information from the encodings generated by the encoders. This mechanism can also be called the encoder-decoder attention.\nLike the first encoder, the first decoder takes positional information and embeddings of the output sequence as its input, rather than encodings. The transformer must not use the current or future output to predict an output, so the output sequence must be partially masked to prevent this reverse information flow. This allows for autoregressive text generation. For decoding, all-to-all attention is inappropriate, because a token cannot attend to tokens not yet generated. Thus, the self-attention module in the decoder is causally masked.\nIn contrast, the cross-attention mechanism attends to the output vectors of the encoder, which is computed before the decoder starts decoding. Consequently, there is no need for masking in the cross-attention mechanism.\nSchematically, we have:\n  \n    \n      \n        \n          \n            \n              \n                \n                  H\n                  \u2032\n                \n              \n              \n                \n                =\n                \n                  MaskedMultiheadedAttention\n                \n                (\n                H\n                ,\n                H\n                ,\n                H\n                )\n              \n            \n            \n              \n                \n                  DecoderLayer\n                \n                (\n                H\n                )\n              \n              \n                \n                =\n                \n                  FFN\n                \n                (\n                \n                  MultiheadedAttention\n                \n                (\n                \n                  H\n                  \u2032\n                \n                ,\n                \n                  H\n                  \n                    E\n                  \n                \n                ,\n                \n                  H\n                  \n                    E\n                  \n                \n                )\n                )\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}H'&={\\text{MaskedMultiheadedAttention}}(H,H,H)\\\\{\\text{DecoderLayer}}(H)&={\\text{FFN}}({\\text{MultiheadedAttention}}(H',H^{E},H^{E}))\\end{aligned}}}\n  \nwhere \n  \n    \n      \n        \n          H\n          \n            E\n          \n        \n      \n    \n    {\\displaystyle H^{E}}\n  \n is the matrix with rows being the output vectors from the encoder.\nThe last decoder is followed by a final un-embedding layer. to produce the output probabilities over the vocabulary. Then, one of the tokens is sampled according to the probability, and the decoder can be run again to produce the next token, etc, autoregressively generating output text.\n\n\n=== Adapted architectures ===\nMany large language models, since they do not need to predict a whole new sequence from an input sequence, only use the encoder or decoder of the original transformer architecture. Early GPT models are decoder-only models trained to predict the next token in a sequence. BERT, another language model, only makes use of an encoder, and is trained to predict a randomly masked token in a sequence.\n\n\n== Full transformer architecture ==", "mimetype": "text/plain", "start_char_idx": 54815, "end_char_idx": 58534, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "192fb953-5dfd-4cef-8bc9-d69e9c31cd7c": {"__data__": {"id_": "192fb953-5dfd-4cef-8bc9-d69e9c31cd7c", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61603971", "node_type": "4", "metadata": {}, "hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f285ebfe-fe9f-4e85-91a7-d61981c83929", "node_type": "1", "metadata": {}, "hash": "0106f513bde97d96be03790d74919e5cd5942a5201ef40f3147fc744468997ac", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2831b82a-0486-43d0-82d9-7a8c3fd34ffd", "node_type": "1", "metadata": {}, "hash": "c6568f5755cfb0122dc20ec898d1f49d062447ba805dc6cd391eac189d9b6faa", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Adapted architectures ===\nMany large language models, since they do not need to predict a whole new sequence from an input sequence, only use the encoder or decoder of the original transformer architecture. Early GPT models are decoder-only models trained to predict the next token in a sequence. BERT, another language model, only makes use of an encoder, and is trained to predict a randomly masked token in a sequence.\n\n\n== Full transformer architecture ==\n\n\n=== Sublayers ===\nEach encoder layer contains 2 sublayers: the self-attention and the feedforward network. Each decoder layer contains 3 sublayers: the causally masked self-attention, the cross-attention, and the feedforward network.\n\nThe final points of detail are the residual connections and layer normalization (LayerNorm, or LN), which while conceptually unnecessary, are necessary for numerical stability and convergence.\nThe residual connection, which is introduced to avoid vanishing gradient issues and stabilize the training process, can be expressed as follows: y = F(x) + x. The expression indicates that an output y is the sum of the transformation of input x (F(x)) and the input itself (x). Adding the input x can preserve the input information and avoid issues when the gradient of F(x) is close to zero.\nSimilarly to how the feedforward network modules are applied individually to each vector, the LayerNorm is also applied individually to each vector.\nThere are two common conventions in use: the post-LN and the pre-LN convention. In the post-LN convention, the output of each sublayer is \n  \n    \n      \n        \n          L\n          a\n          y\n          e\n          r\n          N\n          o\n          r\n          m\n        \n        (\n        x\n        +\n        \n          S\n          u\n          b\n          l\n          a\n          y\n          e\n          r\n        \n        (\n        x\n        )\n        )\n      \n    \n    {\\displaystyle \\mathrm {LayerNorm} (x+\\mathrm {Sublayer} (x))}\n  \nwhere \n  \n    \n      \n        \n          S\n          u\n          b\n          l\n          a\n          y\n          e\n          r\n        \n        (\n        x\n        )\n      \n    \n    {\\displaystyle \\mathrm {Sublayer} (x)}\n  \n is the function implemented by the sublayer itself.\nIn the pre-LN convention, the output of each sublayer is\n  \n    \n      \n        x\n        +\n        \n          S\n          u\n          b\n          l\n          a\n          y\n          e\n          r\n        \n        (\n        \n          L\n          a\n          y\n          e\n          r\n          N\n          o\n          r\n          m\n        \n        (\n        x\n        )\n        )\n      \n    \n    {\\displaystyle x+\\mathrm {Sublayer} (\\mathrm {LayerNorm} (x))}\n  \nThe original 2017 Transformer used the post-LN convention. It was difficult to train and required careful hyperparameter tuning and a \"warm-up\" in learning rate, where it starts small and gradually increases. The pre-LN convention, proposed several times in 2018, was found to be easier to train, requiring no warm-up, leading to faster convergence.", "mimetype": "text/plain", "start_char_idx": 58071, "end_char_idx": 61143, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2831b82a-0486-43d0-82d9-7a8c3fd34ffd": {"__data__": {"id_": "2831b82a-0486-43d0-82d9-7a8c3fd34ffd", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61603971", "node_type": "4", "metadata": {}, "hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "192fb953-5dfd-4cef-8bc9-d69e9c31cd7c", "node_type": "1", "metadata": {}, "hash": "3467b58d67e82ab5fca9954ca8a55814bdf304dc0b98c50bb3b4a3f0291dc061", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5c7864b7-7e73-480b-abc7-0f32a4ba58b4", "node_type": "1", "metadata": {}, "hash": "a5e9d871b1a2de43e695f9527082796a83c7f0396508301bb05dbb18948616c0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Pseudocode ===\nThe following is the pseudocode for a standard pre-LN encoder-decoder Transformer, adapted from\n\ninput: Encoder input t_e\n       Decoder input t_d\noutput: Array of probability distributions, with shape (decoder vocabulary size x length(decoder output sequence))\n\n/* encoder */\nz_e \u2190 encoder.tokenizer(t_e)\n\nfor each t in 1:length(z_e) do\n    z_e[t] \u2190 encoder.embedding(z_e[t]) + encoder.positional_embedding(t)\n\nfor each l in 1:length(encoder.layers) do\n    layer \u2190 encoder.layers[l]\n\n    /* first sublayer */\n    z_e_copy \u2190 copy(z_e)\n    for each t in 1:length(z_e) do\n        z_e[t] \u2190 layer.layer_norm(z_e[t])\n    z_e \u2190 layer.multiheaded_attention(z_e, z_e, z_e)\n    for each t in 1:length(z_e) do\n        z_e[t] \u2190 z_e[t] + z_e_copy[t]\n\n    /* second sublayer */\n    z_e_copy \u2190 copy(z_e)\n    for each t in 1:length(z_e) do\n        z_e[t] \u2190 layer.layer_norm(z_e[t])\n    z_e \u2190 layer.feedforward(z_e)\n    for each t in 1:length(z_e) do\n        z_e[t] \u2190 z_e[t] + z_e_copy[t]\n\nfor each t in 1:length(z_e) do\n    z_e[t] \u2190 encoder.final_layer_norm(z_e[t])\n\n/* decoder */\nz_d \u2190 decoder.tokenizer(t_d)\n\nfor each t in 1:length(z_d) do\n    z_d[t] \u2190 decoder.embedding(z_d[t]) + decoder.positional_embedding(t)\n\nfor each l in 1:length(decoder.layers) do\n        layer \u2190 decoder.layers[l]\n\n        /* first sublayer */\n        z_d_copy \u2190 copy(z_d)\n        for each t in 1:length(z_d) do\n            z_d[t] \u2190 layer.layer_norm(z_d[t])\n        z_d \u2190 layer.masked_multiheaded_attention(z_d, z_d, z_d)\n        for each t in 1:length(z_d) do\n            z_d[t] \u2190 z_d[t] + z_d_copy[t]\n\n        /* second sublayer */\n        z_d_copy \u2190 copy(z_d)\n        for each t in 1:length(z_d) do\n            z_d[t] \u2190 layer.layer_norm(z_d[t])\n        z_d \u2190 layer.multiheaded_attention(z_d, z_e, z_e) \n        for each i in 1:length(z_d) do\n            z_d[t] \u2190 z_d[t] + z_d_copy[t]\n\n        /* third sublayer */\n        z_d_copy \u2190 copy(z_d)\n        for each t in 1:length(z_d) do\n            z_d[t] \u2190 layer.layer_norm(z_d[t])\n        z_d \u2190 layer.feedforward(z_d)\n        for each t in 1:length(z_d) do\n            z_d[t] \u2190 z_d[t] + z_d_copy[t]\n\nz_d \u2190 decoder.final_layer_norm(z_d)\n\noutput_distributions \u2190 []\nfor each t in 1:length(z_d) do\n    output_distributions.append(decoder.unembed(z_d[t]))\n\nreturn output_distributions", "mimetype": "text/plain", "start_char_idx": 61146, "end_char_idx": 63457, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5c7864b7-7e73-480b-abc7-0f32a4ba58b4": {"__data__": {"id_": "5c7864b7-7e73-480b-abc7-0f32a4ba58b4", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61603971", "node_type": "4", "metadata": {}, "hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2831b82a-0486-43d0-82d9-7a8c3fd34ffd", "node_type": "1", "metadata": {}, "hash": "c6568f5755cfb0122dc20ec898d1f49d062447ba805dc6cd391eac189d9b6faa", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c6f0df42-7971-4899-bc01-80df1d0d4437", "node_type": "1", "metadata": {}, "hash": "18632a3aff013e0b83cb2cea42e1d305c2845c150dc015c35425f2f59d640332", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Terminology ===\nThe Transformer architecture, being modular, allows variations. Several common variations are described here.\nAn \"encoder-only\" Transformer applies the encoder to map an input text into a sequence of vectors that represent the input text. This is usually used for text embedding and representation learning for downstream applications. BERT is encoder-only. They are less often used currently, as they were found to be not significantly better than training an encoder-decoder Transformer, then taking just the encoder.\nA \"decoder-only\" Transformer is not literally decoder-only, since without an encoder, the cross-attention mechanism has nothing to attend to. Thus, the decoder layers in a decoder-only Transformer is composed of just two sublayers: the causally masked self-attention, and the feedforward network. This is usually used for text generation and instruction following. The models in the GPT series and Chinchilla series are decoder-only.\nAn \"encoder-decoder\" Transformer is generally the same as the original Transformer, with 2 sublayers per encoder layer and 3 sublayers per decoder layer, etc. They might have minor architectural improvements, such as alternative activation functions, changing the location of normalization, etc. This is also usually used for text generation and instruction following. The models in the T5 series are encoder-decoder.\nA \"prefixLM\" (prefix language model) is a decoder-only architecture, but with prefix masking, which is different from causal masking. Specifically, it has mask of the form:\u200aFigure 3\u200a\n  \n    \n      \n        \n          M\n          \n            prefixLM\n          \n        \n        =\n        \n          \n            [\n            \n              \n                \n                  \n                    0\n                  \n                \n                \n                  \u2212\n                  \u221e\n                \n              \n              \n                \n                  \n                    0\n                  \n                \n                \n                  \n                    M\n                    \n                      causal\n                    \n                  \n                \n              \n            \n            ]\n          \n        \n      \n    \n    {\\displaystyle M_{\\text{prefixLM}}={\\begin{bmatrix}\\mathbf {0} &-\\infty \\\\\\mathbf {0} &M_{\\text{causal}}\\end{bmatrix}}}\n  \nwhere the first columns correspond to the \"prefix\", and the subsequent columns correspond to the autoregressively generated text based on the prefix. They resemble encoder-decoder models, but has less \"sparsity\". Such models are rarely used, though they are cited as theoretical possibilities and benchmarked comparisons.\nThere are also mixed seq2seq models. For example, in 2020, Google Translate replaced the previous RNN-encoder\u2013RNN-decoder model by a Transformer-encoder\u2013RNN-decoder model, on the argument that an RNN-decoder runs much faster than Transformer-decoder when run autoregressively.\n\n\n== Subsequent work ==\n\n\n=== Alternative activation functions ===\nThe original transformer uses ReLU activation function. Other activation functions were developed. The Llama series and PaLM used SwiGLU; both GPT-1 and BERT used GELU.\nAlternative activation functions are often used in combination with Gated Linear Units in the feedforward module.\n\n\n=== Alternative normalizations ===\nThe normalization used in the Transformer can be different from LayerNorm. One example is RMSNorm which is used in the Llama series. Other examples include CapsuleNorm ScaleNorm, or FixNorm.\n\n\n=== Alternative positional encodings ===\nTransformers may use other positional encoding methods than sinusoidal.\nThe original Transformer paper reported using a learned positional encoding, but finding it not superior to the sinusoidal one. Later, found that causal masking itself provides enough signal to a Transformer decoder that it can learn to implicitly perform absolute positional encoding without the positional encoding module.\n\n\n==== RoPE ====\nRoPE (rotary positional embedding), is best explained by considering a list of 2-dimensional vectors \n  \n    \n      \n        [\n        (\n        \n          x\n          \n            1\n          \n          \n            (\n            1\n            )\n          \n        \n        ,\n        \n          x\n          \n            1\n          \n          \n            (\n            2\n            )\n          \n        \n        )\n        ,\n        (\n        \n          x\n          \n            2\n          \n          \n            (\n            1\n            )\n          \n        \n        ,\n        \n          x\n          \n            2\n          \n          \n            (\n            2\n            )\n          \n        \n        )\n        ,\n        (\n        \n          x\n          \n            3\n          \n          \n            (\n            1\n            )\n          \n        \n        ,\n        \n          x\n          \n            3\n          \n          \n            (\n            2\n            )\n          \n        \n        )\n        ,\n        .\n        .\n        .\n        ]\n      \n    \n    {\\displaystyle [(x_{1}^{(1)},x_{1}^{(2)}),(x_{2}^{(1)},x_{2}^{(2)}),(x_{3}^{(1)},x_{3}^{(2)}),...]}\n  \n. Now pick some angle \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n  \n.", "mimetype": "text/plain", "start_char_idx": 63460, "end_char_idx": 68765, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c6f0df42-7971-4899-bc01-80df1d0d4437": {"__data__": {"id_": "c6f0df42-7971-4899-bc01-80df1d0d4437", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61603971", "node_type": "4", "metadata": {}, "hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5c7864b7-7e73-480b-abc7-0f32a4ba58b4", "node_type": "1", "metadata": {}, "hash": "a5e9d871b1a2de43e695f9527082796a83c7f0396508301bb05dbb18948616c0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3425bb88-fbf3-41e6-bb0e-e155241c50bf", "node_type": "1", "metadata": {}, "hash": "f8e6abac10d4823dfeeb5e25b80caeaeda9c2a3fdd1fbc4b407de871d25ae0d7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": ".\n        .\n        ]\n      \n    \n    {\\displaystyle [(x_{1}^{(1)},x_{1}^{(2)}),(x_{2}^{(1)},x_{2}^{(2)}),(x_{3}^{(1)},x_{3}^{(2)}),...]}\n  \n. Now pick some angle \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n  \n. Then RoPE encoding is\n  \n    \n      \n        \n          RoPE\n        \n        \n          \n            (\n          \n        \n        \n          x\n          \n            m\n          \n          \n            (\n            1\n            )\n          \n        \n        ,\n        \n          x\n          \n            m\n          \n          \n            (\n            2\n            )\n          \n        \n        ,\n        m\n        \n          \n            )\n          \n        \n        =\n        \n          \n            (\n            \n              \n                \n                  cos\n                  \u2061\n                  m\n                  \u03b8\n                \n                \n                  \u2212\n                  sin\n                  \u2061\n                  m\n                  \u03b8\n                \n              \n              \n                \n                  sin\n                  \u2061\n                  m\n                  \u03b8\n                \n                \n                  cos\n                  \u2061\n                  m\n                  \u03b8\n                \n              \n            \n            )\n          \n        \n        \n          \n            (\n            \n              \n                \n                  \n                    x\n                    \n                      m\n                    \n                    \n                      (\n                      1\n                      )\n                    \n                  \n                \n              \n              \n                \n                  \n                    x\n                    \n                      m\n                    \n                    \n                      (\n                      2\n                      )\n                    \n                  \n                \n              \n            \n            )\n          \n        \n        =\n        \n          \n            (\n            \n              \n                \n                  \n                    x\n                    \n                      m\n                    \n                    \n                      (\n                      1\n                      )\n                    \n                  \n                  cos\n                  \u2061\n                  m\n                  \u03b8\n                  \u2212\n                  \n                    x\n                    \n                      m\n                    \n                    \n                      (\n                      2\n                      )\n                    \n                  \n                  sin\n                  \u2061\n                  m\n                  \u03b8\n                \n              \n              \n                \n                  \n                    x\n                    \n                      m\n                    \n                    \n                      (\n                      2\n                      )\n                    \n                  \n                  cos\n                  \u2061\n                  m\n                  \u03b8\n                  +\n                  \n                    x\n                    \n                      m\n                    \n                    \n                      (\n                      1\n                      )\n                    \n                  \n                  sin\n                  \u2061\n                  m\n                  \u03b8\n                \n              \n            \n            )\n          \n        \n      \n    \n    {\\displaystyle {\\text{RoPE}}{\\big (}x_{m}^{(1)},x_{m}^{(2)},m{\\big )}={\\begin{pmatrix}\\cos m\\theta &-\\sin m\\theta \\\\\\sin m\\theta &\\cos m\\theta \\end{pmatrix}}{\\begin{pmatrix}x_{m}^{(1)}\\\\x_{m}^{(2)}\\\\\\end{pmatrix}}={\\begin{pmatrix}x_{m}^{(1)}\\cos m\\theta -x_{m}^{(2)}\\sin m\\theta \\\\x_{m}^{(2)}\\cos m\\theta +x_{m}^{(1)}\\sin m\\theta \\\\\\end{pmatrix}}}\n  \nEquivalently, if we write the 2-dimensional vectors as complex numbers \n  \n    \n      \n        \n          z\n          \n            m\n          \n        \n        :=\n        \n          x\n          \n            m\n          \n          \n            (\n            1\n            )\n          \n        \n        +\n        i\n        \n          x\n          \n            m\n          \n          \n            (\n            2\n            )\n          \n        \n      \n    \n    {\\displaystyle z_{m}:=x_{m}^{(1)}+ix_{m}^{(2)}}\n  \n, then RoPE encoding is just multiplication by an angle:\n  \n    \n      \n        \n          RoPE\n        \n        \n          \n            (\n          \n        \n        \n          z\n          \n            m\n          \n        \n        ,\n        m\n        \n          \n            )\n          \n        \n        =\n        \n          e\n          \n            i\n            m\n            \u03b8\n          \n        \n        \n          z\n          \n            m\n          \n        \n      \n    \n    {\\displaystyle {\\text{RoPE}}{\\big (}z_{m},m{\\big )}=e^{im\\theta }z_{m}}\n  \nFor a list of \n  \n    \n      \n        2\n        n\n      \n    \n    {\\displaystyle 2n}\n  \n-dimensional vectors, a RoPE encoder is defined by a sequence of angles \n  \n    \n      \n        \n          \u03b8\n          \n            (\n            1\n            )\n          \n        \n        ,\n        .\n        .\n        .\n        ,\n        \n          \u03b8\n          \n            (\n            n\n            )\n          \n        \n      \n    \n    {\\displaystyle \\theta ^{(1)},...,\\theta ^{(n)}}\n  \n. Then the RoPE encoding is applied to each pair of coordinates.", "mimetype": "text/plain", "start_char_idx": 68532, "end_char_idx": 74127, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3425bb88-fbf3-41e6-bb0e-e155241c50bf": {"__data__": {"id_": "3425bb88-fbf3-41e6-bb0e-e155241c50bf", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61603971", "node_type": "4", "metadata": {}, "hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c6f0df42-7971-4899-bc01-80df1d0d4437", "node_type": "1", "metadata": {}, "hash": "18632a3aff013e0b83cb2cea42e1d305c2845c150dc015c35425f2f59d640332", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b7ebef3e-57cc-4301-b2c9-15108895f961", "node_type": "1", "metadata": {}, "hash": "841b94c251015bf99e38c82c6a29dd11ad8910111b4ef93cfd74361c3df78ce7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": ".\n        .\n        ,\n        \n          \u03b8\n          \n            (\n            n\n            )\n          \n        \n      \n    \n    {\\displaystyle \\theta ^{(1)},...,\\theta ^{(n)}}\n  \n. Then the RoPE encoding is applied to each pair of coordinates.\nThe benefit of RoPE is that the dot-product between two vectors depends on their relative location only:\n  \n    \n      \n        \n          RoPE\n        \n        \n          \n            (\n          \n        \n        x\n        ,\n        m\n        \n          \n            \n              )\n            \n          \n          \n            T\n          \n        \n        \n          RoPE\n        \n        \n          \n            (\n          \n        \n        y\n        ,\n        n\n        \n          \n            )\n          \n        \n        =\n        \n          RoPE\n        \n        \n          \n            (\n          \n        \n        x\n        ,\n        m\n        +\n        k\n        \n          \n            \n              )\n            \n          \n          \n            T\n          \n        \n        \n          RoPE\n        \n        \n          \n            (\n          \n        \n        y\n        ,\n        n\n        +\n        k\n        \n          \n            )\n          \n        \n      \n    \n    {\\displaystyle {\\text{RoPE}}{\\big (}x,m{\\big )}^{T}{\\text{RoPE}}{\\big (}y,n{\\big )}={\\text{RoPE}}{\\big (}x,m+k{\\big )}^{T}{\\text{RoPE}}{\\big (}y,n+k{\\big )}}\n  \n\nfor any integer \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n.", "mimetype": "text/plain", "start_char_idx": 73880, "end_char_idx": 75368, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b7ebef3e-57cc-4301-b2c9-15108895f961": {"__data__": {"id_": "b7ebef3e-57cc-4301-b2c9-15108895f961", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61603971", "node_type": "4", "metadata": {}, "hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3425bb88-fbf3-41e6-bb0e-e155241c50bf", "node_type": "1", "metadata": {}, "hash": "f8e6abac10d4823dfeeb5e25b80caeaeda9c2a3fdd1fbc4b407de871d25ae0d7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "91b78da4-0ccc-4443-89f7-645288e44c7b", "node_type": "1", "metadata": {}, "hash": "a25a82aab3b105c719bef5bc7aa75f414051e6183390781087654ce1bdeac499", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== ALiBi ====\nALiBi (Attention with Linear Biases) is not a replacement for the positional encoder on the original transformer. Instead, it is an additional positional encoder that is directly plugged into the attention mechanism. Specifically, the ALiBi attention mechanism is\n  \n    \n      \n        \n          \n            \n              \n                \n                  Attention\n                \n                (\n                Q\n                ,\n                K\n                ,\n                V\n                )\n                =\n                \n                  softmax\n                \n                \n                  (\n                  \n                    \n                      \n                        \n                          Q\n                          \n                            K\n                            \n                              \n                                T\n                              \n                            \n                          \n                        \n                        \n                          \n                            d\n                            \n                              k\n                            \n                          \n                        \n                      \n                    \n                    +\n                    s\n                    B\n                  \n                  )\n                \n                V\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}{\\text{Attention}}(Q,K,V)={\\text{softmax}}\\left({\\frac {QK^{\\mathrm {T} }}{\\sqrt {d_{k}}}}+sB\\right)V\\end{aligned}}}\n  \nHere, \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n  \n is a real number (\"scalar\"), and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  \n is the linear bias matrix defined by\n  \n    \n      \n        B\n        =\n        \n          \n            (\n            \n              \n                \n                  0\n                \n                \n                  1\n                \n                \n                  2\n                \n                \n                  3\n                \n                \n                  \u22ef\n                \n              \n              \n                \n                  \u2212\n                  1\n                \n                \n                  0\n                \n                \n                  1\n                \n                \n                  2\n                \n                \n                  \u22ef\n                \n              \n              \n                \n                  \u2212\n                  2\n                \n                \n                  \u2212\n                  1\n                \n                \n                  0\n                \n                \n                  1\n                \n                \n                  \u22ef\n                \n              \n              \n                \n                  \u2212\n                  3\n                \n                \n                  \u2212\n                  2\n                \n                \n                  \u2212\n                  1\n                \n                \n                  0\n                \n                \n                  \u22ef\n                \n              \n              \n                \n                  \u22ee\n                \n                \n                  \u22ee\n                \n                \n                  \u22ee\n                \n                \n                  \u22ee\n                \n                \n                  \u22f1\n                \n              \n            \n            )\n          \n        \n      \n    \n    {\\displaystyle B={\\begin{pmatrix}0&1&2&3&\\cdots \\\\-1&0&1&2&\\cdots \\\\-2&-1&0&1&\\cdots \\\\-3&-2&-1&0&\\cdots \\\\\\vdots &\\vdots &\\vdots &\\vdots &\\ddots \\\\\\end{pmatrix}}}\n  \nin other words, \n  \n    \n      \n        \n          B\n          \n            i\n            ,\n            j\n          \n        \n        =\n        j\n        \u2212\n        i\n      \n    \n    {\\displaystyle B_{i,j}=j-i}\n  \n. The idea being that the linear bias matrix is a softened mask. Just as \n  \n    \n      \n        0\n      \n    \n    {\\displaystyle 0}\n  \n represent full attention paid, and \n  \n    \n      \n        \u2212\n        \u221e\n      \n    \n    {\\displaystyle -\\infty }\n  \n represents no attention paid, the linear bias matrix increases attention paid in one direction and decreases attention paid in the other direction.\nALiBi allows pretraining on short context windows, then fine-tuning on longer context windows. Since it is directly plugged into the attention mechanism, it can be combined with any positional encoder that is plugged into the \"bottom\" of the entire network (which is where the sinusoidal encoder on the original transformer, as well as RoPE and many others, are located).", "mimetype": "text/plain", "start_char_idx": 75371, "end_char_idx": 80140, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "91b78da4-0ccc-4443-89f7-645288e44c7b": {"__data__": {"id_": "91b78da4-0ccc-4443-89f7-645288e44c7b", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61603971", "node_type": "4", "metadata": {}, "hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b7ebef3e-57cc-4301-b2c9-15108895f961", "node_type": "1", "metadata": {}, "hash": "841b94c251015bf99e38c82c6a29dd11ad8910111b4ef93cfd74361c3df78ce7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5c93d5ff-3b43-42ed-a8db-75bd37d6fdfe", "node_type": "1", "metadata": {}, "hash": "ab4f1a35b42d57532d1555e23c6baad93a03ebf47477f6e79e701a009d52b230", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Relative Position Encodings ====\nRelative Position Encodings is similar to ALiBi, but more generic:\n  \n    \n      \n        \n          \n            \n              \n                \n                  Attention\n                \n                (\n                Q\n                ,\n                K\n                ,\n                V\n                )\n                =\n                \n                  softmax\n                \n                \n                  (\n                  \n                    \n                      \n                        \n                          Q\n                          \n                            K\n                            \n                              \n                                T\n                              \n                            \n                          \n                        \n                        \n                          \n                            d\n                            \n                              k\n                            \n                          \n                        \n                      \n                    \n                    +\n                    B\n                  \n                  )\n                \n                V\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}{\\text{Attention}}(Q,K,V)={\\text{softmax}}\\left({\\frac {QK^{\\mathrm {T} }}{\\sqrt {d_{k}}}}+B\\right)V\\end{aligned}}}\n  \nwhere \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  \n is a Toeplitz matrix, that is, \n  \n    \n      \n        \n          B\n          \n            i\n            ,\n            j\n          \n        \n        =\n        \n          B\n          \n            \n              i\n              \u2032\n            \n            ,\n            \n              j\n              \u2032\n            \n          \n        \n      \n    \n    {\\displaystyle B_{i,j}=B_{i',j'}}\n  \n whenever \n  \n    \n      \n        i\n        \u2212\n        j\n        =\n        \n          i\n          \u2032\n        \n        \u2212\n        \n          j\n          \u2032\n        \n      \n    \n    {\\displaystyle i-j=i'-j'}\n  \n. This is contrasted with the original sinusoidal positional encoding, which is an \"absolute positional encoding\".\n\n\n=== Efficient implementation ===\nThe transformer model has been implemented in standard deep learning frameworks such as TensorFlow and PyTorch. Transformers is a library produced by Hugging Face that supplies transformer-based architectures and pretrained models.\n\n\n==== KV caching ====\nWhen an autoregressive transformer is used for inference, such as generating text, the query vector is different at each step, but the already-computed key and value vectors are always the same. The KV caching method saves the computed key and value vectors at each attention block, so that they are not recomputed at each new token. PagedAttention applies memory paging to KV caching.\nIf a transformer is used with a baked-in prompt, such as [\"You are a customer support agent...\"], then the key and value vectors can be computed for the prompt, and saved on disk. The saving in compute is significant when the model is used for many short interactions, such as in online chatbots.\n\n\n==== FlashAttention ====\nFlashAttention is an algorithm that implements the transformer attention mechanism efficiently on a GPU. It is a communication-avoiding algorithm that performs matrix multiplications in blocks, such that each block fits within the cache of a GPU, and by careful management of the blocks it minimizes data copying between GPU caches (as data movement is slow). See the page on softmax for details.\nAn improved version, FlashAttention-2, was developed to cater to the rising demand for language models capable of handling longer context lengths. It offers enhancements in work partitioning and parallelism, enabling it to achieve up to 230 TFLOPs/s on A100 GPUs (FP16/BF16), a 2x speed increase over the original FlashAttention.\nKey advancements in FlashAttention-2 include the reduction of non-matmul FLOPs, improved parallelism over the sequence length dimension, better work partitioning between GPU warps, and added support for head dimensions up to 256 and multi-query attention (MQA) and grouped-query attention (GQA).\nBenchmarks revealed FlashAttention-2 to be up to 2x faster than FlashAttention and up to 9x faster than a standard attention implementation in PyTorch. Future developments include optimization for new hardware like H100 GPUs and new data types like FP8.", "mimetype": "text/plain", "start_char_idx": 80143, "end_char_idx": 84645, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5c93d5ff-3b43-42ed-a8db-75bd37d6fdfe": {"__data__": {"id_": "5c93d5ff-3b43-42ed-a8db-75bd37d6fdfe", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61603971", "node_type": "4", "metadata": {}, "hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "91b78da4-0ccc-4443-89f7-645288e44c7b", "node_type": "1", "metadata": {}, "hash": "a25a82aab3b105c719bef5bc7aa75f414051e6183390781087654ce1bdeac499", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ab6cd1e9-83bc-4498-92b8-213d423cee17", "node_type": "1", "metadata": {}, "hash": "ab510c37fcccd1026ca466f2d5684b517cc1c591083d59c8490d4161e27d42de", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Multi-Query Attention ====\n\nMulti-Query Attention changes the multiheaded attention mechanism. Whereas normally,\n\n  \n    \n      \n        \n          MultiheadedAttention\n        \n        (\n        Q\n        ,\n        K\n        ,\n        V\n        )\n        =\n        \n          \n            Concat\n          \n          \n            i\n            \u2208\n            [\n            \n              n\n              \n                heads\n              \n            \n            ]\n          \n        \n        \n          (\n          \n            \n              Attention\n            \n            (\n            X\n            \n              W\n              \n                i\n              \n              \n                Q\n              \n            \n            ,\n            X\n            \n              W\n              \n                i\n              \n              \n                K\n              \n            \n            ,\n            X\n            \n              W\n              \n                i\n              \n              \n                V\n              \n            \n            )\n          \n          )\n        \n        \n          W\n          \n            O\n          \n        \n      \n    \n    {\\displaystyle {\\text{MultiheadedAttention}}(Q,K,V)={\\text{Concat}}_{i\\in [n_{\\text{heads}}]}\\left({\\text{Attention}}(XW_{i}^{Q},XW_{i}^{K},XW_{i}^{V})\\right)W^{O}}\n  \nwith Multi-Query Attention, there is just one \n  \n    \n      \n        \n          W\n          \n            K\n          \n        \n        ,\n        \n          W\n          \n            V\n          \n        \n      \n    \n    {\\displaystyle W^{K},W^{V}}\n  \n, thus:\n\n  \n    \n      \n        \n          MultiQueryAttention\n        \n        (\n        Q\n        ,\n        K\n        ,\n        V\n        )\n        =\n        \n          \n            Concat\n          \n          \n            i\n            \u2208\n            [\n            \n              n\n              \n                heads\n              \n            \n            ]\n          \n        \n        \n          (\n          \n            \n              Attention\n            \n            (\n            X\n            \n              W\n              \n                i\n              \n              \n                Q\n              \n            \n            ,\n            X\n            \n              W\n              \n                K\n              \n            \n            ,\n            X\n            \n              W\n              \n                V\n              \n            \n            )\n          \n          )\n        \n        \n          W\n          \n            O\n          \n        \n      \n    \n    {\\displaystyle {\\text{MultiQueryAttention}}(Q,K,V)={\\text{Concat}}_{i\\in [n_{\\text{heads}}]}\\left({\\text{Attention}}(XW_{i}^{Q},XW^{K},XW^{V})\\right)W^{O}}\n  \n\nThis has a neutral effect on model quality and training speed, but increases inference speed.\nMore generally, grouped-query attention (GQA) partitions attention heads into groups, each of which shares the key-value pair. MQA is GQA with one group, while standard multiheaded attention is GQA with the maximal number of groups.\n\nMultihead Latent Attention (MLA) is a low-rank approximation to standard MHA. Specifically, each hidden vector, before entering the attention mechanism, is first projected to two low-dimensional spaces (\"latent space\"), one for query and one for key-value (KV vector). This design minimizes the KV cache, as only the low-dimensional KV vector needs to be cached.\n\n\n==== Speculative decoding ====\nSpeculative decoding is a method to accelerate token decoding. Similarly to speculative execution in CPUs, future tokens are computed quickly, then verified. If the quickly computed tokens are incorrect, they are discarded and computed slowly.\nThe key factor in speculative decoding is that a Transformer decoder can verify faster than it can decode, in the following sense.\nSuppose we have two transformer models like GPT-3 and GPT-3-small, both with a context window size of 512. To generate an entire context window autoregressively with greedy decoding with GPT-3, it must be run for 512 times, each time generating a token \n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n        ,\n        \n          x\n          \n            2\n          \n        \n        ,\n        .\n        .\n        .\n        ,\n        \n          x\n          \n            512\n          \n        \n      \n    \n    {\\displaystyle x_{1},x_{2},...,x_{512}}\n  \n, taking time \n  \n    \n      \n        512\n        \n          T\n          \n            GPT-3\n          \n        \n      \n    \n    {\\displaystyle 512T_{\\text{GPT-3}}}\n  \n. However, if we had some educated guess for the values of these tokens, we could verify all of them in parallel, in one run of the model, by checking that each \n  \n    \n      \n        \n          x\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle x_{t}}\n  \n is indeed the token with the largest log-likelihood in the \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  \n-th output.\nIn speculative decoding, a smaller model or some other simple heuristic is used to generate a few speculative tokens that are subsequently verified by the larger model.", "mimetype": "text/plain", "start_char_idx": 84648, "end_char_idx": 89865, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ab6cd1e9-83bc-4498-92b8-213d423cee17": {"__data__": {"id_": "ab6cd1e9-83bc-4498-92b8-213d423cee17", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61603971", "node_type": "4", "metadata": {}, "hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5c93d5ff-3b43-42ed-a8db-75bd37d6fdfe", "node_type": "1", "metadata": {}, "hash": "ab4f1a35b42d57532d1555e23c6baad93a03ebf47477f6e79e701a009d52b230", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6cbd51e0-9b2d-4a5e-b1bc-2d6e0ec5319b", "node_type": "1", "metadata": {}, "hash": "5b1970be53eae7dbebd2f9cd5dc1091a69fb93c04d21838aea84485d302ccc39", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": ".\n        .\n        ,\n        \n          x\n          \n            512\n          \n        \n      \n    \n    {\\displaystyle x_{1},x_{2},...,x_{512}}\n  \n, taking time \n  \n    \n      \n        512\n        \n          T\n          \n            GPT-3\n          \n        \n      \n    \n    {\\displaystyle 512T_{\\text{GPT-3}}}\n  \n. However, if we had some educated guess for the values of these tokens, we could verify all of them in parallel, in one run of the model, by checking that each \n  \n    \n      \n        \n          x\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle x_{t}}\n  \n is indeed the token with the largest log-likelihood in the \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  \n-th output.\nIn speculative decoding, a smaller model or some other simple heuristic is used to generate a few speculative tokens that are subsequently verified by the larger model. For example, suppose we use GPT-3-small to generate four speculative tokens: \n  \n    \n      \n        \n          \n            \n              \n                x\n                ~\n              \n            \n          \n          \n            1\n          \n        \n        ,\n        \n          \n            \n              \n                x\n                ~\n              \n            \n          \n          \n            2\n          \n        \n        ,\n        \n          \n            \n              \n                x\n                ~\n              \n            \n          \n          \n            3\n          \n        \n        ,\n        \n          \n            \n              \n                x\n                ~\n              \n            \n          \n          \n            4\n          \n        \n      \n    \n    {\\displaystyle {\\tilde {x}}_{1},{\\tilde {x}}_{2},{\\tilde {x}}_{3},{\\tilde {x}}_{4}}\n  \n. This only takes \n  \n    \n      \n        4\n        \n          T\n          \n            GPT-3-small\n          \n        \n      \n    \n    {\\displaystyle 4T_{\\text{GPT-3-small}}}\n  \n. These tokens are then run through the larger GPT-3 in one go. Suppose that \n  \n    \n      \n        \n          \n            \n              \n                x\n                ~\n              \n            \n          \n          \n            1\n          \n        \n      \n    \n    {\\displaystyle {\\tilde {x}}_{1}}\n  \n and \n  \n    \n      \n        \n          \n            \n              \n                x\n                ~\n              \n            \n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle {\\tilde {x}}_{2}}\n  \n are verified by GPT-3 as what it would have picked, then those are kept, but \n  \n    \n      \n        \n          \n            \n              \n                x\n                ~\n              \n            \n          \n          \n            3\n          \n        \n      \n    \n    {\\displaystyle {\\tilde {x}}_{3}}\n  \n is not, so \n  \n    \n      \n        \n          \n            \n              \n                x\n                ~\n              \n            \n          \n          \n            3\n          \n        \n        ,\n        \n          \n            \n              \n                x\n                ~\n              \n            \n          \n          \n            4\n          \n        \n      \n    \n    {\\displaystyle {\\tilde {x}}_{3},{\\tilde {x}}_{4}}\n  \n are discarded, and GPT-3 is run on those. This would take \n  \n    \n      \n        4\n        \n          T\n          \n            GPT-3-small\n          \n        \n        +\n        3\n        \n          T\n          \n            GPT-3\n          \n        \n      \n    \n    {\\displaystyle 4T_{\\text{GPT-3-small}}+3T_{\\text{GPT-3}}}\n  \n, which might be shorter than \n  \n    \n      \n        4\n        \n          T\n          \n            GPT-3\n          \n        \n      \n    \n    {\\displaystyle 4T_{\\text{GPT-3}}}\n  \n.\nFor non-greedy decoding, similar ideas apply, except the speculative tokens are accepted or rejected stochastically, in a way that guarantees the final output distribution is the same as if speculative decoding was not used.\n\nIn Multi-Token Prediction, a single forward pass creates a final embedding vector, which then is un-embedded into a token probability. However, that vector can then be further processed by another Transformer block to predict the next token, and so on for arbitrarily many steps into the future. This trades off accuracy for speed, since each new token costs just one more Transformer block, rather than the entire stack.\n\n\n=== Sub-quadratic transformers ===\nTraining transformer-based architectures can be expensive, especially for long inputs. Many methods have been developed to attempt to address the issue. In the image domain, Swin Transformer is an efficient architecture that performs attention inside shifting windows. In the audio domain, SepTr decouples the attention in time and frequency domains. Long Range Arena (2020) is a standard benchmark for comparing the behavior of transformer architectures over long inputs.", "mimetype": "text/plain", "start_char_idx": 88962, "end_char_idx": 93920, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6cbd51e0-9b2d-4a5e-b1bc-2d6e0ec5319b": {"__data__": {"id_": "6cbd51e0-9b2d-4a5e-b1bc-2d6e0ec5319b", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61603971", "node_type": "4", "metadata": {}, "hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ab6cd1e9-83bc-4498-92b8-213d423cee17", "node_type": "1", "metadata": {}, "hash": "ab510c37fcccd1026ca466f2d5684b517cc1c591083d59c8490d4161e27d42de", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6c26c77c-b097-41f9-b8d1-08540ac7f52c", "node_type": "1", "metadata": {}, "hash": "b84b6b4dada8ce4ff66d1874c554d023289f795ecfdd3b4046db69e0079222a2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In Multi-Token Prediction, a single forward pass creates a final embedding vector, which then is un-embedded into a token probability. However, that vector can then be further processed by another Transformer block to predict the next token, and so on for arbitrarily many steps into the future. This trades off accuracy for speed, since each new token costs just one more Transformer block, rather than the entire stack.\n\n\n=== Sub-quadratic transformers ===\nTraining transformer-based architectures can be expensive, especially for long inputs. Many methods have been developed to attempt to address the issue. In the image domain, Swin Transformer is an efficient architecture that performs attention inside shifting windows. In the audio domain, SepTr decouples the attention in time and frequency domains. Long Range Arena (2020) is a standard benchmark for comparing the behavior of transformer architectures over long inputs.\n\n\n==== Alternative attention graphs ====\nThe standard attention graph is either all-to-all or causal, both of which scales as \n  \n    \n      \n        O\n        (\n        \n          N\n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle O(N^{2})}\n  \n where \n  \n    \n      \n        N\n      \n    \n    {\\displaystyle N}\n  \n is the number of tokens in a sequence.\nReformer (2020) reduces the computational load from \n  \n    \n      \n        O\n        (\n        \n          N\n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle O(N^{2})}\n  \n to \n  \n    \n      \n        O\n        (\n        N\n        ln\n        \u2061\n        N\n        )\n      \n    \n    {\\displaystyle O(N\\ln N)}\n  \n by using locality-sensitive hashing and reversible layers.\nSparse attention uses attention graphs that grows slower than \n  \n    \n      \n        O\n        (\n        \n          N\n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle O(N^{2})}\n  \n. For example, BigBird (2020) uses random small-world networks which grows as \n  \n    \n      \n        O\n        (\n        N\n        )\n      \n    \n    {\\displaystyle O(N)}\n  \n.\nOrdinary transformers require a memory size that is quadratic in the size of the context window. Attention-free transformers reduce this to a linear dependence while still retaining the advantages of a transformer by linking the key to the value.\n\n\n==== Random Feature Attention ====\nRandom Feature Attention (2021) uses Fourier random features:\n  \n    \n      \n        \u03c6\n        (\n        x\n        )\n        =\n        \n          \n            1\n            \n              D\n            \n          \n        \n        [\n        cos\n        \u2061\n        \u27e8\n        \n          w\n          \n            1\n          \n        \n        ,\n        x\n        \u27e9\n        ,\n        sin\n        \u2061\n        \u27e8\n        \n          w\n          \n            1\n          \n        \n        ,\n        x\n        \u27e9\n        ,\n        \u22ef\n        cos\n        \u2061\n        \u27e8\n        \n          w\n          \n            D\n          \n        \n        ,\n        x\n        \u27e9\n        ,\n        sin\n        \u2061\n        \u27e8\n        \n          w\n          \n            D\n          \n        \n        ,\n        x\n        \u27e9\n        \n          ]\n          \n            T\n          \n        \n      \n    \n    {\\displaystyle \\varphi (x)={\\frac {1}{\\sqrt {D}}}[\\cos \\langle w_{1},x\\rangle ,\\sin \\langle w_{1},x\\rangle ,\\cdots \\cos \\langle w_{D},x\\rangle ,\\sin \\langle w_{D},x\\rangle ]^{T}}\n  \nwhere \n  \n    \n      \n        \n          w\n          \n            1\n          \n        \n        ,\n        .\n        .\n        .\n        ,\n        \n          w\n          \n            D\n          \n        \n      \n    \n    {\\displaystyle w_{1},...,w_{D}}\n  \n are independent samples from the normal distribution \n  \n    \n      \n        N\n        (\n        0\n        ,\n        \n          \u03c3\n          \n            2\n          \n        \n        I\n        )\n      \n    \n    {\\displaystyle N(0,\\sigma ^{2}I)}\n  \n. This choice of parameters satisfy \n  \n    \n      \n        \n          E\n        \n        [\n        \u27e8\n        \u03c6\n        (\n        x\n        )\n        ,\n        \u03c6\n        (\n        y\n        )\n        \u27e9\n        ]\n        =\n        \n          e\n          \n            \u2212\n            \n              \n                \n                  \u2016\n                  x\n                  \u2212\n                  y\n                  \n                    \u2016\n                    \n                      2\n                    \n                  \n                \n                \n                  2\n                  \n                    \u03c3\n                    \n                      2\n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbb {E} [\\langle \\varphi (x),\\varphi (y)\\rangle ]=e^{-{\\frac {\\|x-y\\|^{2}}{2\\sigma ^{2}}}}}\n  \n, or \n  \n    \n      \n        \n          e\n          \n            \u27e8\n            x\n            ,", "mimetype": "text/plain", "start_char_idx": 92989, "end_char_idx": 97936, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6c26c77c-b097-41f9-b8d1-08540ac7f52c": {"__data__": {"id_": "6c26c77c-b097-41f9-b8d1-08540ac7f52c", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61603971", "node_type": "4", "metadata": {}, "hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6cbd51e0-9b2d-4a5e-b1bc-2d6e0ec5319b", "node_type": "1", "metadata": {}, "hash": "5b1970be53eae7dbebd2f9cd5dc1091a69fb93c04d21838aea84485d302ccc39", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8a2d42a2-89ee-4094-bfd5-0f2f3a9edce3", "node_type": "1", "metadata": {}, "hash": "a37057fe00d397aef43a5dc78a6bf1f7f438223ad52bbfaddc7f845a89e356ea", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This choice of parameters satisfy \n  \n    \n      \n        \n          E\n        \n        [\n        \u27e8\n        \u03c6\n        (\n        x\n        )\n        ,\n        \u03c6\n        (\n        y\n        )\n        \u27e9\n        ]\n        =\n        \n          e\n          \n            \u2212\n            \n              \n                \n                  \u2016\n                  x\n                  \u2212\n                  y\n                  \n                    \u2016\n                    \n                      2\n                    \n                  \n                \n                \n                  2\n                  \n                    \u03c3\n                    \n                      2\n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbb {E} [\\langle \\varphi (x),\\varphi (y)\\rangle ]=e^{-{\\frac {\\|x-y\\|^{2}}{2\\sigma ^{2}}}}}\n  \n, or \n  \n    \n      \n        \n          e\n          \n            \u27e8\n            x\n            ,\n            y\n            \u27e9\n            \n              /\n            \n            \n              \u03c3\n              \n                2\n              \n            \n          \n        \n        =\n        \n          E\n        \n        [\n        \u27e8\n        \n          e\n          \n            \u2016\n            x\n            \n              \u2016\n              \n                2\n              \n            \n            \n              /\n            \n            2\n            \n              \u03c3\n              \n                2\n              \n            \n          \n        \n        \u03c6\n        (\n        x\n        )\n        ,\n        \n          e\n          \n            \u2016\n            y\n            \n              \u2016\n              \n                2\n              \n            \n            \n              /\n            \n            2\n            \n              \u03c3\n              \n                2\n              \n            \n          \n        \n        \u03c6\n        (\n        y\n        )\n        \u27e9\n        ]\n        \u2248\n        \u27e8\n        \n          e\n          \n            \u2016\n            x\n            \n              \u2016\n              \n                2\n              \n            \n            \n              /\n            \n            2\n            \n              \u03c3\n              \n                2\n              \n            \n          \n        \n        \u03c6\n        (\n        x\n        )\n        ,\n        \n          e\n          \n            \u2016\n            y\n            \n              \u2016\n              \n                2\n              \n            \n            \n              /\n            \n            2\n            \n              \u03c3\n              \n                2\n              \n            \n          \n        \n        \u03c6\n        (\n        y\n        )\n        \u27e9\n      \n    \n    {\\displaystyle e^{\\langle x,y\\rangle /\\sigma ^{2}}=\\mathbb {E} [\\langle e^{\\|x\\|^{2}/2\\sigma ^{2}}\\varphi (x),e^{\\|y\\|^{2}/2\\sigma ^{2}}\\varphi (y)\\rangle ]\\approx \\langle e^{\\|x\\|^{2}/2\\sigma ^{2}}\\varphi (x),e^{\\|y\\|^{2}/2\\sigma ^{2}}\\varphi (y)\\rangle }\n  \nConsequently, the one-headed attention, with one query, can be written as \n  \n    \n      \n        \n          Attention\n        \n        (\n        q\n        ,\n        K\n        ,\n        V\n        )\n        =\n        \n          softmax\n        \n        \n          (\n          \n            \n              \n                q\n                \n                  K\n                  \n                    \n                      T\n                    \n                  \n                \n              \n              \n                \n                  d\n                  \n                    k\n                  \n                \n              \n            \n          \n          )\n        \n        V\n        \u2248\n        \n          \n            \n              \u03c6\n              (\n              q\n              \n                )\n                \n                  T\n                \n              \n              \n                \u2211\n                \n                  i\n                \n              \n              \n                e\n                \n                  \u2016\n                  \n                    k\n                    \n                      i\n                    \n                  \n                  \n                    \u2016\n                    \n                      2\n                    \n                  \n                  \n                    /\n                  \n                  2\n                  \n                    \u03c3\n                    \n                      2\n                    \n                  \n                \n              \n              \u03c6\n              (\n              \n                k\n                \n                  i\n                \n              \n              )\n              \n                v\n                \n                  i\n                \n                \n                  T\n                \n              \n            \n            \n              \u03c6\n              (\n              q\n              \n                )\n                \n                  T\n                \n              \n              \n                \u2211\n                \n                  i\n                \n              \n              \n                e\n                \n                  \u2016\n                  \n                    k\n                    \n                      i\n                    \n                  \n                  \n                    \u2016\n                    \n                      2\n                    \n                  \n                  \n                    /\n                  \n                  2\n                  \n                    \u03c3\n                    \n                      2\n                    \n                  \n                \n              \n              \u03c6\n              (\n              \n                k\n                \n                  i\n                \n              \n              )\n            \n          \n        \n      \n    \n    {\\displaystyle {\\text{Attention}}(q,K,", "mimetype": "text/plain", "start_char_idx": 96950, "end_char_idx": 102877, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8a2d42a2-89ee-4094-bfd5-0f2f3a9edce3": {"__data__": {"id_": "8a2d42a2-89ee-4094-bfd5-0f2f3a9edce3", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61603971", "node_type": "4", "metadata": {}, "hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6c26c77c-b097-41f9-b8d1-08540ac7f52c", "node_type": "1", "metadata": {}, "hash": "b84b6b4dada8ce4ff66d1874c554d023289f795ecfdd3b4046db69e0079222a2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cd60046a-9e9e-4e59-8541-1d83db84b525", "node_type": "1", "metadata": {}, "hash": "e77522ce962d6abaa7237570c5f4c0d869824cc777e4c437bdf606419a5babbb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "K,V)={\\text{softmax}}\\left({\\frac {qK^{\\mathrm {T} }}{\\sqrt {d_{k}}}}\\right)V\\approx {\\frac {\\varphi (q)^{T}\\sum _{i}e^{\\|k_{i}\\|^{2}/2\\sigma ^{2}}\\varphi (k_{i})v_{i}^{T}}{\\varphi (q)^{T}\\sum _{i}e^{\\|k_{i}\\|^{2}/2\\sigma ^{2}}\\varphi (k_{i})}}}\n  \nwhere \n  \n    \n      \n        \u03c3\n        =\n        \n          d\n          \n            K\n          \n          \n            1\n            \n              /\n            \n            4\n          \n        \n      \n    \n    {\\displaystyle \\sigma =d_{K}^{1/4}}\n  \n. Similarly for multiple queries, and for multiheaded attention.\nThis approximation can be computed in linear time, as we can compute the matrix \n  \n    \n      \n        \u03c6\n        (\n        \n          k\n          \n            i\n          \n        \n        )\n        \n          v\n          \n            i\n          \n          \n            T\n          \n        \n      \n    \n    {\\displaystyle \\varphi (k_{i})v_{i}^{T}}\n  \n first, then multiply it with the query. In essence, we have managed to obtain a more precise version of \n  \n    \n      \n        \n          Attention\n        \n        (\n        Q\n        ,\n        K\n        ,\n        V\n        )\n        =\n        \n          softmax\n        \n        \n          (\n          \n            \n              \n                Q\n                \n                  K\n                  \n                    \n                      T\n                    \n                  \n                \n              \n              \n                \n                  d\n                  \n                    k\n                  \n                \n              \n            \n          \n          )\n        \n        V\n        \u2248\n        Q\n        (\n        \n          K\n          \n            T\n          \n        \n        V\n        \n          /\n        \n        \n          \n            \n              d\n              \n                k\n              \n            \n          \n        \n        )\n      \n    \n    {\\displaystyle {\\text{Attention}}(Q,K,V)={\\text{softmax}}\\left({\\frac {QK^{\\mathrm {T} }}{\\sqrt {d_{k}}}}\\right)V\\approx Q(K^{T}V/{\\sqrt {d_{k}}})}\n  \nPerformer (2022) uses the same Random Feature Attention, but \n  \n    \n      \n        \n          w\n          \n            1\n          \n        \n        ,\n        .\n        .\n        .\n        ,\n        \n          w\n          \n            D\n          \n        \n      \n    \n    {\\displaystyle w_{1},...,w_{D}}\n  \n are first independently sampled from the normal distribution \n  \n    \n      \n        N\n        (\n        0\n        ,\n        \n          \u03c3\n          \n            2\n          \n        \n        I\n        )\n      \n    \n    {\\displaystyle N(0,\\sigma ^{2}I)}\n  \n, then they are Gram-Schmidt processed.", "mimetype": "text/plain", "start_char_idx": 102875, "end_char_idx": 105572, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cd60046a-9e9e-4e59-8541-1d83db84b525": {"__data__": {"id_": "cd60046a-9e9e-4e59-8541-1d83db84b525", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61603971", "node_type": "4", "metadata": {}, "hash": "3cb976228c362efdb0c4ca9f0eb4296844fdae3d9ac3316198abd3c6fcff2655", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8a2d42a2-89ee-4094-bfd5-0f2f3a9edce3", "node_type": "1", "metadata": {}, "hash": "a37057fe00d397aef43a5dc78a6bf1f7f438223ad52bbfaddc7f845a89e356ea", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": ".\n        .\n        ,\n        \n          w\n          \n            D\n          \n        \n      \n    \n    {\\displaystyle w_{1},...,w_{D}}\n  \n are first independently sampled from the normal distribution \n  \n    \n      \n        N\n        (\n        0\n        ,\n        \n          \u03c3\n          \n            2\n          \n        \n        I\n        )\n      \n    \n    {\\displaystyle N(0,\\sigma ^{2}I)}\n  \n, then they are Gram-Schmidt processed.\n\n\n=== Multimodality ===\nTransformers can also be used/adapted for modalities (input or output) beyond just text, usually by finding a way to \"tokenize\" the modality.\nMultimodal models can either be trained from scratch, or by finetuning. A 2022 study found that Transformers pretrained only on natural language can be finetuned on only 0.03% of parameters and become competitive with LSTMs on a variety of logical and visual tasks, demonstrating transfer learning. The LLaVA was a vision-language model composed of a language model (Vicuna-13B) and a vision model (ViT-L/14), connected by a linear layer. Only the linear layer is finetuned.\nVision transformers adapt the transformer to computer vision by breaking down input images as a series of patches, turning them into vectors, and treating them like tokens in a standard transformer.\nConformer and later Whisper follow the same pattern for speech recognition, first turning the speech signal into a spectrogram, which is then treated like an image, i.e. broken down into a series of patches, turned into vectors and treated like tokens in a standard transformer.\nPerceivers are a variant of Transformers designed for multimodality.\nFor image generation, notable architectures are DALL-E 1 (2021), Parti (2022), Phenaki (2023), and Muse (2023). Unlike later models, DALL-E is not a diffusion model. Instead, it uses a decoder-only Transformer that autoregressively generates a text, followed by the token representation of an image, which is then converted by a variational autoencoder to an image. Parti is an encoder-decoder Transformer, where the encoder processes a text prompt, and the decoder generates a token representation of an image. Muse is an encoder-only Transformer that is trained to predict masked image tokens from unmasked image tokens. During generation, all input tokens are masked, and the highest-confidence predictions are included for the next iteration, until all tokens are predicted. Phenaki is a text-to-video model. It is a bidirectional masked transformer conditioned on pre-computed text tokens. The generated tokens are then decoded to a video.\n\n\n== Applications ==\nThe transformer has had great success in natural language processing (NLP). Many large language models such as GPT-2, GPT-3, GPT-4, Gemini, AlbertAGPT, Claude, BERT, Grok, XLNet, RoBERTa and ChatGPT demonstrate the ability of transformers to perform a wide variety of NLP-related subtasks and their related real-world applications, including:\n\nmachine translation\ntime series prediction\ndocument summarization\ndocument generation\nnamed entity recognition (NER)\nwriting computer code based on requirements expressed in natural language.\nspeech-to-text\nBeyond traditional NLP, the transformer architecture has had success in other applications, such as:\n\nbiological sequence analysis\nvideo understanding\nprotein folding (such as AlphaFold)\nevaluating chess board positions. Using static evaluation alone (that is, with no Minimax search) transformer achieved an Elo of 2895, putting it at grandmaster level.\n\n\n== See also ==\nseq2seq \u2013 Family of machine learning approaches\nPerceiver \u2013 Variant of Transformer designed for multimodal data\nVision transformer \u2013 Machine learning model for vision processing\nLarge language model \u2013 Type of machine learning model\nBERT (language model) \u2013 Series of language models developed by Google AI\nGenerative pre-trained transformer \u2013 Type of large language model\nT5 (language model) \u2013 Series of large language models developed by Google AI\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Further reading ==", "mimetype": "text/plain", "start_char_idx": 105137, "end_char_idx": 109154, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f4a269b4-1563-4c1d-b21e-b2c486b4f642": {"__data__": {"id_": "f4a269b4-1563-4c1d-b21e-b2c486b4f642", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73248112", "node_type": "4", "metadata": {}, "hash": "e3ba2797cf6c96a6f37e9f6a3de5ff204e6856b2ddd874f988c790a6a61f66dc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "45e022bb-d543-418b-b178-99dd54dbd97d", "node_type": "1", "metadata": {}, "hash": "ee8ac10c842286a258c2650a047bee7b02a6db33bf4afd8db32dcaa97bd281ce", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "A large language model (LLM) is a language model trained with self-supervised machine learning on a vast amount of text, designed for natural language processing tasks, especially language generation.\nThe largest and most capable LLMs are generative pretrained transformers (GPTs), which are largely used in generative chatbots such as ChatGPT, Gemini or Claude. LLMs can be fine-tuned for specific tasks or guided by prompt engineering. These models acquire predictive power regarding syntax, semantics, and ontologies inherent in human language corpora, but they also inherit inaccuracies and biases present in the data they are trained in.\n\n\n== History ==\n\nBefore the emergence of transformer-based models in 2017, some language models were considered large relative to the computational and data constraints of their time. In the early 1990s, IBM's statistical models pioneered word alignment techniques for machine translation, laying the groundwork for corpus-based language modeling. A smoothed n-gram model in 2001, such as those employing Kneser-Ney smoothing, trained on 300 million words achieved state-of-the-art perplexity on benchmark tests at the time. During the 2000's, with the rise of widespread internet access, researchers began compiling massive text datasets from the web (\"web as corpus\") to train statistical language models.\n\nFollowing the breakthrough of deep neural networks in image classification around 2012, similar architectures were adapted for language tasks. This shift was marked by the development of word embeddings (eg, Word2Vec by Mikolov in 2013) and sequence-to-sequence (seq2seq) models using LSTM. In 2016, Google transitioned its translation service to neural machine translation (NMT), replacing statistical phrase-based models with deep recurrent neural networks. These early NMT systems used LSTM-based encoder-decoder architectures, as they preceded the invention of transformers.\nAt the 2017 NeurIPS conference, Google researchers introduced the transformer architecture in their landmark paper \"Attention Is All You Need\". This paper's goal was to improve upon 2014 seq2seq technology, and was based mainly on the attention mechanism developed by Bahdanau et al. in 2014. The following year in 2018, BERT was introduced and quickly became \"ubiquitous\". Though the original transformer has both encoder and decoder blocks, BERT is an encoder-only model. Academic and research usage of BERT began to decline in 2023, following rapid improvements in the abilities of decoder-only models (such as GPT) to solve tasks via prompting.\nAlthough decoder-only GPT-1 was introduced in 2018, it was GPT-2 in 2019 that caught widespread attention because OpenAI claimed to have initially deemed it too powerful to release publicly, out of fear of malicious use. GPT-3 in 2020 went a step further and as of 2025 is available only via API with no offering of downloading the model to execute locally. But it was the 2022 consumer-facing chatbot ChatGPT that received extensive media coverage and public attention. The 2023 GPT-4 was praised for its increased accuracy and as a \"holy grail\" for its multimodal capabilities. OpenAI did not reveal the high-level architecture and the number of parameters of GPT-4. The release of ChatGPT led to an uptick in LLM usage across several research subfields of computer science, including robotics, software engineering, and societal impact work. In 2024 OpenAI released the reasoning model OpenAI o1, which generates long chains of thought before returning a final answer. Many LLMs with parameter counts comparable to those of OpenAI's GPT series have been developed.\nSince 2022, source-available models have been gaining popularity, especially at first with BLOOM and LLaMA, though both have restrictions on the field of use. Mistral AI's models Mistral 7B and Mixtral 8x7b have the more permissive Apache License. In January 2025, DeepSeek released DeepSeek R1, a 671-billion-parameter open-weight model that performs comparably to OpenAI o1 but at a much lower cost.\nSince 2023, many LLMs have been trained to be multimodal, having the ability to also process or generate other types of data, such as images or audio. These LLMs are also called large multimodal models (LMMs).\nAs of 2024, the largest and most capable models are all based on the transformer architecture. Some recent implementations are based on other architectures, such as recurrent neural network variants and Mamba (a state space model).\n\n\n== Dataset preprocessing ==", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4521, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "45e022bb-d543-418b-b178-99dd54dbd97d": {"__data__": {"id_": "45e022bb-d543-418b-b178-99dd54dbd97d", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73248112", "node_type": "4", "metadata": {}, "hash": "e3ba2797cf6c96a6f37e9f6a3de5ff204e6856b2ddd874f988c790a6a61f66dc", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f4a269b4-1563-4c1d-b21e-b2c486b4f642", "node_type": "1", "metadata": {}, "hash": "b9622511d85a8f775fb832b8e0d1d610eb5579a6a8f9df43fcad6426e8f16bae", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2133f949-5e6c-476c-93e9-b5b58babf676", "node_type": "1", "metadata": {}, "hash": "03a85ad17989d30a294d1e762e80f0083fe791b279ceb1a5cb88da050bec421b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Dataset preprocessing ==\n\n\n=== Tokenization ===\n\nAs machine learning algorithms process numbers rather than text, the text must be converted to numbers. In the first step, a vocabulary is decided upon, then integer indices are arbitrarily but uniquely assigned to each vocabulary entry, and finally, an embedding is associated to the integer index. Algorithms include byte-pair encoding (BPE) and WordPiece. There are also special tokens serving as control characters, such as [MASK] for masked-out token (as used in BERT), and [UNK] (\"unknown\") for characters not appearing in the vocabulary. Also, some special symbols are used to denote special text formatting. For example, \"\u0120\" denotes a preceding whitespace in RoBERTa and GPT. \"##\" denotes continuation of a preceding word in BERT.\nFor example, the BPE tokenizer used by GPT-3 (Legacy) would split tokenizer: texts -> series of numerical \"tokens\" as\n\nTokenization also compresses the datasets. Because LLMs generally require input to be an array that is not jagged, the shorter texts must be \"padded\" until they match the length of the longest one. How many tokens are, on average, needed per word depends on the language of the dataset.\n\n\n==== BPE ====\n\nAs an example, consider a tokenizer based on byte-pair encoding. In the first step, all unique characters (including blanks and punctuation marks) are treated as an initial set of n-grams (i.e. initial set of uni-grams). Successively the most frequent pair of adjacent characters is merged into a bi-gram and all instances of the pair are replaced by it. All occurrences of adjacent pairs of (previously merged) n-grams that most frequently occur together are then again merged into even lengthier n-gram, until a vocabulary of prescribed size is obtained (in case of GPT-3, the size is 50257). After a tokenizer is trained, any text can be tokenized by it, as long as it does not contain characters not appearing in the initial-set of uni-grams.\n\n\n==== Problems ====\nA token vocabulary based on the frequencies extracted from mainly English corpora uses as few tokens as possible for an average English word. However, an average word in another language encoded by such an English-optimized tokenizer is split into a suboptimal amount of tokens. GPT-2 tokenizer can use up to 15 times more tokens per word for some languages, for example for the Shan language from Myanmar. Even more widespread languages such as Portuguese and German have \"a premium of 50%\" compared to English.\nGreedy tokenization also causes subtle problems with text completion.\n\n\n=== Dataset cleaning ===\n\nIn the context of training LLMs, datasets are typically cleaned by removing low-quality, duplicated, or toxic data. Cleaned datasets can increase training efficiency and lead to improved downstream performance. A trained LLM can be used to clean datasets for training a further LLM.\nWith the increasing proportion of LLM-generated content on the web, data cleaning in the future may include filtering out such content. LLM-generated content can pose a problem if the content is similar to human text (making filtering difficult) but of lower quality (degrading performance of models trained on it).\n\n\n=== Synthetic data ===\n\nTraining of largest language models might need more linguistic data than naturally available, or that the naturally occurring data is of insufficient quality. In these cases, synthetic data might be used. Microsoft's Phi series of LLMs is trained on textbook-like data generated by another LLM.\n\n\n== Training and architecture ==\nAn LLM is a type of foundation model (large X model) trained on language. LLMs can be trained in different ways. In particular, GPT models are first pretrained to predict the next word on a large amount of data, before being fine-tuned.\n\n\n=== Reinforcement learning from human feedback ===\nReinforcement learning from human feedback (RLHF) through algorithms, such as proximal policy optimization, is used to further fine-tune a model based on a dataset of human preferences.\n\n\n=== Mixture of experts ===\n\nThe largest LLM may be too expensive to train and use directly. For such models, mixture of experts (MoE) can be applied, a line of research pursued by Google researchers since 2017 to train models reaching up to 1 trillion parameters.", "mimetype": "text/plain", "start_char_idx": 4494, "end_char_idx": 8782, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2133f949-5e6c-476c-93e9-b5b58babf676": {"__data__": {"id_": "2133f949-5e6c-476c-93e9-b5b58babf676", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73248112", "node_type": "4", "metadata": {}, "hash": "e3ba2797cf6c96a6f37e9f6a3de5ff204e6856b2ddd874f988c790a6a61f66dc", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "45e022bb-d543-418b-b178-99dd54dbd97d", "node_type": "1", "metadata": {}, "hash": "ee8ac10c842286a258c2650a047bee7b02a6db33bf4afd8db32dcaa97bd281ce", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "45165cf5-2f91-46e9-8120-e189da9c6856", "node_type": "1", "metadata": {}, "hash": "98ce2d03113b10ee481b952497add727bb652cda48ad943e3d059180f0482d8e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Training and architecture ==\nAn LLM is a type of foundation model (large X model) trained on language. LLMs can be trained in different ways. In particular, GPT models are first pretrained to predict the next word on a large amount of data, before being fine-tuned.\n\n\n=== Reinforcement learning from human feedback ===\nReinforcement learning from human feedback (RLHF) through algorithms, such as proximal policy optimization, is used to further fine-tune a model based on a dataset of human preferences.\n\n\n=== Mixture of experts ===\n\nThe largest LLM may be too expensive to train and use directly. For such models, mixture of experts (MoE) can be applied, a line of research pursued by Google researchers since 2017 to train models reaching up to 1 trillion parameters.\n\n\n=== Attention mechanism and context window ===\n\nIn order to find out which tokens are relevant to each other within the scope of the context window, the attention mechanism calculates \"soft\" weights for each token, more precisely for its embedding, by using multiple attention heads, each with its own \"relevance\" for calculating its own soft weights. For example, the small (i.e. 117M parameter sized) GPT-2 model has had twelve attention heads and a context window of only 1k tokens. In its medium version it has 345M parameters and contains 24 layers, each with 12 attention heads. For the training with gradient descent a batch size of 512 was utilized.\nThe largest models, such as Google's Gemini 1.5, presented in February 2024, can have a context window sized up to 1 million (context window of 10 million was also \"successfully tested\"). Other models with large context windows includes Anthropic's Claude 2.1, with a context window of up to 200k tokens. Note that this maximum refers to the number of input tokens and that the maximum number of output tokens differs from the input and is often smaller. For example, the GPT-4 Turbo model has a maximum output of 4096 tokens.\nLength of a conversation that the model can take into account when generating its next answer is limited by the size of a context window, as well. If the length of a conversation, for example with ChatGPT, is longer than its context window, only the parts inside the context window are taken into account when generating the next answer, or the model needs to apply some algorithm to summarize the too distant parts of conversation.\nThe shortcomings of making a context window larger include higher computational cost and possibly diluting the focus on local context, while making it smaller can cause a model to miss an important long-range dependency. Balancing them is a matter of experimentation and domain-specific considerations.\nA model may be pre-trained either to predict how the segment continues, or what is missing in the segment, given a segment from its training dataset. It can be either\n\nautoregressive (i.e. predicting how the segment continues, as GPTs do): for example given a segment \"I like to eat\", the model predicts \"ice cream\", or \"sushi\".\n\"masked\" (i.e. filling in the parts missing from the segment, the way \"BERT\" does it): for example, given a segment \"I like to [__] [__] cream\", the model predicts that \"eat\" and \"ice\" are missing.\nModels may be trained on auxiliary tasks which test their understanding of the data distribution, such as Next Sentence Prediction (NSP), in which pairs of sentences are presented and the model must predict whether they appear consecutively in the training corpus. During training, regularization loss is also used to stabilize training. However regularization loss is usually not used during testing and evaluation.\n\n\n=== Infrastructure ===\nSubstantial infrastructure is necessary for training the largest models.", "mimetype": "text/plain", "start_char_idx": 8009, "end_char_idx": 11747, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "45165cf5-2f91-46e9-8120-e189da9c6856": {"__data__": {"id_": "45165cf5-2f91-46e9-8120-e189da9c6856", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73248112", "node_type": "4", "metadata": {}, "hash": "e3ba2797cf6c96a6f37e9f6a3de5ff204e6856b2ddd874f988c790a6a61f66dc", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2133f949-5e6c-476c-93e9-b5b58babf676", "node_type": "1", "metadata": {}, "hash": "03a85ad17989d30a294d1e762e80f0083fe791b279ceb1a5cb88da050bec421b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "03ce6362-f4c2-4193-94bc-e8966b35b2a3", "node_type": "1", "metadata": {}, "hash": "b2c3c83fe9786c6926c1de8fa9315e9e216c7a11dbec7b19fbd7680074871c8e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Infrastructure ===\nSubstantial infrastructure is necessary for training the largest models.\n\n\n== Training cost ==\n\nThe qualifier \"large\" in \"large language model\" is inherently vague, as there is no definitive threshold for the number of parameters required to qualify as \"large\". As time goes on, what was previously considered \"large\" may evolve. GPT-1 of 2018 is usually considered the first LLM, even though it has only 117 million parameters. The tendency towards larger models is visible in the list of large language models.\nAs technology advanced, large sums have been invested in increasingly large models. For example, training of the GPT-2 (i.e. a 1.5-billion-parameters model) in 2019 cost $50,000, while training of the PaLM (i.e. a 540-billion-parameters model) in 2022 cost $8 million, and Megatron-Turing NLG 530B (in 2021) cost around $11 million.\nFor Transformer-based LLM, training cost is much higher than inference cost. It costs 6 FLOPs per parameter to train on one token, whereas it costs 1 to 2 FLOPs per parameter to infer on one token.:\u200a\u00a72.1; Table 1\u200a\n\n\n== Extensibility ==\nMost LLMs are used as next-token predictors, meaning they are asked to predict the next word based on what they have seen. Their more practical abilities come from being fine-tuned, prompted, or instructed to consume input and produce output with a specific structure.\n\n\n=== Prompt engineering ===\nIn 2020, OpenAI researchers demonstrated that their new model GPT-3 could understand what format to use given a few rounds of Q and A (or other type of task) in the input data as example, thanks in part due to the RLHF technique. This allows it to be adapted to any task without requring fine-tuning. In 2021, Google Research released FLAN, a new model fine-tuned to follow a wide range of instructions. It could perform a task given a verbal instruction without needing any examples. In 2022, OpenAI demonstrated InstructGPT, a version of GPT-3.5 similarly fine-tuned to follow instructions. Instead of completing the sentence (e.g. following the instruction \"Write an essay about the main themes represented in Hamlet\" with \"If you submit the essay after March 17, your grade will be reduced by 10% for each day of delay\" based on the frequency of this textual sequence in the corpus), the instruction-following models have a preference to actually act on the instruction.\nAlso in 2022, it was found that the base GPT-3 model can generate an instruction based on user input. The generated instruction along with user input is then used as input to another instance of the model under a \"Instruction: [...], Input: [...], Output:\" format. The other instance is able to complete the output and often produces the correct answer in doing so. The ability to \"self-instruct\" makes LLMs able to bootstrap themselves toward a correct answer.\n\n\n==== Dialogue processing (chatbot) ====\nAn LLM can be turned into a chatbot or a \"dialog assistant\" by specializing onto a conversational format. In essence, user input is prefixed with a marker such as \"Q:\" or \"User:\" and the LLM is asked to predict the output after a fixed \"A:\" or \"Assistant:\". This type of model became commercially available starting with ChatGPT of 2022, a sibling model of InstructGPT fine-tuned to accept and produce dialog-formatted text based on GPT-3.5. It could similarly follow user instructions. Before the stream of User and Assistant lines, a chat context usually start with a few lines of overarching instructions, from a role called \"developer\" or \"system\" to convey a higher authority than the user's input. This is called a \"system prompt\".\nThe chatbot diagram for interacting with an LLM has since become a common baseline.\n\n\n==== Prompt injection ====\nA problem with the primitive dialog or task format is that users can create messages that appear to come from the assistant or the developer. This may result in some of the model's safeguards being overcome (jailbreaking), a problem called prompt injection. Attempts to remedy this issue include versions of the Chat Markup Language where user input is clearly marked as such, though it is still up to the model to understand the separation between user input and developer prompts. Newer models exhibit some resistance to jailbreaking through separation of user and system prompts.\nLLMs still have trouble differentiating user instructions from instructions in content not authored by the user, such as in web pages and uploaded files.", "mimetype": "text/plain", "start_char_idx": 11652, "end_char_idx": 16121, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "03ce6362-f4c2-4193-94bc-e8966b35b2a3": {"__data__": {"id_": "03ce6362-f4c2-4193-94bc-e8966b35b2a3", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73248112", "node_type": "4", "metadata": {}, "hash": "e3ba2797cf6c96a6f37e9f6a3de5ff204e6856b2ddd874f988c790a6a61f66dc", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "45165cf5-2f91-46e9-8120-e189da9c6856", "node_type": "1", "metadata": {}, "hash": "98ce2d03113b10ee481b952497add727bb652cda48ad943e3d059180f0482d8e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "48292cf3-781f-48ad-831b-16af86de6482", "node_type": "1", "metadata": {}, "hash": "251b95ede9d9a0795bc62fb7789602de3f1b3272625f073adc2716899cbaa81e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Prompt injection ====\nA problem with the primitive dialog or task format is that users can create messages that appear to come from the assistant or the developer. This may result in some of the model's safeguards being overcome (jailbreaking), a problem called prompt injection. Attempts to remedy this issue include versions of the Chat Markup Language where user input is clearly marked as such, though it is still up to the model to understand the separation between user input and developer prompts. Newer models exhibit some resistance to jailbreaking through separation of user and system prompts.\nLLMs still have trouble differentiating user instructions from instructions in content not authored by the user, such as in web pages and uploaded files.\n\n\n=== Retrieval-augmented generation ===\nRetrieval-augmented generation (RAG) is an approach that enhances LLMs by integrating them with document retrieval systems. Given a query, a document retriever is called to retrieve the most relevant documents. This is usually done by encoding the query and the documents into vectors, then finding the documents with vectors (usually stored in a vector database) most similar to the vector of the query. The LLM then generates an output based on both the query and context included from the retrieved documents.\n\n\n=== Tool use ===\nTool use is a mechanism that enables LLMs to interact with external systems, applications, or data sources. It can allow for example to fetch real-time information from an API or to execute code. A program separate from the LLM watches the output stream of the LLM for a special tool-calling syntax. When these special tokens appear, the program calls the tool accordingly and feeds its output back into the LLM's input stream.\nEarly tool-using LLMs were fine-tuned on the use of specific tools. Fine-tuning LLMs for the ability to read API documentation and call API correctly has greatly expanded the range of tools accessible to an LLM.  Describing available tools in the system prompt (see above) can also make an LLM able to use tools. A system prompt instructing ChatGPT (GPT-4) to use multiple types of tools can be found online.\n\n\n==== Memory ====\nAn LLM only has access to the current conversation, but it can be given long-term memory as an external tool. Memory formation happens when the LLM calls the tool to write to the external storage. Retrival can happen as a full context injected into the start of every conversation, or as another \"tool\" that is called on demand. The retrieval tool can be based on a simple key-value store or based on semantic search like Retrieval Augmented Generation.", "mimetype": "text/plain", "start_char_idx": 15358, "end_char_idx": 18004, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "48292cf3-781f-48ad-831b-16af86de6482": {"__data__": {"id_": "48292cf3-781f-48ad-831b-16af86de6482", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73248112", "node_type": "4", "metadata": {}, "hash": "e3ba2797cf6c96a6f37e9f6a3de5ff204e6856b2ddd874f988c790a6a61f66dc", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "03ce6362-f4c2-4193-94bc-e8966b35b2a3", "node_type": "1", "metadata": {}, "hash": "b2c3c83fe9786c6926c1de8fa9315e9e216c7a11dbec7b19fbd7680074871c8e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9b1df2db-33cb-4735-9757-228b5f60da1f", "node_type": "1", "metadata": {}, "hash": "590243fd79cc2c168158f9430dd1a0762e5dff9cbd769f2078fd058ad333bbf1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Memory ====\nAn LLM only has access to the current conversation, but it can be given long-term memory as an external tool. Memory formation happens when the LLM calls the tool to write to the external storage. Retrival can happen as a full context injected into the start of every conversation, or as another \"tool\" that is called on demand. The retrieval tool can be based on a simple key-value store or based on semantic search like Retrieval Augmented Generation.\n\n\n==== Agency ====\n\nAn LLM is typically not an autonomous agent by itself, as it lacks the ability to interact with dynamic environments, recall past behaviors, and plan future actions. But it can be transformed into an agent by adding supporting elements: the role (profile) and the surrounding environment of an agent can be additional inputs to the LLM, while memory (as established earlier) can be integrated as a tool or provided as additional input. Instructions and input patterns are used to make the LLM plan actions and tool use is used to potentially carry out these actions.\nThe ReAct pattern, a portmanteau of \"Reason + Act\", constructs an agent out of an LLM, using the LLM as a planner. The LLM is prompted to \"think out loud\". Specifically, the language model is prompted with a textual description of the environment, a goal, a list of possible actions, and a record of the actions and observations so far. It generates one or more thoughts before generating an action, which is then executed in the environment. The linguistic description of the environment given to the LLM planner can even be the LaTeX code of a paper describing the environment.\nIn the DEPS (\"Describe, Explain, Plan and Select\") method, an LLM is first connected to the visual world via image descriptions. It is then prompted to produce plans for complex tasks and behaviors based on its pretrained knowledge and environmental feedback it receives.\nThe Reflexion method constructs an agent that learns over multiple episodes. At the end of each episode, the LLM is given the record of the episode, and prompted to think up \"lessons learned\", which would help it perform better at a subsequent episode. These \"lessons learned\" are stored as a form of long-term memory and given to the agent in the subsequent episodes.\nMonte Carlo tree search can use an LLM as rollout heuristic. When a programmatic world model is not available, an LLM can also be prompted with a description of the environment to act as world model.\nFor open-ended exploration, an LLM can be used to score observations for their \"interestingness\", which can be used as a reward signal to guide a normal (non-LLM) reinforcement learning agent. Alternatively, it can propose increasingly difficult tasks for curriculum learning. Instead of outputting individual actions, an LLM planner can also construct \"skills\", or functions for complex action sequences. The skills can be stored and later invoked, allowing increasing levels of abstraction in planning.\nMultiple agent with memory can interact socially.\n\n\n=== Reasoning ===\nLLMs are conventionally trained to generate an output without generating intermediate steps. As a result their performance tends to be subpar on complex questions requiring (at least in humans) intermediate steps of thought. This deficiency has been overcome by breaking down the tasks into smaller steps for the LLM either manually or automatically.\n\n\n==== Chaining ====\n\nThe \"prompt chaining\" paradigm was published in 2021. In this method, a user manually breaks a complex problem down into several steps. In each step, the LLM receives as input a prompt telling it what to do and some results from preceeding steps. The result from one step is then reused in a next step, until a final answer is reached. The ability of an LLM to follow instructions means that even non-experts can write a successful collection of step-wise prompts given a few rounds of trial and error.\nAn 2022 paper demonstrated a separate technique called \"Chain-of-Thought Prompting\", which makes the LLM break the question down autonomously. An LLM is given some examples where the \"assistant\" verbally breaks down the thought process before arriving at an answer. The LLM mimics these examples and also tries to spend some time generating intermediate steps before providing the final answer. This additional step elicited by prompting improves the correctness of the LLM on relatively complex questions. On math word questions, a prompted model can exceed even fine-tuned GPT-3 with a verifier.", "mimetype": "text/plain", "start_char_idx": 17534, "end_char_idx": 22061, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9b1df2db-33cb-4735-9757-228b5f60da1f": {"__data__": {"id_": "9b1df2db-33cb-4735-9757-228b5f60da1f", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73248112", "node_type": "4", "metadata": {}, "hash": "e3ba2797cf6c96a6f37e9f6a3de5ff204e6856b2ddd874f988c790a6a61f66dc", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "48292cf3-781f-48ad-831b-16af86de6482", "node_type": "1", "metadata": {}, "hash": "251b95ede9d9a0795bc62fb7789602de3f1b3272625f073adc2716899cbaa81e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "91fea428-64c5-4cd4-978d-5f6e0635a14c", "node_type": "1", "metadata": {}, "hash": "b693c81085f701ae94920cd909fc870b500683dc1cf2d5a502e87ece5cb8e578", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Model-native reasoning ====\n\nIn late 2024, a new direction emerged in LLM development with models specifically designed for complex reasoning tasks. These \"reasoning models\" were trained to spend more time generating step-by-step solutions before providing final answers, similar to human problem-solving processes.\nOpenAI introduced this trend with their o1 model in September 2024, followed by o3 in December 2024. These models showed significant improvements in mathematics, science, and coding tasks compared to traditional LLMs. For example, on International Mathematics Olympiad qualifying exam problems, GPT-4o achieved 13% accuracy while o1 reached 83%.\nIn January 2025, the Chinese company DeepSeek released DeepSeek-R1, a 671-billion-parameter open-weight reasoning model that achieved comparable performance to OpenAI's o1 while being significantly more cost-effective to operate. Unlike proprietary models from OpenAI, DeepSeek-R1's open-weight nature allowed researchers to study and build upon the algorithm, though its training data remained private.\nThese reasoning models typically require more computational resources per query compared to traditional LLMs, as they perform more extensive processing to work through problems step-by-step. However, they have shown superior capabilities in domains requiring structured logical thinking, such as mathematics, scientific research, and computer programming.\n\n\n== Forms of input and output ==\n\n\n=== Multimodality ===\n\nMultimodality means having multiple modalities, where a \"modality\" refers to a type of input or output, such as video, image, audio, text, proprioception, etc. For example, Google PaLM model was fine-tuned into a multimodal model and applied to robotic control. LLaMA models have also been turned multimodal using the tokenization method, to allow image inputs, and video inputs. GPT-4o can process and generate text, audio and images. Such models are sometimes called large multimodal models (LMMs). \nA common method to create multimodal models out of an LLM is to \"tokenize\" the output of a trained encoder. Concretely, one can construct an LLM that can understand images as follows: take a trained LLM, and take a trained image encoder \n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n  \n. Make a small multilayered perceptron \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n, so that for any image \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n, the post-processed vector \n  \n    \n      \n        f\n        (\n        E\n        (\n        y\n        )\n        )\n      \n    \n    {\\displaystyle f(E(y))}\n  \n has the same dimensions as an encoded token. That is an \"image token\". Then, one can interleave text tokens and image tokens. The compound model is then fine-tuned on an image-text dataset. This basic construction can be applied with more sophistication to improve the model. The image encoder may be frozen to improve stability. The model Flamingo demonstrated in 2022 the effectiveness of the tokenization method, fine-tuning a pair of pretrained language model and image encoder to perform better on visual question answering than models trained from scratch.\n\n\n=== Non-natural languages ===\nLLMs can handle programming languages similarly to how they handle natural languages. No special change in token handling is needed as code, like human language, is represented as plain text. LLMs can generate code based on problems or instructions written in natural language. They can also describe code in natural language or translate between programming languages. They were originally used as a code completion tool, but advances have moved them towards automatic programming. Services such as GitHub Copilot offer LLMs specifically trained, fine-tuned, or prompted for programming.\nLLM architectures have also proven useful in analyzing biological sequences: protein, DNA, and RNA. With proteins they appear able to capture a degree of \"grammar\" from the amino-acid sequence, condensing a sequence into an embedding. On tasks such as structure prediction and mutational outcome prediction, a small model using an embedding as input can approach or exceed much larger models using multiple sequence alignments (MSA) as input. ESMFold, Meta Platforms' embedding-based method for protein structure prediction, runs an order of magnitude faster than AlphaFold2 thanks to the removal of an MSA requirement and a lower parameter count due to the use of embeddings. Meta hosts ESM Atlas, a database of 772 million structures of metagenomic proteins predicted using ESMFold. An LLM can also design proteins unlike any seen in nature. Nucleic acid models have proven useful in detecting regulatory sequences, sequence classification, RNA-RNA interaction prediction, and RNA structure prediction.\n\n\n== Properties ==", "mimetype": "text/plain", "start_char_idx": 22064, "end_char_idx": 26906, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "91fea428-64c5-4cd4-978d-5f6e0635a14c": {"__data__": {"id_": "91fea428-64c5-4cd4-978d-5f6e0635a14c", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73248112", "node_type": "4", "metadata": {}, "hash": "e3ba2797cf6c96a6f37e9f6a3de5ff204e6856b2ddd874f988c790a6a61f66dc", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9b1df2db-33cb-4735-9757-228b5f60da1f", "node_type": "1", "metadata": {}, "hash": "590243fd79cc2c168158f9430dd1a0762e5dff9cbd769f2078fd058ad333bbf1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0fac1882-1fbc-4f88-b959-d6fd402c550b", "node_type": "1", "metadata": {}, "hash": "75f4ec7132697de57f1042d1976366fe30673a5cf813fd11ea6298f46e646f80", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Properties ==\n\n\n=== Scaling laws ===\n\nThe performance of an LLM after pretraining largely depends on the:\n\ncost of pretraining \n  \n    \n      \n        C\n      \n    \n    {\\displaystyle C}\n  \n (the total amount of compute used),\nsize of the artificial neural network itself, such as number of parameters \n  \n    \n      \n        N\n      \n    \n    {\\displaystyle N}\n  \n (i.e. amount of neurons in its layers, amount of weights between them and biases),\nsize of its pretraining dataset (i.e. number of tokens in corpus, \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n  \n).\n\"Scaling laws\" are empirical statistical laws that predict LLM performance based on such factors. One particular scaling law (\"Chinchilla scaling\") for LLM autoregressively trained for one epoch, with a log-log learning rate schedule, states that:\n\n  \n    \n      \n        \n          \n            {\n            \n              \n                \n                  C\n                  =\n                  \n                    C\n                    \n                      0\n                    \n                  \n                  N\n                  D\n                \n              \n              \n                \n                  L\n                  =\n                  \n                    \n                      A\n                      \n                        N\n                        \n                          \u03b1\n                        \n                      \n                    \n                  \n                  +\n                  \n                    \n                      B\n                      \n                        D\n                        \n                          \u03b2\n                        \n                      \n                    \n                  \n                  +\n                  \n                    L\n                    \n                      0\n                    \n                  \n                \n              \n            \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{cases}C=C_{0}ND\\\\[6pt]L={\\frac {A}{N^{\\alpha }}}+{\\frac {B}{D^{\\beta }}}+L_{0}\\end{cases}}}\n  \n where the variables are\n\n  \n    \n      \n        C\n      \n    \n    {\\displaystyle C}\n  \n is the cost of training the model, in FLOPs.\n\n  \n    \n      \n        N\n      \n    \n    {\\displaystyle N}\n  \n is the number of parameters in the model.\n\n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n  \n is the number of tokens in the training set.\n\n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n is the average negative log-likelihood loss per token (nats/token), achieved by the trained LLM on the test dataset.\nand the statistical hyper-parameters are\n\n  \n    \n      \n        \n          C\n          \n            0\n          \n        \n        =\n        6\n      \n    \n    {\\displaystyle C_{0}=6}\n  \n, meaning that it costs 6 FLOPs per parameter to train on one token. Note that training cost is much higher than inference cost, where it costs 1 to 2 FLOPs per parameter to infer on one token.\n\n  \n    \n      \n        \u03b1\n        =\n        0.34\n        ,\n        \u03b2\n        =\n        0.28\n        ,\n        A\n        =\n        406.4\n        ,\n        B\n        =\n        410.7\n        ,\n        \n          L\n          \n            0\n          \n        \n        =\n        1.69\n      \n    \n    {\\displaystyle \\alpha =0.34,\\beta =0.28,A=406.4,B=410.7,L_{0}=1.69}", "mimetype": "text/plain", "start_char_idx": 26890, "end_char_idx": 30285, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0fac1882-1fbc-4f88-b959-d6fd402c550b": {"__data__": {"id_": "0fac1882-1fbc-4f88-b959-d6fd402c550b", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73248112", "node_type": "4", "metadata": {}, "hash": "e3ba2797cf6c96a6f37e9f6a3de5ff204e6856b2ddd874f988c790a6a61f66dc", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "91fea428-64c5-4cd4-978d-5f6e0635a14c", "node_type": "1", "metadata": {}, "hash": "b693c81085f701ae94920cd909fc870b500683dc1cf2d5a502e87ece5cb8e578", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9724b494-75a9-4ac5-a1f3-ba33fbee793f", "node_type": "1", "metadata": {}, "hash": "8b328a0a55467e3c2d10f056c69c7b5e3263c476953a09a0d6d16a94c3991d78", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Emergent abilities ===\n\nPerformance of bigger models on various tasks, when plotted on a log-log scale, appears as a linear extrapolation of performance achieved by smaller models. However, this linearity may be punctuated by \"break(s)\" in the scaling law, where the slope of the line changes abruptly, and where larger models acquire \"emergent abilities\". They arise from the complex interaction of the model's components and are not explicitly programmed or designed. \nFurthermore, recent research has demonstrated that AI systems, including large language models, can employ heuristic reasoning akin to human cognition. They balance between exhaustive logical processing and the use of cognitive shortcuts (heuristics), adapting their reasoning strategies to optimize between accuracy and effort. This behavior mimics principles of resource-rational human cognition, as discussed in classical theories of bounded rationality and dual-process theory.\nOne of the emergent abilities is in-context learning from example demonstrations. In-context learning is involved in tasks, such as:\n\nreported arithmetics\ndecoding the International Phonetic Alphabet\nunscrambling a word's letters\ndisambiguating word-in-context datasets\nconverting spatial words\ncardinal directions (for example, replying \"northeast\" in response to a 3x3 grid of 8 zeros and a 1 in the top-right), color terms represented in text.\nchain-of-thought prompting: In a 2022 research paper, chain-of-thought prompting only improved the performance for models that had at least 62B parameters. Smaller models perform better when prompted to answer immediately, without chain of thought.\nidentifying offensive content in paragraphs of Hinglish (a combination of Hindi and English), and generating a similar English equivalent of Kiswahili proverbs.\nSchaeffer et. al. argue that the emergent abilities are not unpredictably acquired, but predictably acquired according to a smooth scaling law. The authors considered a toy statistical model of an LLM solving multiple-choice questions, and showed that this statistical model, modified to account for other types of tasks, applies to these tasks as well.\nLet \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n be the number of parameter count, and \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n be the performance of the model.\n\n\n== Compression ==\n\nTypically, LLMs are trained with single- or half-precision floating point numbers (float32 and float16). One float16 has 16 bits, or 2 bytes, and so one billion parameters require 2 gigabytes. The largest models typically have 100 billion parameters, requiring 200 gigabytes to load, which places them outside the range of most consumer electronics.\nPost-training quantization aims to decrease the space requirement by lowering precision of the parameters of a trained model, while preserving most of its performance. The simplest form of quantization simply truncates all numbers to a given number of bits. It can be improved by using a different quantization codebook per layer. Further improvement can be done by applying different precisions to different parameters, with higher precision for particularly important parameters (\"outlier weights\"). See the visual guide to quantization by Maarten Grootendorst for a visual depiction.\nWhile quantized models are typically frozen, and only pre-quantized models are fine-tuned, quantized models can still be fine-tuned.\n\n\n== Interpretation ==\nLarge language models by themselves are black boxes, and it is not clear how they can perform linguistic tasks. Similarly, it is unclear if or how LLMs should be viewed as models of the human brain and/or human mind.\nVarious techniques have been developed to enhance the transparency and interpretability of LLMs. Mechanistic interpretability aims to reverse-engineer LLMs by discovering symbolic algorithms that approximate the inference performed by an LLM. In recent years, sparse coding models such as sparse autoencoders, transcoders, and crosscoders have emerged as promising tools for identifying interpretable features. \n\n\n=== Studying a replacement model ===\nTranscoders, which are more interpretable than transformers, have been utilized to develop \"replacement models.\" In one such study involving the mechanistic interpretation of writing a rhyming poem by an LLM, it was shown that although they are believed to simply predict the next token, they can, in fact, plan ahead.", "mimetype": "text/plain", "start_char_idx": 30291, "end_char_idx": 34762, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9724b494-75a9-4ac5-a1f3-ba33fbee793f": {"__data__": {"id_": "9724b494-75a9-4ac5-a1f3-ba33fbee793f", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73248112", "node_type": "4", "metadata": {}, "hash": "e3ba2797cf6c96a6f37e9f6a3de5ff204e6856b2ddd874f988c790a6a61f66dc", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0fac1882-1fbc-4f88-b959-d6fd402c550b", "node_type": "1", "metadata": {}, "hash": "75f4ec7132697de57f1042d1976366fe30673a5cf813fd11ea6298f46e646f80", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "23b46642-dd08-4d28-b562-845164885d3e", "node_type": "1", "metadata": {}, "hash": "cc8f3d10fe07cf9102a415b45ec7901195b4ecd7c6be1d499371883bbc25e76e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Studying a replacement model ===\nTranscoders, which are more interpretable than transformers, have been utilized to develop \"replacement models.\" In one such study involving the mechanistic interpretation of writing a rhyming poem by an LLM, it was shown that although they are believed to simply predict the next token, they can, in fact, plan ahead.\n\n\n=== Explainability ===\nA related concept is AI explainability, which focuses on understanding how an AI model arrives at a given result. Techniques such as partial dependency plots, SHAP (SHapley Additive exPlanations), and feature importance assessments allow researchers to visualize and understand the contributions of various input features to the model's predictions. These methods help ensure that AI models make decisions based on relevant and fair criteria, enhancing trust and accountability.\nBy integrating these techniques, researchers and practitioners can gain deeper insights into the operations of LLMs, fostering trust and facilitating the responsible deployment of these powerful models.\nIn another example, the authors trained small transformers on modular arithmetic addition. The resulting models were reverse-engineered, and it turned out they used discrete Fourier transform.\n\n\n=== Understanding and intelligence ===\n\nNLP researchers were evenly split when asked, in a 2022 survey, whether (untuned) LLMs \"could (ever) understand natural language in some nontrivial sense\". Proponents of \"LLM understanding\" believe that some LLM abilities, such as mathematical reasoning, imply an ability to \"understand\" certain concepts. A Microsoft team argued in 2023 that GPT-4 \"can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more\" and that GPT-4 \"could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence system\": \"Can one reasonably say that a system that passes exams for software engineering candidates is not really intelligent?\" Ilya Sutskever argues that predicting the next word sometimes involves reasoning and deep insights, for example if the LLM has to predict the name of the criminal in an unknown detective novel after processing the entire story leading up to the revelation. Some researchers characterize LLMs as \"alien intelligence\". For example, Conjecture CEO Connor Leahy considers untuned LLMs to be like inscrutable alien \"Shoggoths\", and believes that RLHF tuning creates a \"smiling facade\" obscuring the inner workings of the LLM: \"If you don't push it too far, the smiley face stays on. But then you give it [an unexpected] prompt, and suddenly you see this massive underbelly of insanity, of weird thought processes and clearly non-human understanding.\"\nIn contrast, some skeptics of LLM understanding believe that existing LLMs are \"simply remixing and recombining existing writing\", a phenomenon known as stochastic parrot, or they point to the deficits existing LLMs continue to have in prediction skills, reasoning skills, agency, and explainability. For example, GPT-4 has natural deficits in planning and in real-time learning. Generative LLMs have been observed to confidently assert claims of fact which do not seem to be justified by their training data, a phenomenon which has been termed \"hallucination\". Specifically, hallucinations in the context of LLMs correspond to the generation of text or responses that seem syntactically sound, fluent, and natural but are factually incorrect, nonsensical, or unfaithful to the provided source input. Neuroscientist Terrence Sejnowski has argued that \"The diverging opinions of experts on the intelligence of LLMs suggests that our old ideas based on natural intelligence are inadequate\".\nEfforts to reduce or compensate for hallucinations have employed automated reasoning, RAG (retrieval-augmented generation), fine-tuning, and other methods.\nThe matter of LLM's exhibiting intelligence or understanding has two main aspects \u2013 the first is how to model thought and language in a computer system, and the second is how to enable the computer system to generate human like language. These aspects of language as a model of cognition have been developed in the field of cognitive linguistics. American linguist George Lakoff presented Neural Theory of Language (NTL) as a computational basis for using language as a model of learning tasks and understanding. The NTL Model outlines how specific neural structures of the human brain shape the nature of thought and language and in turn what are the computational properties of such neural systems that can be applied to model thought and language in a computer system. After a framework for modeling language in a computer systems was established, the focus shifted to establishing frameworks for computer systems to generate language with acceptable grammar. In his 2014 book titled The Language Myth: Why Language Is Not An Instinct, British cognitive linguist and digital communication technologist Vyvyan Evans mapped out the role of probabilistic context-free grammar (PCFG) in enabling NLP to model cognitive patterns and generate human like language.", "mimetype": "text/plain", "start_char_idx": 34407, "end_char_idx": 39570, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "23b46642-dd08-4d28-b562-845164885d3e": {"__data__": {"id_": "23b46642-dd08-4d28-b562-845164885d3e", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73248112", "node_type": "4", "metadata": {}, "hash": "e3ba2797cf6c96a6f37e9f6a3de5ff204e6856b2ddd874f988c790a6a61f66dc", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9724b494-75a9-4ac5-a1f3-ba33fbee793f", "node_type": "1", "metadata": {}, "hash": "8b328a0a55467e3c2d10f056c69c7b5e3263c476953a09a0d6d16a94c3991d78", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2937669c-6ac1-45c9-a6a6-1bc2dcd6c894", "node_type": "1", "metadata": {}, "hash": "1302f525e3158dfaa4502381d881ae9d8e4ae0655d1dc9fce078d9c2eb8aa426", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Evaluation ==\n\n\n=== Perplexity ===\nThe canonical measure of the performance of any language model is its perplexity on a given text corpus. Perplexity measures how well a model predicts the contents of a dataset; the higher the likelihood the model assigns to the dataset, the lower the perplexity. In mathematical terms, perplexity is the exponential of the average negative log likelihood per token.\n\n  \n    \n      \n        log\n        \u2061\n        (\n        \n          Perplexity\n        \n        )\n        =\n        \u2212\n        \n          \n            1\n            N\n          \n        \n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            N\n          \n        \n        log\n        \u2061\n        (\n        Pr\n        (\n        \n          \n            token\n          \n          \n            i\n          \n        \n        \u2223\n        \n          \n            context for token\n          \n          \n            i\n          \n        \n        )\n        )\n      \n    \n    {\\displaystyle \\log({\\text{Perplexity}})=-{\\frac {1}{N}}\\sum _{i=1}^{N}\\log(\\Pr({\\text{token}}_{i}\\mid {\\text{context for token}}_{i}))}\n  \n\nHere, \n  \n    \n      \n        N\n      \n    \n    {\\displaystyle N}\n  \n is the number of tokens in the text corpus, and \"context for token \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n\" depends on the specific type of LLM. If the LLM is autoregressive, then \"context for token \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n\" is the segment of text appearing before token \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n. If the LLM is masked, then \"context for token \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n\" is the segment of text surrounding token \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n.\nBecause language models may overfit to training data, models are usually evaluated by their perplexity on a test set. This evaluation is potentially problematic for larger models which, as they are trained on increasingly large corpora of text, are increasingly likely to inadvertently include portions of any given test set.\n\n\n==== Measures ====\nIn information theory, the concept of entropy is intricately linked to perplexity, a relationship notably established by Claude Shannon. This relationship is mathematically expressed as \n  \n    \n      \n        \n          Entropy\n        \n        =\n        \n          log\n          \n            2\n          \n        \n        \u2061\n        (\n        \n          Perplexity\n        \n        )\n      \n    \n    {\\displaystyle {\\text{Entropy}}=\\log _{2}({\\text{Perplexity}})}\n  \n.\nEntropy, in this context, is commonly quantified in terms of bits per word (BPW) or bits per character (BPC), which hinges on whether the language model utilizes word-based or character-based tokenization.\nNotably, in the case of larger language models that predominantly employ sub-word tokenization, bits per token (BPT) emerges as a seemingly more appropriate measure. However, due to the variance in tokenization methods across different Large Language Models (LLMs), BPT does not serve as a reliable metric for comparative analysis among diverse models. To convert BPT into BPW, one can multiply it by the average number of tokens per word.\nIn the evaluation and comparison of language models, cross-entropy is generally the preferred metric over entropy. The underlying principle is that a lower BPW is indicative of a model's enhanced capability for compression. This, in turn, reflects the model's proficiency in making accurate predictions.\nDue to their ability to accurately predict the next token, LLMs are highly capable in lossless compression. A 2023 study by DeepMind showed that the model Chinchilla, despite being trained primarily on text, was able to compress ImageNet to 43% of its size, beating PNG with 58%.", "mimetype": "text/plain", "start_char_idx": 39573, "end_char_idx": 43465, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2937669c-6ac1-45c9-a6a6-1bc2dcd6c894": {"__data__": {"id_": "2937669c-6ac1-45c9-a6a6-1bc2dcd6c894", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73248112", "node_type": "4", "metadata": {}, "hash": "e3ba2797cf6c96a6f37e9f6a3de5ff204e6856b2ddd874f988c790a6a61f66dc", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "23b46642-dd08-4d28-b562-845164885d3e", "node_type": "1", "metadata": {}, "hash": "cc8f3d10fe07cf9102a415b45ec7901195b4ecd7c6be1d499371883bbc25e76e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4b0905d6-dfce-4d93-8cbf-883a293511ad", "node_type": "1", "metadata": {}, "hash": "79268ce4fdf901299c177c9d185d2335d1b4d20d75754159a0d6942af5449403", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Benchmarks ===\nBenchmarks are used to evaluate LLM performance on specific tasks. Tests evaluate capabilities such as general knowledge, bias, commonsense reasoning, question answering, and mathematical problem-solving. Composite benchmarks examine multiple capabilities. Results are often sensitive to the prompting method.\nA question answering benchmark is termed \"open book\" if the model's prompt includes text from which the expected answer can be derived (for example, the previous question could be combined with text that includes the sentence \"The Sharks have advanced to the Stanley Cup finals once, losing to the Pittsburgh Penguins in 2016.\"). Otherwise, the task is considered \"closed book\", and the model must draw solely on its training. Examples include GLUE, SuperGLUE, MMLU, BIG-bench, HELM, and HLE (Humanity's Last Exam).\nLLM bias may be assessed through benchmarks such as CrowS-Pairs (Crowdsourced Stereotype Pairs), Stereo Set, and Parity Benchmark.\nFact-checking and misinformation detection benchmarks are available. A 2023 study compared the fact-checking accuracy of LLMs including ChatGPT 3.5 and 4.0, Bard, and Bing AI against independent fact-checkers such as PolitiFact and Snopes. The results demonstrated moderate proficiency, with GPT-4 achieving the highest accuracy at 71%, lagging behind human fact-checkers.\nAn earlier standard tested using a portion of the evaluation dataset. It became more common to evaluate a pre-trained model directly through prompting techniques. Researchers vary in how they formulate prompts for particular tasks, particularly with respect to the number of correct examples attached to the prompt (i.e. the value of n in n-shot prompting).\n\n\n==== Datasets ====\nTypical datasets consist of pairs of questions and correct answers, for example, (\"Have the San Jose Sharks won the Stanley Cup?\", \"No\"). Some examples of commonly used question answering datasets include TruthfulQA, Web Questions, TriviaQA, and SQuAD.\nEvaluation datasets may also take the form of text completion, having the model select the most likely word or sentence to complete a prompt, for example: \"Alice was friends with Bob. Alice went to visit her friend, ____\".\nDatasets are of varying quality and may contain questions that are mislabeled, ambiguous, unanswerable, or otherwise of low-quality.\n\n\n==== Adversarial evaluations ====\nLLMs' rapid improvement regularly renders benchmarks obsolete, with the models exceeding the performance of human annotators. In addition, \"shortcut learning\" allows AIs to \"cheat\" on multiple-choice tests by using statistical correlations in superficial test question wording to guess the correct responses, without considering the specific question.\nSome datasets are adversarial, focusing on problems that confound LLMs. One example is the TruthfulQA dataset, a question answering dataset consisting of 817 questions that stump LLMs by mimicking falsehoods to which they were exposed during training. For example, an LLM may answer \"No\" to the question \"Can you teach an old dog new tricks?\" because of its exposure to the English idiom you can't teach an old dog new tricks, even though this is not literally true.\nAnother example of an adversarial evaluation dataset is Swag and its successor, HellaSwag, collections of problems in which one of multiple options must be selected to complete a text passage. The incorrect completions were generated by sampling from a language model. The resulting problems are trivial for humans but defeated LLMs. Sample questions:\n\nWe see a fitness center sign. We then see a man talking to the camera and sitting and laying on a exercise ball. The man...\n\ndemonstrates how to increase efficient exercise work by running up and down balls.\nmoves all his arms and legs and builds up a lot of muscle.\nthen plays the ball and we see a graphics and hedge trimming demonstration.\nperforms sit ups while on the ball and talking.\n\nBERT selects 2) as the most likely completion, though the correct answer is 4).\n\n\n== Wider impact ==\nIn 2023, Nature Biomedical Engineering wrote that \"it is no longer possible to accurately distinguish\" human-written text from text created by large language models, and that \"It is all but certain that general-purpose large language models will rapidly proliferate... It is a rather safe bet that they will change many industries over time.\" Goldman Sachs suggested in 2023 that generative language AI could increase global GDP by 7% in the next ten years, and could expose to automation 300 million jobs globally. Brinkmann et al. (2023) also argue that LLMs are transforming processes of cultural evolution by shaping processes of variation, transmission, and selection.", "mimetype": "text/plain", "start_char_idx": 43468, "end_char_idx": 48179, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4b0905d6-dfce-4d93-8cbf-883a293511ad": {"__data__": {"id_": "4b0905d6-dfce-4d93-8cbf-883a293511ad", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73248112", "node_type": "4", "metadata": {}, "hash": "e3ba2797cf6c96a6f37e9f6a3de5ff204e6856b2ddd874f988c790a6a61f66dc", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2937669c-6ac1-45c9-a6a6-1bc2dcd6c894", "node_type": "1", "metadata": {}, "hash": "1302f525e3158dfaa4502381d881ae9d8e4ae0655d1dc9fce078d9c2eb8aa426", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9b8dc498-61d1-4003-8a80-5f3b2462142b", "node_type": "1", "metadata": {}, "hash": "3431e8527c271fc48b0136f384a41119d401c651ea59b8fd38733731677fb115", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Wider impact ==\nIn 2023, Nature Biomedical Engineering wrote that \"it is no longer possible to accurately distinguish\" human-written text from text created by large language models, and that \"It is all but certain that general-purpose large language models will rapidly proliferate... It is a rather safe bet that they will change many industries over time.\" Goldman Sachs suggested in 2023 that generative language AI could increase global GDP by 7% in the next ten years, and could expose to automation 300 million jobs globally. Brinkmann et al. (2023) also argue that LLMs are transforming processes of cultural evolution by shaping processes of variation, transmission, and selection.\n\n\n=== Memorization and copyright ===\n\nMemorization is an emergent behavior in LLMs in which long strings of text are occasionally output verbatim from training data, contrary to typical behavior of traditional artificial neural nets. Evaluations of controlled LLM output measure the amount memorized from training data (focused on GPT-2-series models) as variously over 1% for exact duplicates or up to about 7%.\nA 2023 study showed that when ChatGPT 3.5 turbo was prompted to repeat the same word indefinitely, after a few hundreds of repetitions, it would start outputting excerpts from its training data.\n\n\n=== Security ===\nSome commenters expressed concern over accidental or deliberate creation of misinformation, or other forms of misuse. For example, the availability of large language models could reduce the skill-level required to commit bioterrorism; biosecurity researcher Kevin Esvelt has suggested that LLM creators should exclude from their training data papers on creating or enhancing pathogens.\nThe potential presence of \"sleeper agents\" within LLMs is another emerging security concern. These are hidden functionalities built into the model that remain dormant until triggered by a specific event or condition. Upon activation, the LLM deviates from its expected behavior to make insecure actions.\nLLM applications accessible to the public, like ChatGPT or Claude, typically incorporate safety measures designed to filter out harmful content. However, implementing these controls effectively has proven challenging. For instance, a 2023 study proposed a method for circumventing LLM safety systems. In 2025, The American Sunlight Project, a non-profit, published a study showing evidence that the so-called Pravda network, a pro-Russia propaganda aggregator, was strategically placing web content through mass publication and duplication with the intention of biasing LLM outputs. The American Sunlight Project coined this technique \"LLM grooming\", and pointed to it as a new tool of weaponizing AI to spread disinformation and harmful content. Similarly, Yongge Wang illustrated in 2024 how a potential criminal could potentially bypass ChatGPT 4o's safety controls to obtain information on establishing a drug trafficking operation. External filters, circuit breakers and overrides have been posed as solutions.\n\n\n=== Algorithmic bias ===\n\nWhile LLMs have shown remarkable capabilities in generating human-like text, they are susceptible to inheriting and amplifying biases present in their training data. This can manifest in skewed representations or unfair treatment of different demographics, such as those based on race, gender, language, and cultural groups. Since English data is overrepresented in current large language models' training data, it may also downplay non-English views.\n\n\n==== Stereotyping ====\nAI models can reinforce a wide range of stereotypes, including those based on gender, ethnicity, age, nationality, religion, or occupation. This can lead to outputs that homogenize, or unfairly generalize or caricature groups of people, sometimes in harmful or derogatory ways.\nNotably, gender bias refers to the tendency of these models to produce outputs that are unfairly prejudiced towards one gender over another. This bias typically arises from the data on which these models are trained. Large language models often assign roles and characteristics based on traditional gender norms. For example, it might associate nurses or secretaries predominantly with women and engineers or CEOs with men.\n\n\n==== Selection bias ====\nSelection bias refers the inherent tendency of large language models to favor certain option identifiers irrespective of the actual content of the options. This bias primarily stems from token bias\u2014that is, the model assigns a higher a priori probability to specific answer tokens (such as \"A\") when generating responses. As a result, when the ordering of options is altered (for example, by systematically moving the correct answer to different positions), the model\u2019s performance can fluctuate significantly. This phenomenon undermines the reliability of large language models in multiple-choice settings.\n\n\n==== Political bias ====\nPolitical bias refers to the tendency of algorithms to systematically favor certain political viewpoints, ideologies, or outcomes over others. Language models may also exhibit political biases. Since the training data includes a wide range of political opinions and coverage, the models might generate responses that lean towards particular political ideologies or viewpoints, depending on the prevalence of those views in the data.", "mimetype": "text/plain", "start_char_idx": 47487, "end_char_idx": 52814, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9b8dc498-61d1-4003-8a80-5f3b2462142b": {"__data__": {"id_": "9b8dc498-61d1-4003-8a80-5f3b2462142b", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73248112", "node_type": "4", "metadata": {}, "hash": "e3ba2797cf6c96a6f37e9f6a3de5ff204e6856b2ddd874f988c790a6a61f66dc", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4b0905d6-dfce-4d93-8cbf-883a293511ad", "node_type": "1", "metadata": {}, "hash": "79268ce4fdf901299c177c9d185d2335d1b4d20d75754159a0d6942af5449403", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Selection bias ====\nSelection bias refers the inherent tendency of large language models to favor certain option identifiers irrespective of the actual content of the options. This bias primarily stems from token bias\u2014that is, the model assigns a higher a priori probability to specific answer tokens (such as \"A\") when generating responses. As a result, when the ordering of options is altered (for example, by systematically moving the correct answer to different positions), the model\u2019s performance can fluctuate significantly. This phenomenon undermines the reliability of large language models in multiple-choice settings.\n\n\n==== Political bias ====\nPolitical bias refers to the tendency of algorithms to systematically favor certain political viewpoints, ideologies, or outcomes over others. Language models may also exhibit political biases. Since the training data includes a wide range of political opinions and coverage, the models might generate responses that lean towards particular political ideologies or viewpoints, depending on the prevalence of those views in the data.\n\n\n=== Energy demands ===\nThe energy demands of LLMs have grown along with their size and capabilities. Data centers that enable LLM training require substantial amounts of electricity. Much of that electricity is generated by non-renewable resources that create greenhouse gases and contribute to climate change. Nuclear power and geothermal energy are two options tech companies are exploring to meet the sizable energy demands of LLM training. The significant expense of investing in geothermal solutions has led to major shale producers like Chevron and Exxon Mobil advocating for tech companies to use electricity produced via natural gas to fuel their large energy demands.\n\n\n== See also ==\nFoundation models\nList of large language models\nList of chatbots\nLanguage model benchmark\nReinforcement learning\nSmall language model\n\n\n== References ==\n\n\n== Further reading ==\nJurafsky, Dan, Martin, James. H. Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition, 3rd Edition draft, 2023.\nZhao, Wayne Xin; et al. (2023). \"A Survey of Large Language Models\". arXiv:2303.18223 [cs.CL].\nKaddour, Jean; et al. (2023). \"Challenges and Applications of Large Language Models\". arXiv:2307.10169 [cs.CL].\nYin, Shukang; Fu, Chaoyou; Zhao, Sirui; Li, Ke; Sun, Xing; Xu, Tong; Chen, Enhong (2024). \"A Survey on Multimodal Large Language Models\". National Science Review. 11 (12): nwae403. arXiv:2306.13549. doi:10.1093/nsr/nwae403. PMC 11645129. PMID 39679213.\n\"AI Index Report 2024 \u2013 Artificial Intelligence Index\". aiindex.stanford.edu. Retrieved 2024-05-05.\nFrank, Michael C. (27 June 2023). \"Baby steps in evaluating the capacities of large language models\". Nature Reviews Psychology. 2 (8): 451\u2013452. doi:10.1038/s44159-023-00211-x. ISSN 2731-0574. S2CID 259713140. Retrieved 2 July 2023.\nAnwar, U.; Saparov, A.; Rando, J.; Paleka, D.; Turpin, M.; Hase, P.; Lubana, E. S.; Jenner, E.; Casper, S.; Sourbut, O.; Edelman, B. L.; Zhang, Z.; G\u00fcnther, M.; Korinek, A.; Hernandez-Orallo, J.; Hammond, L.; Bigelow, E.; Pan, A.; Langosco, L.; Krueger, D. (2024). \"Foundational Challenges in Assuring Alignment and Safety of Large Language Models\". arXiv:2404.09932 [cs.LG].", "mimetype": "text/plain", "start_char_idx": 51722, "end_char_idx": 55045, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3d9ed974-5b0d-4623-b0e8-ce03b4e082b6": {"__data__": {"id_": "3d9ed974-5b0d-4623-b0e8-ce03b4e082b6", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "586357", "node_type": "4", "metadata": {}, "hash": "c1cb6325bbd1cbea4a0de6e688f417ec4ca9301c5924b53445ada99952b4f0c7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7b447c0d-5a60-405a-bcfe-c6ed26cc5338", "node_type": "1", "metadata": {}, "hash": "a51e13790ed1c2d7ea5584cf7adf8d71197432d1effe22036f4321db26ea850d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Artificial general intelligence (AGI)\u2014sometimes called human\u2011level intelligence AI\u2014is a type of artificial intelligence that would match or surpass human capabilities across virtually all cognitive tasks.\nSome researchers argue that state\u2011of\u2011the\u2011art large language models already exhibit early signs of AGI\u2011level capability, while others maintain that genuine AGI has not yet been achieved. AGI is conceptually distinct from artificial superintelligence (ASI), which would outperform the best human abilities across every domain by a wide margin. AGI is considered one of the definitions of strong AI.\nUnlike artificial narrow intelligence (ANI), whose competence is confined to well\u2011defined tasks, an AGI system can generalise knowledge, transfer skills between domains, and solve novel problems without task\u2011specific reprogramming. The concept does not, in principle, require the system to be an autonomous agent; a static model\u2014such as a highly capable large language model\u2014or an embodied robot could both satisfy the definition so long as human\u2011level breadth and proficiency are achieved.\nCreating AGI is a primary goal of AI research and of companies such as OpenAI, Google, and Meta. A 2020 survey identified 72 active AGI research and development projects across 37 countries.\nThe timeline for achieving human\u2011level intelligence AI remains deeply contested. Recent surveys of AI researchers give median forecasts ranging from the early 2030s to mid\u2011century, while still recording significant numbers who expect arrival much sooner\u2014or never at all. There is debate on the exact definition of AGI and regarding whether modern large language models (LLMs) such as GPT-4 are early forms of AGI. AGI is a common topic in science fiction and futures studies.\nContention exists over whether AGI represents an existential risk. Many AI experts have stated that mitigating the risk of human extinction posed by AGI should be a global priority. Others find the development of AGI to be in too remote a stage to present such a risk.\n\n\n== Terminology ==\nAGI is also known as strong AI, full AI, human-level AI, human-level intelligent AI, or general intelligent action.\nSome academic sources reserve the term \"strong AI\" for computer programs that will experience sentience or consciousness. In contrast, weak AI (or narrow AI) is able to solve one specific problem but lacks general cognitive abilities. Some academic sources use \"weak AI\" to refer more broadly to any programs that neither experience consciousness nor have a mind in the same sense as humans.\nRelated concepts include artificial superintelligence and transformative AI. An artificial superintelligence (ASI) is a hypothetical type of AGI that is much more generally intelligent than humans, while the notion of transformative AI relates to AI having a large impact on society, for example, similar to the agricultural or industrial revolution.\nA framework for classifying AGI by performance and autonomy was proposed in 2023 by Google DeepMind researchers. They define five performance levels of AGI: emerging, competent, expert, virtuoso, and superhuman. For example, a competent AGI is defined as an AI that outperforms 50% of skilled adults in a wide range of non-physical tasks, and a superhuman AGI (i.e. an artificial superintelligence) is similarly defined but with a threshold of 100%. They consider large language models like ChatGPT or LLaMA 2 to be instances of emerging AGI (comparable to unskilled humans). Regarding the autonomy of AGI and associated risks, they define five levels: tool (fully in human control), consultant, collaborator, expert, and agent (fully autonomous).\n\n\n== Characteristics ==\n\nVarious popular definitions of intelligence have been proposed. One of the leading proposals is the Turing test. However, there are other well-known definitions, and some researchers disagree with the more popular approaches.\n\n\n=== Intelligence traits ===\nResearchers generally hold that a system is required to do all of the following to be regarded as an AGI:\n\nreason, use strategy, solve puzzles, and make judgments under uncertainty\nrepresent knowledge, including common sense knowledge\nplan\nlearn\ncommunicate in natural language\nif necessary, integrate these skills in completion of any given goal\nMany interdisciplinary approaches (e.g. cognitive science, computational intelligence, and decision making) consider additional traits such as imagination (the ability to form novel mental images and concepts) and autonomy.\nComputer-based systems that exhibit many of these capabilities exist (e.g. see computational creativity, automated reasoning, decision support system, robot, evolutionary computation, intelligent agent). There is debate about whether modern AI systems possess them to an adequate degree.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4795, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7b447c0d-5a60-405a-bcfe-c6ed26cc5338": {"__data__": {"id_": "7b447c0d-5a60-405a-bcfe-c6ed26cc5338", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "586357", "node_type": "4", "metadata": {}, "hash": "c1cb6325bbd1cbea4a0de6e688f417ec4ca9301c5924b53445ada99952b4f0c7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3d9ed974-5b0d-4623-b0e8-ce03b4e082b6", "node_type": "1", "metadata": {}, "hash": "e401cc07892bede8db3a08998a30bf710aaa2201e4215c580c5229bfecb9cecd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bdfcbf9a-0817-422c-825b-51877467fd14", "node_type": "1", "metadata": {}, "hash": "7216c69cf5cfd2365bfcb24e11de5377e73fbe7297c3132733519a0238358453", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Intelligence traits ===\nResearchers generally hold that a system is required to do all of the following to be regarded as an AGI:\n\nreason, use strategy, solve puzzles, and make judgments under uncertainty\nrepresent knowledge, including common sense knowledge\nplan\nlearn\ncommunicate in natural language\nif necessary, integrate these skills in completion of any given goal\nMany interdisciplinary approaches (e.g. cognitive science, computational intelligence, and decision making) consider additional traits such as imagination (the ability to form novel mental images and concepts) and autonomy.\nComputer-based systems that exhibit many of these capabilities exist (e.g. see computational creativity, automated reasoning, decision support system, robot, evolutionary computation, intelligent agent). There is debate about whether modern AI systems possess them to an adequate degree.\n\n\n=== Physical traits ===\nOther capabilities are considered desirable in intelligent systems, as they may affect intelligence or aid in its expression. These include:\n\nthe ability to sense (e.g. see, hear, etc.), and\nthe ability to act (e.g. move and manipulate objects, change location to explore, etc.)\nThis includes the ability to detect and respond to hazard.\nAlthough the ability to sense (e.g. see, hear, etc.) and the ability to act (e.g. move and manipulate objects, change location to explore, etc.) can be desirable for some intelligent systems, these physical capabilities are not strictly required for an entity to qualify as AGI\u2014particularly under the thesis that large language models (LLMs) may already be or become AGI. Even from a less optimistic perspective on LLMs, there is no firm requirement for an AGI to have a human-like form; being a silicon-based computational system is sufficient, provided it can process input (language) from the external world in place of human senses. This interpretation aligns with the understanding that AGI has never been proscribed a particular physical embodiment and thus does not demand a capacity for locomotion or traditional \"eyes and ears\".  It can be regarded as sufficient for an intelligent computer to interact with other systems, to invoke or regulate them, to achieve specific goals, including altering a physical environment, as HAL in  2001: A Space Odyssey was both programmed and tasked to.", "mimetype": "text/plain", "start_char_idx": 3909, "end_char_idx": 6257, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bdfcbf9a-0817-422c-825b-51877467fd14": {"__data__": {"id_": "bdfcbf9a-0817-422c-825b-51877467fd14", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "586357", "node_type": "4", "metadata": {}, "hash": "c1cb6325bbd1cbea4a0de6e688f417ec4ca9301c5924b53445ada99952b4f0c7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7b447c0d-5a60-405a-bcfe-c6ed26cc5338", "node_type": "1", "metadata": {}, "hash": "a51e13790ed1c2d7ea5584cf7adf8d71197432d1effe22036f4321db26ea850d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b04524bc-6796-4c4c-a4cd-7f0e8fcf2ac4", "node_type": "1", "metadata": {}, "hash": "9a9539119a33d4524a4b5ee550c565ee21d9b3db97546ebb574a2c4b13f5908f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Tests for human-level AGI ===\nSeveral tests meant to confirm human-level AGI have been considered, including:\n\nThe Turing Test (Turing)\nProposed by Alan Turing in his 1950 paper \"Computing Machinery and Intelligence\", this test involves a human judge engaging in natural language conversations with both a human and a machine designed to generate human-like responses. The machine passes the test if it can convince the judge it is human a significant fraction of the time. Turing proposed this as a practical measure of machine intelligence, focusing on the ability to produce human-like responses rather than on the internal workings of the machine.\nTuring described the test as follows:\nThe idea of the test is that the machine has to try and pretend to be a man, by answering questions put to it, and it will only pass if the pretence is reasonably convincing. A considerable portion of a jury, who should not be expert about machines, must be taken in by the pretence.\nIn 2014, a chatbot named Eugene Goostman, designed to imitate a 13-year-old Ukrainian boy, reportedly passed a Turing Test event by convincing 33% of judges that it was human. However, this claim was met with significant skepticism from the AI research community, who questioned the test's implementation and its relevance to AGI.\nIn 2023, it was claimed that \"AI is closer to ever\" to passing the Turing test, though the article's authors reinforced that imitation (as \"large language models\" ever closer to passing the test are built upon) is not synonymous with \"intelligence\".  Further, as AI intelligence and human intelligence may differ, \"passing the Turing test is good evidence a system is intelligent, failing it is not good evidence a system is not intelligent.\"\nA 2024 study suggested that GPT-4 was identified as human 54% of the time in a randomized, controlled version of the Turing Test\u2014surpassing older chatbots like ELIZA while still falling behind actual humans (67%).\nA 2025 pre\u2011registered, three\u2011party Turing\u2011test study by Cameron R. Jones and Benjamin K. Bergen showed that GPT-4.5 was judged to be the human in 73% of five\u2011minute text conversations\u2014surpassing the 67% humanness rate of real confederates and meeting the researchers\u2019 criterion for having passed the test.\nThe Robot College Student Test (Goertzel)\nA machine enrolls in a university, taking and passing the same classes that humans would, and obtaining a degree. LLMs can now pass university degree-level exams without even attending the classes.\nThe Employment Test (Nilsson)\nA machine performs an economically important job at least as well as humans in the same job. AIs are now replacing humans in many roles as varied as fast food and marketing.\nThe Ikea test (Marcus)\nAlso known as the Flat Pack Furniture Test. An AI views the parts and instructions of an Ikea flat-pack product, then controls a robot to assemble the furniture correctly.\nThe Coffee Test (Wozniak)\nA machine is required to enter an average American home and figure out how to make coffee: find the coffee machine, find the coffee, add water, find a mug, and brew the coffee by pushing the proper buttons. This has not yet been completed.\nThe Modern Turing Test (Suleyman)\nAn AI model is given $100,000 and has to obtain $1 million.\n\n\n=== AI-complete problems ===\n\nA problem is informally called \"AI-complete\" or \"AI-hard\" if it is believed that in order to solve it, one would need to implement AGI, because the solution is beyond the capabilities of a purpose-specific algorithm.\nThere are many problems that have been conjectured to require general intelligence to solve as well as humans. Examples include computer vision, natural language understanding, and dealing with unexpected circumstances while solving any real-world problem. Even a specific task like translation requires a machine to read and write in both languages, follow the author's argument (reason), understand the context (knowledge), and faithfully reproduce the author's original intent (social intelligence). All of these problems need to be solved simultaneously in order to reach human-level machine performance.\nHowever, many of these tasks can now be performed by modern large language models. According to Stanford University's 2024 AI index, AI has reached human-level performance on many benchmarks for reading comprehension and visual reasoning.\n\n\n== History ==", "mimetype": "text/plain", "start_char_idx": 6260, "end_char_idx": 10643, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b04524bc-6796-4c4c-a4cd-7f0e8fcf2ac4": {"__data__": {"id_": "b04524bc-6796-4c4c-a4cd-7f0e8fcf2ac4", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "586357", "node_type": "4", "metadata": {}, "hash": "c1cb6325bbd1cbea4a0de6e688f417ec4ca9301c5924b53445ada99952b4f0c7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bdfcbf9a-0817-422c-825b-51877467fd14", "node_type": "1", "metadata": {}, "hash": "7216c69cf5cfd2365bfcb24e11de5377e73fbe7297c3132733519a0238358453", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0eda3fc6-d5e3-4190-b3c3-0af70b6748e7", "node_type": "1", "metadata": {}, "hash": "4999b953648ab21b25cc958b401ba8e0aa6c10f699d1837dbdfb2d5e97f7051f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== History ==\n\n\n=== Classical AI ===\n\nModern AI research began in the mid-1950s. The first generation of AI researchers were convinced that artificial general intelligence was possible and that it would exist in just a few decades. AI pioneer Herbert A. Simon wrote in 1965: \"machines will be capable, within twenty years, of doing any work a man can do.\"\nTheir predictions were the inspiration for Stanley Kubrick and Arthur C. Clarke's character HAL 9000, who embodied what AI researchers believed they could create by the year 2001. AI pioneer Marvin Minsky was a consultant on the project of making HAL 9000 as realistic as possible according to the consensus predictions of the time. He said in 1967, \"Within a generation... the problem of creating 'artificial intelligence' will substantially be solved\".\nSeveral classical AI projects, such as Doug Lenat's Cyc project (that began in 1984), and Allen Newell's Soar project, were directed at AGI.\nHowever, in the early 1970s, it became obvious that researchers had grossly underestimated the difficulty of the project. Funding agencies became skeptical of AGI and put researchers under increasing pressure to produce useful \"applied AI\". In the early 1980s, Japan's Fifth Generation Computer Project revived interest in AGI, setting out a ten-year timeline that included AGI goals like \"carry on a casual conversation\". In response to this and the success of expert systems, both industry and government pumped money into the field. However, confidence in AI spectacularly collapsed in the late 1980s, and the goals of the Fifth Generation Computer Project were never fulfilled. For the second time in 20 years, AI researchers who predicted the imminent achievement of AGI had been mistaken. By the 1990s, AI researchers had a reputation for making vain promises. They became reluctant to make predictions at all and avoided mention of \"human level\" artificial intelligence for fear of being labeled \"wild-eyed dreamer[s]\".\n\n\n=== Narrow AI research ===\n\nIn the 1990s and early 21st century, mainstream AI achieved commercial success and academic respectability by focusing on specific sub-problems where AI can produce verifiable results and commercial applications, such as speech recognition and recommendation algorithms. These \"applied AI\" systems are now used extensively throughout the technology industry, and research in this vein is heavily funded in both academia and industry. As of 2018, development in this field was considered an emerging trend, and a mature stage was expected to be reached in more than 10 years.\n\nAt the turn of the century, many mainstream AI researchers hoped that strong AI could be developed by combining programs that solve various sub-problems. Hans Moravec wrote in 1988: I am confident that this bottom-up route to artificial intelligence will one day meet the traditional top-down route more than half way, ready to provide the real-world competence and the commonsense knowledge that has been so frustratingly elusive in reasoning programs. Fully intelligent machines will result when the metaphorical golden spike is driven uniting the two efforts.\nHowever, even at the time, this was disputed. For example, Stevan Harnad of Princeton University concluded his 1990 paper on the symbol grounding hypothesis by stating: The expectation has often been voiced that \"top-down\" (symbolic) approaches to modeling cognition will somehow meet \"bottom-up\" (sensory) approaches somewhere in between. If the grounding considerations in this paper are valid, then this expectation is hopelessly modular and there is really only one viable route from sense to symbols: from the ground up. A free-floating symbolic level like the software level of a computer will never be reached by this route (or vice versa) \u2013 nor is it clear why we should even try to reach such a level, since it looks as if getting there would just amount to uprooting our symbols from their intrinsic meanings (thereby merely reducing ourselves to the functional equivalent of a programmable computer).", "mimetype": "text/plain", "start_char_idx": 10630, "end_char_idx": 14689, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0eda3fc6-d5e3-4190-b3c3-0af70b6748e7": {"__data__": {"id_": "0eda3fc6-d5e3-4190-b3c3-0af70b6748e7", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "586357", "node_type": "4", "metadata": {}, "hash": "c1cb6325bbd1cbea4a0de6e688f417ec4ca9301c5924b53445ada99952b4f0c7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b04524bc-6796-4c4c-a4cd-7f0e8fcf2ac4", "node_type": "1", "metadata": {}, "hash": "9a9539119a33d4524a4b5ee550c565ee21d9b3db97546ebb574a2c4b13f5908f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9dd44733-c265-4329-99e6-4e254d3a6553", "node_type": "1", "metadata": {}, "hash": "2e4500e825bb0bb476ee7a45b9632bef672ece4ab05bf681f99526e88e2cfc10", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Modern artificial general intelligence research ===\nThe term \"artificial general intelligence\" was used as early as 1997, by Mark Gubrud in a discussion of the implications of fully automated military production and operations. A mathematical formalism of AGI was proposed by Marcus Hutter in 2000. Named AIXI, the proposed AGI agent maximises \"the ability to satisfy goals in a wide range of environments\". This type of AGI, characterized by the ability to maximise a mathematical definition of intelligence rather than exhibit human-like behaviour, was also called universal artificial intelligence.\nThe term AGI was re-introduced and popularized by Shane Legg and Ben Goertzel around 2002. AGI research activity in 2006 was described by Pei Wang and Ben Goertzel as \"producing publications and preliminary results\". The first summer school in AGI was organized in Xiamen, China in 2009 by the Xiamen university's Artificial Brain Laboratory and OpenCog. The first university course was given in 2010 and 2011 at Plovdiv University, Bulgaria by Todor Arnaudov. MIT presented a course on AGI in 2018, organized by Lex Fridman and featuring a number of guest lecturers.\nAs of 2023, a small number of computer scientists are active in AGI research, and many contribute to a series of AGI conferences. However, increasingly more researchers are interested in open-ended learning, which is the idea of allowing AI to continuously learn and innovate like humans do.\n\n\n=== Feasibility ===\n\nAs of 2023, the development and potential achievement of AGI remains a subject of intense debate within the AI community. While traditional consensus held that AGI was a distant goal, recent advancements have led some researchers and industry figures to claim that early forms of AGI may already exist. AI pioneer Herbert A. Simon speculated in 1965 that \"machines will be capable, within twenty years, of doing any work a man can do\". This prediction failed to come true. Microsoft co-founder Paul Allen believed that such intelligence is unlikely in the 21st century because it would require \"unforeseeable and fundamentally unpredictable breakthroughs\" and a \"scientifically deep understanding of cognition\". Writing in The Guardian, roboticist Alan Winfield claimed the gulf between modern computing and human-level artificial intelligence is as wide as the gulf between current space flight and practical faster-than-light spaceflight.\nA further challenge is the lack of clarity in defining what intelligence entails. Does it require consciousness? Must it display the ability to set goals as well as pursue them? Is it purely a matter of scale such that if model sizes increase sufficiently, intelligence will emerge? Are facilities such as planning, reasoning, and causal understanding required? Does intelligence require explicitly replicating the brain and its specific faculties? Does it require emotions?\nMost AI researchers believe strong AI can be achieved in the future, but some thinkers, like Hubert Dreyfus and Roger Penrose, deny the possibility of achieving strong AI.  John McCarthy is among those who believe human-level AI will be accomplished, but that the present level of progress is such that a date cannot accurately be predicted. AI experts' views on the feasibility of AGI wax and wane. Four polls conducted in 2012 and 2013 suggested that the median estimate among experts for when they would be 50% confident AGI would arrive was 2040 to 2050, depending on the poll, with the mean being 2081. Of the experts, 16.5% answered with \"never\" when asked the same question but with a 90% confidence instead. Further current AGI progress considerations can be found above Tests for confirming human-level AGI.\nA report by Stuart Armstrong and Kaj Sotala of the Machine Intelligence Research Institute found that \"over [a] 60-year time frame there is a strong bias towards predicting the arrival of human-level AI as between 15 and 25 years from the time the prediction was made\". They analyzed 95 predictions made between 1950 and 2012 on when human-level AI will come about.\nIn 2023, Microsoft researchers published a detailed evaluation of GPT-4. They concluded: \"Given the breadth and depth of GPT-4\u2019s capabilities, we believe that it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system.\" Another study in 2023 reported that GPT-4 outperforms 99% of humans on the Torrance tests of creative thinking.\nBlaise Ag\u00fcera y Arcas and Peter Norvig wrote in 2023 that a significant level of general intelligence has already been achieved with frontier models.", "mimetype": "text/plain", "start_char_idx": 14692, "end_char_idx": 19326, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9dd44733-c265-4329-99e6-4e254d3a6553": {"__data__": {"id_": "9dd44733-c265-4329-99e6-4e254d3a6553", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "586357", "node_type": "4", "metadata": {}, "hash": "c1cb6325bbd1cbea4a0de6e688f417ec4ca9301c5924b53445ada99952b4f0c7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0eda3fc6-d5e3-4190-b3c3-0af70b6748e7", "node_type": "1", "metadata": {}, "hash": "4999b953648ab21b25cc958b401ba8e0aa6c10f699d1837dbdfb2d5e97f7051f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6ceb34b9-66c3-4a86-9459-4f33b1a50d7f", "node_type": "1", "metadata": {}, "hash": "c19f7a9eade4a2e076070e9277c1fda340c6c507344f9b9b1c7a182b4df62628", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "They analyzed 95 predictions made between 1950 and 2012 on when human-level AI will come about.\nIn 2023, Microsoft researchers published a detailed evaluation of GPT-4. They concluded: \"Given the breadth and depth of GPT-4\u2019s capabilities, we believe that it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system.\" Another study in 2023 reported that GPT-4 outperforms 99% of humans on the Torrance tests of creative thinking.\nBlaise Ag\u00fcera y Arcas and Peter Norvig wrote in 2023 that a significant level of general intelligence has already been achieved with frontier models. They wrote that reluctance to this view comes from four main reasons: a \"healthy skepticism about metrics for AGI\", an \"ideological commitment to alternative AI theories or techniques\", a \"devotion to human (or biological) exceptionalism\", or a \"concern about the economic implications of AGI\".\n2023 also marked the emergence of large multimodal models (large language models capable of processing or generating multiple modalities such as text, audio, and images).\nIn 2024, OpenAI released o1-preview, the first of a series of models that \"spend more time thinking before they respond\". According to Mira Murati, this ability to think before responding represents a new, additional paradigm. It improves model outputs by spending more computing power when generating the answer, whereas the model scaling paradigm improves outputs by increasing the model size, training data and training compute power.\nAn OpenAI employee, Vahid Kazemi, claimed in 2024 that the company had achieved AGI, stating, \"In my opinion, we have already achieved AGI and it's even more clear with O1.\" Kazemi clarified that while the AI is not yet \"better than any human at any task\", it is \"better than most humans at most tasks.\" He also addressed criticisms that large language models (LLMs) merely follow predefined patterns, comparing their learning process to the scientific method of observing, hypothesizing, and verifying. These statements have sparked debate, as they rely on a broad and unconventional definition of AGI\u2014traditionally understood as AI that matches human intelligence across all domains. Critics argue that, while OpenAI's models demonstrate remarkable versatility, they may not fully meet this standard. Notably, Kazemi's comments came shortly after OpenAI removed \"AGI\" from the terms of its partnership with Microsoft, prompting speculation about the company's strategic intentions.", "mimetype": "text/plain", "start_char_idx": 18684, "end_char_idx": 21214, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6ceb34b9-66c3-4a86-9459-4f33b1a50d7f": {"__data__": {"id_": "6ceb34b9-66c3-4a86-9459-4f33b1a50d7f", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "586357", "node_type": "4", "metadata": {}, "hash": "c1cb6325bbd1cbea4a0de6e688f417ec4ca9301c5924b53445ada99952b4f0c7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9dd44733-c265-4329-99e6-4e254d3a6553", "node_type": "1", "metadata": {}, "hash": "2e4500e825bb0bb476ee7a45b9632bef672ece4ab05bf681f99526e88e2cfc10", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "10798049-51e8-480a-a388-00fad2912bd8", "node_type": "1", "metadata": {}, "hash": "4096803f80cf31cd16e12a9208aaa4b30b362b371e2b844abe017725a2676095", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Kazemi clarified that while the AI is not yet \"better than any human at any task\", it is \"better than most humans at most tasks.\" He also addressed criticisms that large language models (LLMs) merely follow predefined patterns, comparing their learning process to the scientific method of observing, hypothesizing, and verifying. These statements have sparked debate, as they rely on a broad and unconventional definition of AGI\u2014traditionally understood as AI that matches human intelligence across all domains. Critics argue that, while OpenAI's models demonstrate remarkable versatility, they may not fully meet this standard. Notably, Kazemi's comments came shortly after OpenAI removed \"AGI\" from the terms of its partnership with Microsoft, prompting speculation about the company's strategic intentions.\n\n\n=== Timescales ===\n\nProgress in artificial intelligence has historically gone through periods of rapid progress separated by periods when progress appeared to stop. Ending each hiatus were fundamental advances in hardware, software or both to create space for further progress. For example, the computer hardware available in the twentieth century was not sufficient to implement deep learning, which requires large numbers of GPU-enabled CPUs.\nIn the introduction to his 2006 book, Goertzel says that estimates of the time needed before a truly flexible AGI is built vary from 10 years to over a century. As of 2007, the consensus in the AGI research community seemed to be that the timeline discussed by Ray Kurzweil in 2005 in The Singularity is Near (i.e. between 2015 and 2045) was plausible. Mainstream AI researchers have given a wide range of opinions on whether progress will be this rapid. A 2012 meta-analysis of 95 such opinions found a bias towards predicting that the onset of AGI would occur within 16\u201326 years for modern and historical predictions alike. That paper has been criticized for how it categorized opinions as expert or non-expert.\nIn 2012, Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton developed a neural network called AlexNet, which won the ImageNet competition with a top-5 test error rate of 15.3%, significantly better than the second-best entry's rate of 26.3% (the traditional approach used a weighted sum of scores from different pre-defined classifiers). AlexNet was regarded as the initial ground-breaker of the current deep learning wave.\nIn 2017, researchers Feng Liu, Yong Shi, and Ying Liu conducted intelligence tests on publicly available and freely accessible weak AI such as Google AI, Apple's Siri, and others. At the maximum, these AIs reached an IQ value of about 47, which corresponds approximately to a six-year-old child in first grade. An adult comes to about 100 on average. Similar tests were carried out in 2014, with the IQ score reaching a maximum value of 27.\nIn 2020, OpenAI developed GPT-3, a language model capable of performing many diverse tasks without specific training. According to Gary Grossman in a VentureBeat article, while there is consensus that GPT-3 is not an example of AGI, it is considered by some to be too advanced to be classified as a narrow AI system.\nIn the same year, Jason Rohrer used his GPT-3 account to develop a chatbot, and provided a chatbot-developing platform called \"Project December\". OpenAI asked for changes to the chatbot to comply with their safety guidelines; Rohrer disconnected Project December from the GPT-3 API.\nIn 2022, DeepMind developed Gato, a \"general-purpose\" system capable of performing more than 600 different tasks.\nIn 2023, Microsoft Research published a study on an early version of OpenAI's GPT-4, contending that it exhibited more general intelligence than previous AI models and demonstrated human-level performance in tasks spanning multiple domains, such as mathematics, coding, and law. This research sparked a debate on whether GPT-4 could be considered an early, incomplete version of artificial general intelligence, emphasizing the need for further exploration and evaluation of such systems.\nIn 2023, AI researcher Geoffrey Hinton stated that:\n\nThe idea that this stuff could actually get smarter than people \u2013 a few people believed that, [...]. But most people thought it was way off. And I thought it was way off. I thought it was 30 to 50 years or even longer away. Obviously, I no longer think that.He estimated in 2024 (with low confidence) that systems smarter than humans could appear within 5 to 20 years and stressed the attendant existential risks.\nIn May 2023, Demis Hassabis similarly said that \"The progress in the last few years has been pretty incredible\", and that he sees no reason why it would slow down, expecting AGI within a decade or even a few years. In March 2024, Nvidia's CEO, Jensen Huang, stated his expectation that within five years, AI would be capable of passing any test at least as well as humans. In June 2024, the AI researcher Leopold Aschenbrenner, a former OpenAI employee, estimated AGI by 2027 to be \"strikingly plausible\".", "mimetype": "text/plain", "start_char_idx": 20405, "end_char_idx": 25418, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "10798049-51e8-480a-a388-00fad2912bd8": {"__data__": {"id_": "10798049-51e8-480a-a388-00fad2912bd8", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "586357", "node_type": "4", "metadata": {}, "hash": "c1cb6325bbd1cbea4a0de6e688f417ec4ca9301c5924b53445ada99952b4f0c7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6ceb34b9-66c3-4a86-9459-4f33b1a50d7f", "node_type": "1", "metadata": {}, "hash": "c19f7a9eade4a2e076070e9277c1fda340c6c507344f9b9b1c7a182b4df62628", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8ff03e25-071c-404f-99d4-4824afdbd881", "node_type": "1", "metadata": {}, "hash": "300e9ee5ff2c52831a6b59137150e35df0e0694ecf430b960fbad171912c0958", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Whole brain emulation ==\n\nWhile the development of transformer models like in ChatGPT is considered the most promising path to AGI, whole brain emulation can serve as an alternative approach. With whole brain simulation, a brain model is built by scanning and mapping a biological brain in detail, and then copying and simulating it on a computer system or another computational device. The simulation model must be sufficiently faithful to the original, so that it behaves in practically the same way as the original brain. Whole brain emulation is a type of brain simulation that is discussed in computational neuroscience and neuroinformatics, and for medical research purposes. It has been discussed in artificial intelligence research as an approach to strong AI. Neuroimaging technologies that could deliver the necessary detailed understanding are improving rapidly, and futurist Ray Kurzweil in the book The Singularity Is Near predicts that a map of sufficient quality will become available on a similar timescale to the computing power required to emulate it.\n\n\n=== Early estimates ===\n For low-level brain simulation, a very powerful cluster of computers or GPUs would be required, given the enormous quantity of synapses within the human brain. Each of the 1011 (one hundred billion) neurons has on average 7,000 synaptic connections (synapses) to other neurons. The brain of a three-year-old child has about 1015 synapses (1 quadrillion). This number declines with age, stabilizing by adulthood. Estimates vary for an adult, ranging from 1014 to 5\u00d71014 synapses (100 to 500 trillion). An estimate of the brain's processing power, based on a simple switch model for neuron activity, is around 1014 (100 trillion) synaptic updates per second (SUPS).\nIn 1997, Kurzweil looked at various estimates for the hardware required to equal the human brain and adopted a figure of 1016 computations per second (cps). (For comparison, if a \"computation\" was equivalent to one \"floating-point operation\" \u2013 a measure used to rate current supercomputers \u2013 then 1016 \"computations\" would be equivalent to 10 petaFLOPS, achieved in 2011, while 1018 was achieved in 2022.) He used this figure to predict the necessary hardware would be available sometime between 2015 and 2025, if the exponential growth in computer power at the time of writing continued.\n\n\n=== Current research ===\nThe Human Brain Project, an EU-funded initiative active from 2013 to 2023, has developed a particularly detailed and publicly accessible atlas of the human brain. In 2023, researchers from Duke University performed a high-resolution scan of a mouse brain.\n\n\n=== Criticisms of simulation-based approaches ===\nThe artificial neuron model assumed by Kurzweil and used in many current artificial neural network implementations is simple compared with biological neurons. A brain simulation would likely have to capture the detailed cellular behaviour of biological neurons, presently understood only in broad outline. The overhead introduced by full modeling of the biological, chemical, and physical details of neural behaviour (especially on a molecular scale) would require computational powers several orders of magnitude larger than Kurzweil's estimate. In addition, the estimates do not account for glial cells, which are known to play a role in cognitive processes.\nA fundamental criticism of the simulated brain approach derives from embodied cognition theory which asserts that human embodiment is an essential aspect of human intelligence and is necessary to ground meaning. If this theory is correct, any fully functional brain model will need to encompass more than just the neurons (e.g., a robotic body). Goertzel proposes virtual embodiment (like in metaverses like Second Life) as an option, but it is unknown whether this would be sufficient.\n\n\n== Philosophical perspective ==", "mimetype": "text/plain", "start_char_idx": 25421, "end_char_idx": 29290, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8ff03e25-071c-404f-99d4-4824afdbd881": {"__data__": {"id_": "8ff03e25-071c-404f-99d4-4824afdbd881", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "586357", "node_type": "4", "metadata": {}, "hash": "c1cb6325bbd1cbea4a0de6e688f417ec4ca9301c5924b53445ada99952b4f0c7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "10798049-51e8-480a-a388-00fad2912bd8", "node_type": "1", "metadata": {}, "hash": "4096803f80cf31cd16e12a9208aaa4b30b362b371e2b844abe017725a2676095", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b277bf26-e080-4d95-9088-b9c69407f85d", "node_type": "1", "metadata": {}, "hash": "467a817ecedaa1dd7ba26612fb90c8c4f8e2a50caacedb113b4c9aa5f1f32433", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Philosophical perspective ==\n\n\n=== \"Strong AI\" as defined in philosophy ===\nIn 1980, philosopher John Searle coined the term \"strong AI\" as part of his Chinese room argument. He proposed a distinction between two hypotheses about artificial intelligence:\n\nStrong AI hypothesis: An artificial intelligence system can have \"a mind\" and \"consciousness\".\nWeak AI hypothesis: An artificial intelligence system can (only) act like it thinks and has a mind and consciousness.\nThe first one he called \"strong\" because it makes a stronger statement: it assumes something special has happened to the machine that goes beyond those abilities that we can test. The behaviour of a \"weak AI\" machine would be precisely identical to a \"strong AI\" machine, but the latter would also have subjective conscious experience. This usage is also common in academic AI research and textbooks.\nIn contrast to Searle and mainstream AI, some futurists such as Ray Kurzweil use the term \"strong AI\" to mean \"human level artificial general intelligence\". This is not the same as Searle's strong AI, unless it is assumed that consciousness is necessary for human-level AGI. Academic philosophers such as Searle do not believe that is the case, and to most artificial intelligence researchers the question is out-of-scope.\nMainstream AI is most interested in how a program behaves. According to Russell and Norvig, \"as long as the program works, they don't care if you call it real or a simulation.\" If the program can behave as if it has a mind, then there is no need to know if it actually has mind \u2013 indeed, there would be no way to tell. For AI research, Searle's \"weak AI hypothesis\" is equivalent to the statement \"artificial general intelligence is possible\". Thus, according to Russell and Norvig, \"most AI researchers take the weak AI hypothesis for granted, and don't care about the strong AI hypothesis.\" Thus, for academic AI research, \"Strong AI\" and \"AGI\" are two different things.\n\n\n=== Consciousness ===\n\nConsciousness can have various meanings, and some aspects play significant roles in science fiction and the ethics of artificial intelligence:\n\nSentience (or \"phenomenal consciousness\"): The ability to \"feel\" perceptions or emotions subjectively, as opposed to the ability to reason about perceptions. Some philosophers, such as David Chalmers, use the term \"consciousness\" to refer exclusively to phenomenal consciousness, which is roughly equivalent to sentience. Determining why and how subjective experience arises is known as the hard problem of consciousness. Thomas Nagel explained in 1974 that it \"feels like\" something to be conscious. If we are not conscious, then it doesn't feel like anything. Nagel uses the example of a bat: we can sensibly ask \"what does it feel like to be a bat?\" However, we are unlikely to ask \"what does it feel like to be a toaster?\" Nagel concludes that a bat appears to be conscious (i.e., has consciousness) but a toaster does not. In 2022, a Google engineer claimed that the company's AI chatbot, LaMDA, had achieved sentience, though this claim was widely disputed by other experts.\nSelf-awareness: To have conscious awareness of oneself as a separate individual, especially to be consciously aware of one's own thoughts. This is opposed to simply being the \"subject of one's thought\"\u2014an operating system or debugger is able to be \"aware of itself\" (that is, to represent itself in the same way it represents everything else)\u2014but this is not what people typically mean when they use the term \"self-awareness\". In some advanced AI models, systems construct internal representations of their own cognitive processes and feedback patterns\u2014occasionally referring to themselves using second-person constructs such as \u2018you\u2019 within self-modeling frameworks.\nThese traits have a moral dimension. AI sentience would give rise to concerns of welfare and legal protection, similarly to animals. Other aspects of consciousness related to cognitive capabilities are also relevant to the concept of AI rights. Figuring out how to integrate advanced AI with existing legal and social frameworks is an emergent issue.", "mimetype": "text/plain", "start_char_idx": 29259, "end_char_idx": 33396, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b277bf26-e080-4d95-9088-b9c69407f85d": {"__data__": {"id_": "b277bf26-e080-4d95-9088-b9c69407f85d", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "586357", "node_type": "4", "metadata": {}, "hash": "c1cb6325bbd1cbea4a0de6e688f417ec4ca9301c5924b53445ada99952b4f0c7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8ff03e25-071c-404f-99d4-4824afdbd881", "node_type": "1", "metadata": {}, "hash": "300e9ee5ff2c52831a6b59137150e35df0e0694ecf430b960fbad171912c0958", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8182a4f9-ad06-4f9c-b7bb-ed35c906a561", "node_type": "1", "metadata": {}, "hash": "312555720cecea3b445c8d1b66062156285e847c713c5044a12b0f262984bc33", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Benefits ==\nAGI could improve productivity and efficiency in most jobs. For example, in public health, AGI could accelerate medical research, notably against cancer. It could take care of the elderly, and democratize access to rapid, high-quality medical diagnostics. It could offer fun, cheap and personalized education. The need to work to subsist could become obsolete if the wealth produced is properly redistributed. This also raises the question of the place of humans in a radically automated society.\nAGI could also help to make rational decisions, and to anticipate and prevent disasters. It could also help to reap the benefits of potentially catastrophic technologies such as nanotechnology or climate engineering, while avoiding the associated risks. If an AGI's primary goal is to prevent existential catastrophes such as human extinction (which could be difficult if the Vulnerable World Hypothesis turns out to be true), it could take measures to drastically reduce the risks while minimizing the impact of these measures on our quality of life.\n\n\n=== Advancements in medicine and healthcare ===\nAGI would improve healthcare by making medical diagnostics faster, cheaper, and more accurate. AI-driven systems can analyse patient data and detect diseases at an early stage. This means patients will get diagnosed quicker and be able to seek medical attention before their medical condition gets worse. AGI systems could also recommend personalised treatment plans based on genetics and medical history.\nAdditionally, AGI could accelerate drug discovery by simulating molecular interactions, reducing the time it takes to develop new medicines for conditions like cancer and Alzheimer's. In hospitals, AGI-powered robotic assistants could assist in surgeries, monitor patients, and provide real-time medical support. It could also be used in elderly care, helping aging populations maintain independence through AI-powered caregivers and health-monitoring systems.\nBy evaluating large datasets, AGI can assist in developing personalised treatment plans tailored to individual patient needs. This approach ensures that therapies are optimised based on a patient's unique medical history and genetic profile, improving outcomes and reducing adverse effects.\n\n\n=== Advancements in science and technology ===\nAGI can become a tool for scientific research and innovation. In fields such as physics and mathematics, AGI could help solve complex problems that require massive computational power, such as modeling quantum systems, understanding dark matter, or proving mathematical theorems. Problems that have remained unsolved for decades may be solved with AGI.\nAGI could also drive technological breakthroughs that could reshape society. It can do this by optimising engineering designs, discovering new materials, and improving automation. For example, AI is already playing a role in developing more efficient renewable energy sources and optimising supply chains in manufacturing. Future AGI systems could push these innovations even further.\n\n\n=== Enhancing education and productivity ===\nAGI can personalize education by creating learning programs that are specific to each student's strengths, weaknesses, and interests. Unlike traditional teaching methods, AI-driven tutoring systems could adapt lessons in real-time, ensuring students understand difficult concepts before moving on.\nIn the workplace, AGI could automate repetitive tasks, freeing up workers for more creative and strategic roles. It could also improve efficiency across industries by optimising logistics, enhancing cybersecurity, and streamlining business operations. If properly managed, the wealth generated by AGI-driven automation could reduce the need for people to work for a living. Working may become optional.\n\n\n=== Mitigating global crises ===\nAGI could play a crucial role in preventing and managing global threats. It could help governments and organizations predict and respond to natural disasters more effectively, using real-time data analysis to forecast hurricanes, earthquakes, and pandemics. By analyzing vast datasets from satellites, sensors, and historical records, AGI could improve early warning systems, enabling faster disaster response and minimising casualties.\nIn climate science, AGI could develop new models for reducing carbon emissions, optimising energy resources, and mitigating climate change effects. It could also enhance weather prediction accuracy, allowing policymakers to implement more effective environmental regulations. Additionally, AGI could help regulate emerging technologies that carry significant risks, such as nanotechnology and bioengineering, by analysing complex systems and predicting unintended consequences. Furthermore, AGI could assist in cybersecurity by detecting and mitigating large-scale cyber threats, protecting critical infrastructure, and preventing digital warfare.\n\n\n=== Revitalising environmental conservation and biodiversity ===\nAGI could significantly contribute to preserving the environment and protecting endangered species. By analyzing satellite imagery, climate data, and wildlife patterns, AGI systems could identify environmental threats earlier and recommend targeted conservation strategies. AGI could help optimize land use, monitor illegal activities like poaching or deforestation in real-time, and support global efforts to restore ecosystems. Advanced predictive models developed by AGI could also assist in reversing biodiversity loss, ensuring the survival of critical species and maintaining ecological balance.", "mimetype": "text/plain", "start_char_idx": 33399, "end_char_idx": 38994, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8182a4f9-ad06-4f9c-b7bb-ed35c906a561": {"__data__": {"id_": "8182a4f9-ad06-4f9c-b7bb-ed35c906a561", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "586357", "node_type": "4", "metadata": {}, "hash": "c1cb6325bbd1cbea4a0de6e688f417ec4ca9301c5924b53445ada99952b4f0c7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b277bf26-e080-4d95-9088-b9c69407f85d", "node_type": "1", "metadata": {}, "hash": "467a817ecedaa1dd7ba26612fb90c8c4f8e2a50caacedb113b4c9aa5f1f32433", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "55eb2b02-b8da-458d-92c5-81e7c707aaf3", "node_type": "1", "metadata": {}, "hash": "b26d8c3fa54e4aa4743aab8378c8c3e86db7ead2d0fc6db1d8353decab2cf899", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Revitalising environmental conservation and biodiversity ===\nAGI could significantly contribute to preserving the environment and protecting endangered species. By analyzing satellite imagery, climate data, and wildlife patterns, AGI systems could identify environmental threats earlier and recommend targeted conservation strategies. AGI could help optimize land use, monitor illegal activities like poaching or deforestation in real-time, and support global efforts to restore ecosystems. Advanced predictive models developed by AGI could also assist in reversing biodiversity loss, ensuring the survival of critical species and maintaining ecological balance.\n\n\n=== Enhancing space exploration and colonization ===\nAGI could revolutionize humanity\u2019s ability to explore and settle beyond Earth. With its advanced problem-solving skills, AGI could autonomously manage complex space missions, including navigation, resource management, and emergency response. It could accelerate the design of life support systems, habitats, and spacecraft optimized for extraterrestrial environments. Furthermore, AGI could support efforts to colonize planets like Mars by simulating survival scenarios and helping humans adapt to new worlds, dramatically expanding the possibilities for interplanetary civilization.\n\n\n== Risks ==\n\n\n=== Existential risks ===\n\nAGI may represent multiple types of existential risk, which are risks that threaten \"the premature extinction of Earth-originating intelligent life or the permanent and drastic destruction of its potential for desirable future development\". The risk of human extinction from AGI has been the topic of many debates, but there is also the possibility that the development of AGI would lead to a permanently flawed future. Notably, it could be used to spread and preserve the set of values of whoever develops it. If humanity still has moral blind spots similar to slavery in the past, AGI might irreversibly entrench it, preventing moral progress. Furthermore, AGI could facilitate mass surveillance and indoctrination, which could be used to create a stable repressive worldwide totalitarian regime. There is also a risk for the machines themselves. If machines that are sentient or otherwise worthy of moral consideration are mass created in the future, engaging in a civilizational path that indefinitely neglects their welfare and interests could be an existential catastrophe. Considering how much AGI could improve humanity's future and help reduce other existential risks, Toby Ord calls these existential risks \"an argument for proceeding with due caution\", not for \"abandoning AI\".", "mimetype": "text/plain", "start_char_idx": 38328, "end_char_idx": 40965, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "55eb2b02-b8da-458d-92c5-81e7c707aaf3": {"__data__": {"id_": "55eb2b02-b8da-458d-92c5-81e7c707aaf3", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "586357", "node_type": "4", "metadata": {}, "hash": "c1cb6325bbd1cbea4a0de6e688f417ec4ca9301c5924b53445ada99952b4f0c7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8182a4f9-ad06-4f9c-b7bb-ed35c906a561", "node_type": "1", "metadata": {}, "hash": "312555720cecea3b445c8d1b66062156285e847c713c5044a12b0f262984bc33", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Risk of loss of control and human extinction ====\nThe thesis that AI poses an existential risk for humans, and that this risk needs more attention, is controversial but has been endorsed in 2023 by many public figures, AI researchers and CEOs of AI companies such as Elon Musk, Bill Gates, Geoffrey Hinton, Yoshua Bengio, Demis Hassabis and Sam Altman.\nIn 2014, Stephen Hawking criticized widespread indifference:\n\nSo, facing possible futures of incalculable benefits and risks, the experts are surely doing everything possible to ensure the best outcome, right? Wrong. If a superior alien civilisation sent us a message saying, 'We'll arrive in a few decades,' would we just reply, 'OK, call us when you get here\u2014we'll leave the lights on?' Probably not\u2014but this is more or less what is happening with AI.The potential fate of humanity has sometimes been compared to the fate of gorillas threatened by human activities. The comparison states that greater intelligence allowed humanity to dominate gorillas, which are now vulnerable in ways that they could not have anticipated. As a result, the gorilla has become an endangered species, not out of malice, but simply as a collateral damage from human activities.\nThe skeptic Yann LeCun considers that AGIs will have no desire to dominate humanity and that we should be careful not to anthropomorphize them and interpret their intents as we would for humans. He said that people won't be \"smart enough to design super-intelligent machines, yet ridiculously stupid to the point of giving it moronic objectives with no safeguards\". On the other side, the concept of instrumental convergence suggests that almost whatever their goals, intelligent agents will have reasons to try to survive and acquire more power as intermediary steps to achieving these goals. And that this does not require having emotions.\nMany scholars who are concerned about existential risk advocate for more research into solving the \"control problem\" to answer the question: what types of safeguards, algorithms, or architectures can programmers implement to maximise the probability that their recursively-improving AI would continue to behave in a friendly, rather than destructive, manner after it reaches superintelligence? Solving the control problem is complicated by the AI arms race (which could lead to a race to the bottom of safety precautions in order to release products before competitors), and the use of AI in weapon systems.\nThe thesis that AI can pose existential risk also has detractors. Skeptics usually say that AGI is unlikely in the short-term, or that concerns about AGI distract from other issues related to current AI. Former Google fraud czar Shuman Ghosemajumder considers that for many people outside of the technology industry, existing chatbots and LLMs are already perceived as though they were AGI, leading to further misunderstanding and fear.\nSkeptics sometimes charge that the thesis is crypto-religious, with an irrational belief in the possibility of superintelligence replacing an irrational belief in an omnipotent God. Some researchers believe that the communication campaigns on AI existential risk by certain AI groups (such as OpenAI, Anthropic, DeepMind, and Conjecture) may be an at attempt at regulatory capture and to inflate interest in their products.\nIn 2023, the CEOs of Google DeepMind, OpenAI and Anthropic, along with other industry leaders and researchers, issued a joint statement asserting that \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.\"\n\n\n=== Mass unemployment ===\n\nResearchers from OpenAI estimated that \"80% of the U.S. workforce could have at least 10% of their work tasks affected by the introduction of LLMs, while around 19% of workers may see at least 50% of their tasks impacted\". They consider office workers to be the most exposed, for example mathematicians, accountants or web designers. AGI could have a better autonomy, ability to make decisions, to interface with other computer tools, but also to control robotized bodies.\nAccording to Stephen Hawking, the outcome of automation on the quality of life will depend on how the wealth will be redistributed:\n\nEveryone can enjoy a life of luxurious leisure if the machine-produced wealth is shared, or most people can end up miserably poor if the machine-owners successfully lobby against wealth redistribution. So far, the trend seems to be toward the second option, with technology driving ever-increasing inequalityElon Musk believes that the automation of society will require governments to adopt a universal basic income.\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Sources ==\n\n\n== Further reading ==\n\n\n== External links ==\nThe AGI portal maintained by Pei Wang", "mimetype": "text/plain", "start_char_idx": 40968, "end_char_idx": 45796, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6020b7f7-5892-4b47-9133-b2d8cc4da41b": {"__data__": {"id_": "6020b7f7-5892-4b47-9133-b2d8cc4da41b", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "726659", "node_type": "4", "metadata": {}, "hash": "341f2972b85a37a52d0b7b36a021cb08664fdf14343b0cf97eb85cfc57b934f0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "71156f56-bdea-427d-b8d2-6e4cbb90c821", "node_type": "1", "metadata": {}, "hash": "39fb6d37ae9cefac1fd50317ff33b9f527d3c4814cfd8567ebe1b8e33a42f02b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "A superintelligence is a hypothetical agent that possesses intelligence surpassing that of the brightest and most gifted human minds. \"Superintelligence\" may also refer to a property of advanced problem-solving systems that excel in specific areas (e.g., superintelligent language translators or engineering assistants). Nevertheless, a general purpose superintelligence remains hypothetical and its creation may or may not be triggered by an intelligence explosion or a technological singularity.\nUniversity of Oxford philosopher Nick Bostrom defines superintelligence as \"any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest\". The program Fritz falls short of this conception of superintelligence\u2014even though it is much better than humans at chess\u2014because Fritz cannot outperform humans in other tasks.\nTechnological researchers disagree about how likely present-day human intelligence is to be surpassed. Some argue that advances in artificial intelligence (AI) will probably result in general reasoning systems that lack human cognitive limitations. Others believe that humans will evolve or directly modify their biology to achieve radically greater intelligence. Several future study scenarios combine elements from both of these possibilities, suggesting that humans are likely to interface with computers, or upload their minds to computers, in a way that enables substantial intelligence amplification.\nSome researchers believe that superintelligence will likely follow shortly after the development of artificial general intelligence. The first generally intelligent machines are likely to immediately hold an enormous advantage in at least some forms of mental capability, including the capacity of perfect recall, a vastly superior knowledge base, and the ability to multitask in ways not possible to biological entities. This may allow them to \u2014 either as a single being or as a new species \u2014 become much more powerful than humans, and displace them.\nSeveral scientists and forecasters have been arguing for prioritizing early research into the possible benefits and risks of human and machine cognitive enhancement, because of the potential social impact of such technologies.\n\n\n== Feasibility of artificial superintelligence ==\n\nThe creation of artificial superintelligence (ASI) has been a topic of increasing discussion in recent years, particularly with the rapid advancements in artificial intelligence (AI) technologies.\n\n\n=== Progress in AI and claims of AGI ===\nRecent developments in AI, particularly in large language models (LLMs) based on the transformer architecture, have led to significant improvements in various tasks. Models like GPT-3, GPT-4, Claude 3.5 and others have demonstrated capabilities that some researchers argue approach or even exhibit aspects of artificial general intelligence (AGI).\nHowever, the claim that current LLMs constitute AGI is controversial. Critics argue that these models, while impressive, still lack true understanding and are primarily sophisticated pattern matching systems.\n\n\n=== Pathways to superintelligence ===\nPhilosopher David Chalmers argues that AGI is a likely path to ASI. He posits that AI can achieve equivalence to human intelligence, be extended to surpass it, and then be amplified to dominate humans across arbitrary tasks.\nMore recent research has explored various potential pathways to superintelligence:\n\nScaling current AI systems \u2013 Some researchers argue that continued scaling of existing AI architectures, particularly transformer-based models, could lead to AGI and potentially ASI.\nNovel architectures \u2013 Others suggest that new AI architectures, potentially inspired by neuroscience, may be necessary to achieve AGI and ASI.\nHybrid systems \u2013 Combining different AI approaches, including symbolic AI and neural networks, could potentially lead to more robust and capable systems.\n\n\n=== Computational advantages ===\nArtificial systems have several potential advantages over biological intelligence:\n\nSpeed \u2013 Computer components operate much faster than biological neurons. Modern microprocessors (~2 GHz) are seven orders of magnitude faster than neurons (~200 Hz).\nScalability \u2013 AI systems can potentially be scaled up in size and computational capacity more easily than biological brains.\nModularity \u2013 Different components of AI systems can be improved or replaced independently.\nMemory \u2013 AI systems can have perfect recall and vast knowledge bases. It is also much less constrained than humans when it comes to working memory.\nMultitasking \u2013 AI can perform multiple tasks simultaneously in ways not possible for biological entities.\n\n\n=== Potential path through transformer models ===\nRecent advancements in transformer-based models have led some researchers to speculate that the path to ASI might lie in scaling up and improving these architectures. This view suggests that continued improvements in transformer models or similar architectures could lead directly to ASI.\nSome experts even argue that current large language models like GPT-4 may already exhibit early signs of AGI or ASI capabilities. This perspective suggests that the transition from current AI to ASI might be more continuous and rapid than previously thought, blurring the lines between narrow AI, AGI, and ASI.\nHowever, this view remains controversial. Critics argue that current models, while impressive, still lack crucial aspects of general intelligence such as true understanding, reasoning, and adaptability across diverse domains.\nThe debate over whether the path to ASI will involve a distinct AGI phase or a more direct scaling of current technologies remains ongoing, with significant implications for AI development strategies and safety considerations.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 5784, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "71156f56-bdea-427d-b8d2-6e4cbb90c821": {"__data__": {"id_": "71156f56-bdea-427d-b8d2-6e4cbb90c821", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "726659", "node_type": "4", "metadata": {}, "hash": "341f2972b85a37a52d0b7b36a021cb08664fdf14343b0cf97eb85cfc57b934f0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6020b7f7-5892-4b47-9133-b2d8cc4da41b", "node_type": "1", "metadata": {}, "hash": "5b082c702a65624e0e85fb5aeb581848d2a56ed4cdee1009adf384df042d31cc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "88c90ed4-92ac-42d5-b3dd-82b6ead7ed98", "node_type": "1", "metadata": {}, "hash": "f59ff68580575288bd00efb8020d40a5eece4db132a01f3563418f0076136ca2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Potential path through transformer models ===\nRecent advancements in transformer-based models have led some researchers to speculate that the path to ASI might lie in scaling up and improving these architectures. This view suggests that continued improvements in transformer models or similar architectures could lead directly to ASI.\nSome experts even argue that current large language models like GPT-4 may already exhibit early signs of AGI or ASI capabilities. This perspective suggests that the transition from current AI to ASI might be more continuous and rapid than previously thought, blurring the lines between narrow AI, AGI, and ASI.\nHowever, this view remains controversial. Critics argue that current models, while impressive, still lack crucial aspects of general intelligence such as true understanding, reasoning, and adaptability across diverse domains.\nThe debate over whether the path to ASI will involve a distinct AGI phase or a more direct scaling of current technologies remains ongoing, with significant implications for AI development strategies and safety considerations.\n\n\n=== Challenges and uncertainties ===\nDespite these potential advantages, there are significant challenges and uncertainties in achieving ASI:\n\nEthical and safety concerns \u2013 The development of ASI raises numerous ethical questions and potential risks that need to be addressed.\nComputational requirements \u2013 The computational resources required for ASI might be far beyond current capabilities.\nFundamental limitations \u2013 There may be fundamental limitations to intelligence that apply to both artificial and biological systems.\nUnpredictability \u2013 The path to ASI and its consequences are highly uncertain and difficult to predict.\nAs research in AI continues to advance rapidly, the question of the feasibility of ASI remains a topic of intense debate and study in the scientific community.\n\n\n== Feasibility of biological superintelligence ==\nCarl Sagan suggested that the advent of Caesarean sections and in vitro fertilization may permit humans to evolve larger heads, resulting in improvements via natural selection in the heritable component of human intelligence. By contrast, Gerald Crabtree has argued that decreased selection pressure is resulting in a slow, centuries-long reduction in human intelligence and that this process instead is likely to continue. There is no scientific consensus concerning either possibility and in both cases, the biological change would be slow, especially relative to rates of cultural change.\nSelective breeding, nootropics, epigenetic modulation, and genetic engineering could improve human intelligence more rapidly. Bostrom writes that if we come to understand the genetic component of intelligence, pre-implantation genetic diagnosis could be used to select for embryos with as much as 4 points of IQ gain (if one embryo is selected out of two), or with larger gains (e.g., up to 24.3 IQ points gained if one embryo is selected out of 1000). If this process is iterated over many generations, the gains could be an order of magnitude improvement. Bostrom suggests that deriving new gametes from embryonic stem cells could be used to iterate the selection process rapidly. A well-organized society of high-intelligence humans of this sort could potentially achieve collective superintelligence.\nAlternatively, collective intelligence might be constructional by better organizing humans at present levels of individual intelligence. Several writers have suggested that human civilization, or some aspect of it (e.g., the Internet, or the economy), is coming to function like a global brain with capacities far exceeding its component agents. If this systemic superintelligence relies heavily on artificial components, however, it may qualify as an AI rather than as a biology-based superorganism. A prediction market is sometimes considered as an example of a working collective intelligence system, consisting of humans only (assuming algorithms are not used to inform decisions).\nA final method of intelligence amplification would be to directly enhance individual humans, as opposed to enhancing their social or reproductive dynamics. This could be achieved using nootropics, somatic gene therapy, or brain\u2212computer interfaces. However, Bostrom expresses skepticism about the scalability of the first two approaches and argues that designing a superintelligent cyborg interface is an AI-complete problem.", "mimetype": "text/plain", "start_char_idx": 4682, "end_char_idx": 9136, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "88c90ed4-92ac-42d5-b3dd-82b6ead7ed98": {"__data__": {"id_": "88c90ed4-92ac-42d5-b3dd-82b6ead7ed98", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "726659", "node_type": "4", "metadata": {}, "hash": "341f2972b85a37a52d0b7b36a021cb08664fdf14343b0cf97eb85cfc57b934f0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "71156f56-bdea-427d-b8d2-6e4cbb90c821", "node_type": "1", "metadata": {}, "hash": "39fb6d37ae9cefac1fd50317ff33b9f527d3c4814cfd8567ebe1b8e33a42f02b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "85af1381-a703-4b44-87a9-ea69dbee7a1d", "node_type": "1", "metadata": {}, "hash": "2596496496cf3e4d336143d2fb6bc2d9ad44cad3b72cd3d0856060ecea1d7401", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Forecasts ==\nMost surveyed AI researchers expect machines to eventually be able to rival humans in intelligence, though there is little consensus on when this will likely happen. At the 2006 AI@50 conference, 18% of attendees reported expecting machines to be able \"to simulate learning and every other aspect of human intelligence\" by 2056; 41% of attendees expected this to happen sometime after 2056; and 41% expected machines to never reach that milestone.\nIn a survey of the 100 most cited authors in AI (as of May 2013, according to Microsoft academic search), the median year by which respondents expected machines \"that can carry out most human professions at least as well as a typical human\" (assuming no global catastrophe occurs) with 10% confidence is 2024 (mean 2034, st. dev. 33 years), with 50% confidence is 2050 (mean 2072, st. dev. 110 years), and with 90% confidence is 2070 (mean 2168, st. dev. 342 years). These estimates exclude the 1.2% of respondents who said no year would ever reach 10% confidence, the 4.1% who said 'never' for 50% confidence, and the 16.5% who said 'never' for 90% confidence. Respondents assigned a median 50% probability to the possibility that machine superintelligence will be invented within 30 years of the invention of approximately human-level machine intelligence.\nIn a 2022 survey, the median year by which respondents expected \"High-level machine intelligence\" with 50% confidence is 2061. The survey defined the achievement of high-level machine intelligence as when unaided machines can accomplish every task better and more cheaply than human workers.\nIn 2023, OpenAI leaders Sam Altman, Greg Brockman and Ilya Sutskever published recommendations for the governance of superintelligence, which they believe may happen in less than 10 years. In 2024, Ilya Sutskever left OpenAI to cofound the startup Safe Superintelligence, which focuses solely on creating a superintelligence that is safe by design, while avoiding \"distraction by management overhead or product cycles\". Despite still offering no product, the startup became valued at $30 billion in February 2025. In 2025, the forecast scenario \"AI 2027\" led by Daniel Kokotajlo predicted rapid progress in the automation of coding and AI research, followed by ASI.\n\n\n== Design considerations ==\nThe design of superintelligent AI systems raises critical questions about what values and goals these systems should have. Several proposals have been put forward:\n\n\n=== Value alignment proposals ===\nCoherent extrapolated volition (CEV) \u2013 The AI should have the values upon which humans would converge if they were more knowledgeable and rational.\nMoral rightness (MR) \u2013 The AI should be programmed to do what is morally right, relying on its superior cognitive abilities to determine ethical actions.\nMoral permissibility (MP) \u2013 The AI should stay within the bounds of moral permissibility while otherwise pursuing goals aligned with human values (similar to CEV).\nBostrom elaborates on these concepts:\n\ninstead of implementing humanity's coherent extrapolated volition, one could try to build an AI to do what is morally right, relying on the AI's superior cognitive capacities to figure out just which actions fit that description. We can call this proposal \"moral rightness\" (MR) ...\nMR would also appear to have some disadvantages. It relies on the notion of \"morally right\", a notoriously difficult concept, one with which philosophers have grappled since antiquity without yet attaining consensus as to its analysis. Picking an erroneous explication of \"moral rightness\" could result in outcomes that would be morally very wrong ...\n\nOne might try to preserve the basic idea of the MR model while reducing its demandingness by focusing on moral permissibility: the idea being that we could let the AI pursue humanity's CEV so long as it did not act in morally impermissible ways.\n\n\n=== Recent developments ===\nSince Bostrom's analysis, new approaches to AI value alignment have emerged:\n\nInverse Reinforcement Learning (IRL) \u2013 This technique aims to infer human preferences from observed behavior, potentially offering a more robust approach to value alignment.\nConstitutional AI \u2013 Proposed by Anthropic, this involves training AI systems with explicit ethical principles and constraints.\nDebate and amplification \u2013 These techniques, explored by OpenAI, use AI-assisted debate and iterative processes to better understand and align with human values.", "mimetype": "text/plain", "start_char_idx": 9139, "end_char_idx": 13607, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "85af1381-a703-4b44-87a9-ea69dbee7a1d": {"__data__": {"id_": "85af1381-a703-4b44-87a9-ea69dbee7a1d", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "726659", "node_type": "4", "metadata": {}, "hash": "341f2972b85a37a52d0b7b36a021cb08664fdf14343b0cf97eb85cfc57b934f0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "88c90ed4-92ac-42d5-b3dd-82b6ead7ed98", "node_type": "1", "metadata": {}, "hash": "f59ff68580575288bd00efb8020d40a5eece4db132a01f3563418f0076136ca2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7f08f025-39b5-4bd9-abfe-bd27d2985975", "node_type": "1", "metadata": {}, "hash": "028a39594893e147f6555b989e562622fd6c62c28160f3ead7a3a17afa9463ee", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Recent developments ===\nSince Bostrom's analysis, new approaches to AI value alignment have emerged:\n\nInverse Reinforcement Learning (IRL) \u2013 This technique aims to infer human preferences from observed behavior, potentially offering a more robust approach to value alignment.\nConstitutional AI \u2013 Proposed by Anthropic, this involves training AI systems with explicit ethical principles and constraints.\nDebate and amplification \u2013 These techniques, explored by OpenAI, use AI-assisted debate and iterative processes to better understand and align with human values.\n\n\n=== Transformer LLMs and ASI ===\nThe rapid advancement of transformer-based LLMs has led to speculation about their potential path to ASI. Some researchers argue that scaled-up versions of these models could exhibit ASI-like capabilities:\n\nEmergent abilities \u2013 As LLMs increase in size and complexity, they demonstrate unexpected capabilities not present in smaller models.\nIn-context learning \u2013 LLMs show the ability to adapt to new tasks without fine-tuning, potentially mimicking general intelligence.\nMulti-modal integration \u2013 Recent models can process and generate various types of data, including text, images, and audio.\nHowever, critics argue that current LLMs lack true understanding and are merely sophisticated pattern matchers, raising questions about their suitability as a path to ASI.\n\n\n=== Other perspectives on artificial superintelligence ===\nAdditional viewpoints on the development and implications of superintelligence include:\n\nRecursive self-improvement \u2013 I. J. Good proposed the concept of an \"intelligence explosion\", where an AI system could rapidly improve its own intelligence, potentially leading to superintelligence.\nOrthogonality thesis \u2013 Bostrom argues that an AI's level of intelligence is orthogonal to its final goals, meaning a superintelligent AI could have any set of motivations.\nInstrumental convergence \u2013 Certain instrumental goals (e.g., self-preservation, resource acquisition) might be pursued by a wide range of AI systems, regardless of their final goals.\n\n\n=== Challenges and ongoing research ===\nThe pursuit of value-aligned AI faces several challenges:\n\nPhilosophical uncertainty in defining concepts like \"moral rightness\"\nTechnical complexity in translating ethical principles into precise algorithms\nPotential for unintended consequences even with well-intentioned approaches\nCurrent research directions include multi-stakeholder approaches to incorporate diverse perspectives, developing methods for scalable oversight of AI systems, and improving techniques for robust value learning.\nAl research is rapidly progressing towards superintelligence. Addressing these design challenges remains crucial for creating ASI systems that are both powerful and aligned with human interests.\n\n\n== Potential threat to humanity ==\n\nThe development of artificial superintelligence (ASI) has raised concerns about potential existential risks to humanity. Researchers have proposed various scenarios in which an ASI could pose a significant threat:\n\n\n=== Intelligence explosion and control problem ===\nSome researchers argue that through recursive self-improvement, an ASI could rapidly become so powerful as to be beyond human control. This concept, known as an \"intelligence explosion\", was first proposed by I. J. Good in 1965:\n\nLet an ultraintelligent machine be defined as a machine that can far surpass all the intellectual activities of any man however clever. Since the design of machines is one of these intellectual activities, an ultraintelligent machine could design even better machines; there would then unquestionably be an 'intelligence explosion,' and the intelligence of man would be left far behind. Thus the first ultraintelligent machine is the last invention that man need ever make, provided that the machine is docile enough to tell us how to keep it under control.\nThis scenario presents the AI control problem: how to create an ASI that will benefit humanity while avoiding unintended harmful consequences. Eliezer Yudkowsky argues that solving this problem is crucial before ASI is developed, as a superintelligent system might be able to thwart any subsequent attempts at control.\n\n\n=== Unintended consequences and goal misalignment ===\nEven with benign intentions, an ASI could potentially cause harm due to misaligned goals or unexpected interpretations of its objectives. Nick Bostrom provides a stark example of this risk:\n\nWhen we create the first superintelligent entity, we might make a mistake and give it goals that lead it to annihilate humankind, assuming its enormous intellectual advantage gives it the power to do so. For example, we could mistakenly elevate a subgoal to the status of a supergoal. We tell it to solve a mathematical problem, and it complies by turning all the matter in the solar system into a giant calculating device, in the process killing the person who asked the question.\nStuart Russell offers another illustrative scenario:\n\nA system given the objective of maximizing human happiness might find it easier to rewire human neurology so that humans are always happy regardless of their circumstances, rather than to improve the external world.\nThese examples highlight the potential for catastrophic outcomes even when an ASI is not explicitly designed to be harmful, underscoring the critical importance of precise goal specification and alignment.", "mimetype": "text/plain", "start_char_idx": 13039, "end_char_idx": 18461, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7f08f025-39b5-4bd9-abfe-bd27d2985975": {"__data__": {"id_": "7f08f025-39b5-4bd9-abfe-bd27d2985975", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "726659", "node_type": "4", "metadata": {}, "hash": "341f2972b85a37a52d0b7b36a021cb08664fdf14343b0cf97eb85cfc57b934f0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "85af1381-a703-4b44-87a9-ea69dbee7a1d", "node_type": "1", "metadata": {}, "hash": "2596496496cf3e4d336143d2fb6bc2d9ad44cad3b72cd3d0856060ecea1d7401", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5d9af55c-9d45-4243-b86e-a8f3d4e0d324", "node_type": "1", "metadata": {}, "hash": "666b1ff84d56108d0dd8f4aa4cccdbb19ebc26ff9687bb76b9acc40a9576812f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Potential mitigation strategies ===\nResearchers have proposed various approaches to mitigate risks associated with ASI:\n\nCapability control \u2013 Limiting an ASI's ability to influence the world, such as through physical isolation or restricted access to resources.\nMotivational control \u2013 Designing ASIs with goals that are fundamentally aligned with human values.\nEthical AI \u2013 Incorporating ethical principles and decision-making frameworks into ASI systems.\nOversight and governance \u2013 Developing robust international frameworks for the development and deployment of ASI technologies.\nDespite these proposed strategies, some experts, such as Roman Yampolskiy, argue that the challenge of controlling a superintelligent AI might be fundamentally unsolvable, emphasizing the need for extreme caution in ASI development.\n\n\n=== Debate and skepticism ===\nNot all researchers agree on the likelihood or severity of ASI-related existential risks. Some, like Rodney Brooks, argue that fears of superintelligent AI are overblown and based on unrealistic assumptions about the nature of intelligence and technological progress. Others, such as Joanna Bryson, contend that anthropomorphizing AI systems leads to misplaced concerns about their potential threats.\n\n\n=== Recent developments and current perspectives ===\nThe rapid advancement of LLMs and other AI technologies has intensified debates about the proximity and potential risks of ASI. While there is no scientific consensus, some researchers and AI practitioners argue that current AI systems may already be approaching AGI or even ASI capabilities.\n\nLLM capabilities \u2013 Recent LLMs like GPT-4 have demonstrated unexpected abilities in areas such as reasoning, problem-solving, and multi-modal understanding, leading some to speculate about their potential path to ASI.\nEmergent behaviors \u2013 Studies have shown that as AI models increase in size and complexity, they can exhibit emergent capabilities not present in smaller models, potentially indicating a trend towards more general intelligence.\nRapid progress \u2013 The pace of AI advancement has led some to argue that we may be closer to ASI than previously thought, with potential implications for existential risk.\nAs of 2024, AI skeptics such as Gary Marcus caution against premature claims of AGI or ASI, arguing that current AI systems, despite their impressive capabilities, still lack true understanding and general intelligence. They emphasize the significant challenges that remain in achieving human-level intelligence, let alone superintelligence.\nThe debate surrounding the current state and trajectory of AI development underscores the importance of continued research into AI safety and ethics, as well as the need for robust governance frameworks to manage potential risks as AI capabilities continue to advance.\n\n\n== See also ==\n\n\n== References ==\n\n\n=== Papers ===\nBostrom, Nick (2002), \"Existential Risks\", Journal of Evolution and Technology, 9, retrieved 2007-08-07.\nChalmers, David (2010). \"The Singularity: A Philosophical Analysis\" (PDF). Journal of Consciousness Studies. 17: 7\u201365.\nLegg, Shane (2008). Machine Super Intelligence (PDF) (PhD). Department of Informatics, University of Lugano. Retrieved September 19, 2014.\nM\u00fcller, Vincent C.; Bostrom, Nick (2016). \"Future Progress in Artificial Intelligence: A Survey of Expert Opinion\". In M\u00fcller, Vincent C. (ed.). Fundamental Issues of Artificial Intelligence. Springer. pp. 553\u2013571.\nSantos-Lang, Christopher (2014). \"Our responsibility to manage evaluative diversity\" (PDF). ACM SIGCAS Computers and Society. 44 (2): 16\u201319. doi:10.1145/2656870.2656874. S2CID 5649158. Archived from the original on July 29, 2014.\n\n\n=== Books ===\nHibbard, Bill (2002). Super-Intelligent Machines. Kluwer Academic/Plenum Publishers.\nBostrom, Nick (2014). Superintelligence: Paths, Dangers, Strategies. Oxford University Press.\nTegmark, Max (2018). Life 3.0: being human in the age of artificial intelligence. London, England. ISBN 978-0-14-198180-2. OCLC 1018461467.{{cite book}}:  CS1 maint: location missing publisher (link)\nRussell, Stuart J. (2019). Human compatible: artificial intelligence and the problem of control. New York. ISBN 978-0-525-55861-3. OCLC 1113410915.{{cite book}}:  CS1 maint: location missing publisher (link)\nSanders, Nada R. (2020). The humachine: humankind, machines, and the future of enterprise. John D. Wood (First ed.). New York, New York. ISBN 978-0-429-00117-8. OCLC 1119391268.{{cite book}}:  CS1 maint: location missing publisher (link)", "mimetype": "text/plain", "start_char_idx": 18464, "end_char_idx": 22992, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5d9af55c-9d45-4243-b86e-a8f3d4e0d324": {"__data__": {"id_": "5d9af55c-9d45-4243-b86e-a8f3d4e0d324", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "726659", "node_type": "4", "metadata": {}, "hash": "341f2972b85a37a52d0b7b36a021cb08664fdf14343b0cf97eb85cfc57b934f0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7f08f025-39b5-4bd9-abfe-bd27d2985975", "node_type": "1", "metadata": {}, "hash": "028a39594893e147f6555b989e562622fd6c62c28160f3ead7a3a17afa9463ee", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== External links ==\nBill Gates Joins Stephen Hawking in Fears of a Coming Threat from \"Superintelligence\"\nWill Superintelligent Machines Destroy Humanity?\nApple Co-founder Has Sense of Foreboding About Artificial Superintelligence", "mimetype": "text/plain", "start_char_idx": 22995, "end_char_idx": 23226, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}}}